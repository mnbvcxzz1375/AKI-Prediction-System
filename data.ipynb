{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3386cf9-ca06-46ea-8fb2-c94c19427d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# 设置可视化风格\n",
    "plt.style.use('tableau-colorblind10')\n",
    "# 设置字体为SimHei(黑体)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "# 解决中文字体下坐标轴负数的负号显示问题\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f88db3b-6bc0-46a4-8e15-7cabaaead1d1",
   "metadata": {},
   "source": [
    "### 血气数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3806438e-9419-4397-b0dc-dd48426334b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25768\\862766434.py:7: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清洗后的数据已保存到 cleaned_blood_gas_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler ,MinMaxScaler\n",
    "\n",
    "# 读取数据\n",
    "file_path = 'blood_gas_sampled_with_flags.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 1. 删除 ID 类和文本描述相关的列\n",
    "columns_to_remove = ['subject_id', 'hadm_id', 'icd9_code']  # 添加需要移除的列名\n",
    "df_cleaned = df.drop(columns=[col for col in columns_to_remove if col in df.columns])\n",
    "\n",
    "if 'gender' in df_cleaned.columns:\n",
    "    df_cleaned['gender'] = df_cleaned['gender'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "\n",
    "# 2. 去除缺失值比例超过 50% 的列\n",
    "missing_threshold = 0.5\n",
    "df_cleaned = df_cleaned.loc[:, df_cleaned.isnull().mean() <= missing_threshold]\n",
    "\n",
    "# 3. 填充剩余的缺失值\n",
    "imputer = SimpleImputer(strategy='median')  # 使用中位数填充\n",
    "df_cleaned[df_cleaned.columns] = imputer.fit_transform(df_cleaned)\n",
    "\n",
    "# 4. 提取数值特征并标准化\n",
    "features = df_cleaned.drop(columns=['match_flag'])  # 假设 'match_flag' 是标签列\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "scaler = MinMaxScaler()  \n",
    "features_scaled = scaler.fit_transform(features_scaled) \n",
    "\n",
    "# 转换为 DataFrame 并添加回标签列\n",
    "df_final = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "df_final['match_flag'] = df_cleaned['match_flag'].values\n",
    "\n",
    "# 保存清洗后的数据\n",
    "output_file = 'cleaned_blood_gas_data.csv'\n",
    "df_final.to_csv(output_file, index=False)\n",
    "print(f\"清洗后的数据已保存到 {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36dbc71-381d-477c-8daa-86083beb45bb",
   "metadata": {},
   "source": [
    "### aki患者肌酐水平+第一天实验室数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6874d3e3-10c7-4326-9c90-bdb8fc5f5dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25768\\2036710154.py:7: DtypeWarning: Columns (46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清洗后的数据已保存到 cleaned_aki_patients_labs_sampled_with_flags.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler ,MinMaxScaler\n",
    "\n",
    "# 读取数据\n",
    "file_path = 'aki_patients_labs_sampled_with_flags.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 1. 删除 ID 类和文本描述相关的列\n",
    "columns_to_remove = ['subject_id', 'hadm_id', 'icustay_id',  'charttime','icd9_code','long_title',]  # 添加需要移除的列名\n",
    "df_cleaned = df.drop(columns=[col for col in columns_to_remove if col in df.columns])\n",
    "\n",
    "if 'gender' in df_cleaned.columns:\n",
    "    df_cleaned['gender'] = df_cleaned['gender'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "# 2. 去除缺失值比例超过 50% 的列\n",
    "missing_threshold = 0.5\n",
    "df_cleaned = df_cleaned.loc[:, df_cleaned.isnull().mean() <= missing_threshold]\n",
    "\n",
    "# 3. 填充剩余的缺失值\n",
    "imputer = SimpleImputer(strategy='median')  # 使用中位数填充\n",
    "df_cleaned[df_cleaned.columns] = imputer.fit_transform(df_cleaned)\n",
    "\n",
    "# 4. 提取数值特征并标准化\n",
    "features = df_cleaned.drop(columns=['match_flag'])  # 假设 'match_flag' 是标签列\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "scaler = MinMaxScaler()  \n",
    "features_scaled = scaler.fit_transform(features_scaled) \n",
    "\n",
    "# 转换为 DataFrame 并添加回标签列\n",
    "df_final = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "df_final['match_flag'] = df_cleaned['match_flag'].values\n",
    "\n",
    "# 保存清洗后的数据\n",
    "output_file = 'cleaned_aki_patients_labs_sampled_with_flags.csv'\n",
    "df_final.to_csv(output_file, index=False)\n",
    "print(f\"清洗后的数据已保存到 {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de732c4-a23c-45ad-9f2f-94c333dfbf8b",
   "metadata": {},
   "source": [
    "### aki患者肌酐水平+微生物实验室数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eed4f890-0eae-43a8-8a09-8ba2ec29ffd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25768\\317449091.py:8: DtypeWarning: Columns (40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清洗后的数据已保存到 cleaned_aki_microbiology_sampled_with_flags_encoded_unique.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 读取数据\n",
    "file_path = 'aki_microbiology_sampled_with_flags.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 1. 删除 ID 类和文本描述相关的列\n",
    "columns_to_remove = ['row_id', 'subject_id', 'hadm_id', 'icustay_id', 'charttime',\n",
    "                     'icd9_code', 'long_title', 'chartdate', 'spec_itemid', 'spec_type_desc',\n",
    "                     'org_itemid', 'org_name', 'ab_itemid', 'ab_name', 'dilution_text',\n",
    "                     'dilution_comparison', 'dod', 'admittime', 'dischtime', 'intime',\n",
    "                     'outtime', 'icustay_seq', 'long_title']  # 添加需要移除的列名\n",
    "df_cleaned = df.drop(columns=[col for col in columns_to_remove if col in df.columns])\n",
    "\n",
    "# 2. 去除重复列\n",
    "df_cleaned = df_cleaned.loc[:, ~df_cleaned.columns.duplicated()]\n",
    "\n",
    "# 3. 将性别转换为数值类型\n",
    "if 'gender' in df_cleaned.columns:\n",
    "    df_cleaned['gender'] = df_cleaned['gender'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "# 4. 对非文本类型的分类特征进行编码\n",
    "for col in df_cleaned.select_dtypes(include=['object']).columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    df_cleaned[col] = label_encoder.fit_transform(df_cleaned[col].astype(str))\n",
    "\n",
    "# 5. 去除缺失值比例超过 50% 的列\n",
    "missing_threshold = 0.5\n",
    "df_cleaned = df_cleaned.loc[:, df_cleaned.isnull().mean() <= missing_threshold]\n",
    "\n",
    "# 6. 填充剩余的缺失值\n",
    "imputer = SimpleImputer(strategy='median')  # 使用中位数填充\n",
    "df_cleaned[df_cleaned.columns] = imputer.fit_transform(df_cleaned)\n",
    "\n",
    "# 7. 提取数值特征并标准化\n",
    "features = df_cleaned.drop(columns=['match_flag'])  # 假设 'match_flag' 是标签列\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 进一步归一化到 [0, 1] 范围\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features_scaled)\n",
    "\n",
    "# 转换为 DataFrame 并添加回标签列\n",
    "df_final = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "df_final['match_flag'] = df_cleaned['match_flag'].values\n",
    "\n",
    "# 保存清洗后的数据\n",
    "output_file = 'cleaned_aki_microbiology_sampled_with_flags_encoded_unique.csv'\n",
    "df_final.to_csv(output_file, index=False)\n",
    "print(f\"清洗后的数据已保存到 {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ac5c5-5e5e-421c-9bad-c4cfe0882426",
   "metadata": {},
   "source": [
    "### aki肾衰竭患者尿量数据+第一天实验室数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46158126-25a2-4490-b6ff-80fc13060dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25768\\1969900157.py:8: DtypeWarning: Columns (53) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清洗后的数据已保存到 cleaned_aki_urine_labs_sampled_with_flags.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 读取数据\n",
    "file_path = 'aki_urine_labs_sampled_with_flags.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 1. 删除 ID 类和文本描述相关的列\n",
    "columns_to_remove = ['row_id', 'subject_id', 'hadm_id', 'icustay_id', 'charttime',\n",
    "                     'icd9_code', 'long_title', ]  # 添加需要移除的列名\n",
    "df_cleaned = df.drop(columns=[col for col in columns_to_remove if col in df.columns])\n",
    "\n",
    "# 2. 去除重复列\n",
    "df_cleaned = df_cleaned.loc[:, ~df_cleaned.columns.duplicated()]\n",
    "\n",
    "# 3. 将性别转换为数值类型\n",
    "if 'gender' in df_cleaned.columns:\n",
    "    df_cleaned['gender'] = df_cleaned['gender'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "# 4. 对非文本类型的分类特征进行编码\n",
    "for col in df_cleaned.select_dtypes(include=['object']).columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    df_cleaned[col] = label_encoder.fit_transform(df_cleaned[col].astype(str))\n",
    "\n",
    "# 5. 去除缺失值比例超过 50% 的列\n",
    "missing_threshold = 0.5\n",
    "df_cleaned = df_cleaned.loc[:, df_cleaned.isnull().mean() <= missing_threshold]\n",
    "\n",
    "# 6. 填充剩余的缺失值\n",
    "imputer = SimpleImputer(strategy='median')  # 使用中位数填充\n",
    "df_cleaned[df_cleaned.columns] = imputer.fit_transform(df_cleaned)\n",
    "\n",
    "# 7. 提取数值特征并标准化\n",
    "features = df_cleaned.drop(columns=['match_flag'])  # 假设 'match_flag' 是标签列\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 进一步归一化到 [0, 1] 范围\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features_scaled)\n",
    "\n",
    "# 转换为 DataFrame 并添加回标签列\n",
    "df_final = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "df_final['match_flag'] = df_cleaned['match_flag'].values\n",
    "\n",
    "# 保存清洗后的数据\n",
    "output_file = 'cleaned_aki_urine_labs_sampled_with_flags.csv'\n",
    "df_final.to_csv(output_file, index=False)\n",
    "print(f\"清洗后的数据已保存到 {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b9ddc5-60bf-4020-9a88-b320ae96d124",
   "metadata": {},
   "source": [
    "### 住院第一天的生命体征与aki肾衰竭患者尿量数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6976ad3d-d5fc-4be7-894a-cf48e974099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25768\\3589550008.py:8: DtypeWarning: Columns (39) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清洗后的数据已保存到 cleaned_vitals_aki_urine_sampled_with_flags.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 读取数据\n",
    "file_path = 'vitals_aki_urine_sampled_with_flags.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 1. 删除 ID 类和文本描述相关的列\n",
    "columns_to_remove = ['row_id', 'subject_id', 'hadm_id', 'icustay_id', 'charttime',\n",
    "                     'icd9_code', 'long_title', ]  # 添加需要移除的列名\n",
    "df_cleaned = df.drop(columns=[col for col in columns_to_remove if col in df.columns])\n",
    "\n",
    "# 2. 去除重复列\n",
    "df_cleaned = df_cleaned.loc[:, ~df_cleaned.columns.duplicated()]\n",
    "\n",
    "# 3. 将性别转换为数值类型\n",
    "if 'gender' in df_cleaned.columns:\n",
    "    df_cleaned['gender'] = df_cleaned['gender'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "# 4. 对非文本类型的分类特征进行编码\n",
    "for col in df_cleaned.select_dtypes(include=['object']).columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    df_cleaned[col] = label_encoder.fit_transform(df_cleaned[col].astype(str))\n",
    "\n",
    "# 5. 去除缺失值比例超过 50% 的列\n",
    "missing_threshold = 0.5\n",
    "df_cleaned = df_cleaned.loc[:, df_cleaned.isnull().mean() <= missing_threshold]\n",
    "\n",
    "# 6. 填充剩余的缺失值\n",
    "imputer = SimpleImputer(strategy='median')  # 使用中位数填充\n",
    "df_cleaned[df_cleaned.columns] = imputer.fit_transform(df_cleaned)\n",
    "\n",
    "# 7. 提取数值特征并标准化\n",
    "features = df_cleaned.drop(columns=['match_flag'])  # 假设 'match_flag' 是标签列\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 进一步归一化到 [0, 1] 范围\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features_scaled)\n",
    "\n",
    "# 转换为 DataFrame 并添加回标签列\n",
    "df_final = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "df_final['match_flag'] = df_cleaned['match_flag'].values\n",
    "\n",
    "# 保存清洗后的数据\n",
    "output_file = 'cleaned_vitals_aki_urine_sampled_with_flags.csv'\n",
    "df_final.to_csv(output_file, index=False)\n",
    "print(f\"清洗后的数据已保存到 {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa129f60-7544-48e4-bd1c-c8c029df59e6",
   "metadata": {},
   "source": [
    "### 语言 宗教 婚姻 种族"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a539d8b-1e37-45d5-a2b1-341222a26030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清洗后的数据已保存到 cleaned_language_religion_ethnicity_sampled_with_flags.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 读取数据\n",
    "file_path = 'language_religion_ethnicity_sampled_with_flags.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 1. 删除 ID 类和文本描述相关的列\n",
    "columns_to_remove = ['row_id', 'subject_id', 'hadm_id', 'icustay_id', 'charttime',\n",
    "                     'icd9_code', 'long_title', ]  # 添加需要移除的列名\n",
    "df_cleaned = df.drop(columns=[col for col in columns_to_remove if col in df.columns])\n",
    "\n",
    "# 2. 去除重复列\n",
    "df_cleaned = df_cleaned.loc[:, ~df_cleaned.columns.duplicated()]\n",
    "\n",
    "# 3. 将性别转换为数值类型\n",
    "if 'gender' in df_cleaned.columns:\n",
    "    df_cleaned['gender'] = df_cleaned['gender'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "# 4. 对非文本类型的分类特征进行编码\n",
    "for col in df_cleaned.select_dtypes(include=['object']).columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    df_cleaned[col] = label_encoder.fit_transform(df_cleaned[col].astype(str))\n",
    "\n",
    "# 5. 去除缺失值比例超过 50% 的列\n",
    "missing_threshold = 0.5\n",
    "df_cleaned = df_cleaned.loc[:, df_cleaned.isnull().mean() <= missing_threshold]\n",
    "\n",
    "# 6. 填充剩余的缺失值\n",
    "imputer = SimpleImputer(strategy='median')  # 使用中位数填充\n",
    "df_cleaned[df_cleaned.columns] = imputer.fit_transform(df_cleaned)\n",
    "\n",
    "# 7. 提取数值特征并标准化\n",
    "features = df_cleaned.drop(columns=['match_flag'])  # 假设 'match_flag' 是标签列\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 进一步归一化到 [0, 1] 范围\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features_scaled)\n",
    "\n",
    "# 转换为 DataFrame 并添加回标签列\n",
    "df_final = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "df_final['match_flag'] = df_cleaned['match_flag'].values\n",
    "\n",
    "# 保存清洗后的数据\n",
    "output_file = 'cleaned_language_religion_ethnicity_sampled_with_flags.csv'\n",
    "df_final.to_csv(output_file, index=False)\n",
    "print(f\"清洗后的数据已保存到 {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9778121b-3e10-4272-ad44-2282315c3c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spo2</th>\n",
       "      <th>po2</th>\n",
       "      <th>pco2</th>\n",
       "      <th>pao2fio2</th>\n",
       "      <th>ph</th>\n",
       "      <th>totalco2</th>\n",
       "      <th>match_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.122642</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.098208</td>\n",
       "      <td>0.650350</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.134771</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.107512</td>\n",
       "      <td>0.657343</td>\n",
       "      <td>0.204819</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.115903</td>\n",
       "      <td>0.102679</td>\n",
       "      <td>0.093039</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.204819</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.185984</td>\n",
       "      <td>0.084821</td>\n",
       "      <td>0.116196</td>\n",
       "      <td>0.671329</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.373315</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.112474</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.168675</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       spo2       po2      pco2  pao2fio2        ph  totalco2  match_flag\n",
       "0  0.979798  0.122642  0.089286  0.098208  0.650350  0.192771         1.0\n",
       "1  0.979798  0.134771  0.093750  0.107512  0.657343  0.204819         1.0\n",
       "2  0.979798  0.115903  0.102679  0.093039  0.636364  0.204819         1.0\n",
       "3  0.979798  0.185984  0.084821  0.116196  0.671329  0.192771         1.0\n",
       "4  0.979798  0.373315  0.116071  0.112474  0.559441  0.168675         1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'cleaned_blood_gas_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18829eeb-8555-41f4-9afe-e5600fcfbf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler  \n",
    "import numpy as np  \n",
    "\n",
    "\n",
    "X=df.iloc[:,:-1]\n",
    "Y=df['match_flag']\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff40c4f3-1630-49c8-a5ef-68040eca7b6d",
   "metadata": {},
   "source": [
    "## cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff569b61-1ab1-4718-a2fd-a8be3127aa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------第1轮训练-------\n",
      "训练损失: 28101.7449\n",
      "测试损失: 11623.4030, 准确率: 0.7496\n",
      "------第2轮训练-------\n",
      "训练损失: 27771.1330\n",
      "测试损失: 11600.9753, 准确率: 0.7496\n",
      "------第3轮训练-------\n",
      "训练损失: 27636.6002\n",
      "测试损失: 11549.7414, 准确率: 0.7495\n",
      "------第4轮训练-------\n",
      "训练损失: 27540.9744\n",
      "测试损失: 11455.4247, 准确率: 0.7496\n",
      "------第5轮训练-------\n",
      "训练损失: 27480.3246\n",
      "测试损失: 11481.5648, 准确率: 0.7495\n",
      "------第6轮训练-------\n",
      "训练损失: 27318.6247\n",
      "测试损失: 11466.1227, 准确率: 0.7494\n",
      "------第7轮训练-------\n",
      "训练损失: 27113.3984\n",
      "测试损失: 11498.3413, 准确率: 0.7495\n",
      "------第8轮训练-------\n",
      "训练损失: 26995.6864\n",
      "测试损失: 11405.2650, 准确率: 0.7495\n",
      "------第9轮训练-------\n",
      "训练损失: 26948.7613\n",
      "测试损失: 11391.7469, 准确率: 0.7495\n",
      "------第10轮训练-------\n",
      "训练损失: 26913.7181\n",
      "测试损失: 11533.4576, 准确率: 0.7495\n",
      "模型已保存到 cnn_model1.pth\n",
      "总训练时间: 2186.01 秒\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 检测设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 读取数据\n",
    "file_path = './data/cleaned_kdigo_uo.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "X = df.iloc[:, :-1].values  # 特征\n",
    "Y = df['match_flag'].values  # 标签\n",
    "\n",
    "# 数据分割\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 转换为 PyTorch 张量\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # 添加通道维度\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)  # 转换为浮点型\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)  # 转换为浮点型\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# 定义 CNN 模型\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.model1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=2, padding=3),\n",
    "            nn.BatchNorm1d(16),  # 增加 Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(1),\n",
    "\n",
    "            nn.Conv1d(16, 32, kernel_size=5),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(1),\n",
    "\n",
    "            nn.Conv1d(32, 64, kernel_size=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(1),\n",
    "            # nn.Dropout(p=0.2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.model2 = None  # Placeholder\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.model1(input)\n",
    "\n",
    "        # 动态初始化 model2\n",
    "        if self.model2 is None:\n",
    "            self.model2 = nn.Sequential(\n",
    "                nn.Linear(in_features=x.shape[1], out_features=128, bias=True),\n",
    "                nn.BatchNorm1d(128),  # 增加 Batch Normalization\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.4),  # 增加 Dropout\n",
    "                nn.Linear(in_features=128, out_features=1, bias=True),\n",
    "            )\n",
    "            self.model2 = self.model2.to(input.device)  # 确保在正确的设备上\n",
    "\n",
    "        x = self.model2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 实例化模型并移动到设备\n",
    "cnn = CNN().to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n",
    "\n",
    "# 超参数设置\n",
    "epoch = 10\n",
    "\n",
    "# TensorBoard 日志记录\n",
    "writer = SummaryWriter('loss_train')\n",
    "start_time = time.time()\n",
    "\n",
    "# 开始训练\n",
    "for i in range(epoch):\n",
    "    print(f'------第{i + 1}轮训练-------')\n",
    "\n",
    "    cnn.train()\n",
    "    total_train_loss = 0\n",
    "    for batch_data, batch_labels in train_loader:\n",
    "        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = cnn(batch_data).squeeze(1)  # 去掉通道维度\n",
    "        loss = loss_fn(outputs, batch_labels)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    print(f'训练损失: {total_train_loss:.4f}')\n",
    "    writer.add_scalar('Train Loss', total_train_loss, i)\n",
    "\n",
    "    # 测试阶段\n",
    "    cnn.eval()\n",
    "    total_test_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in test_loader:\n",
    "            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "\n",
    "            outputs = cnn(batch_data).squeeze(1)  # 去掉通道维度\n",
    "            loss = loss_fn(outputs, batch_labels)\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            # 计算准确率\n",
    "            predictions = torch.sigmoid(outputs) > 0.5  # 转为概率并判断大于0.5\n",
    "            total_correct += (predictions == batch_labels).sum().item()\n",
    "\n",
    "    accuracy = total_correct / len(test_dataset)\n",
    "    print(f'测试损失: {total_test_loss:.4f}, 准确率: {accuracy:.4f}')\n",
    "    writer.add_scalar('Test Loss', total_test_loss, i)\n",
    "    writer.add_scalar('Accuracy', accuracy, i)\n",
    "\n",
    "# 保存模型\n",
    "model_path = 'cnn_model1.pth'\n",
    "torch.save(cnn.state_dict(), model_path)\n",
    "print(f'模型已保存到 {model_path}')\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'总训练时间: {end_time - start_time:.2f} 秒')\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc18042-501d-4f41-a403-748a0f8366bd",
   "metadata": {},
   "source": [
    "## TabTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb2a05f-fb1b-4d62-a4db-405f6e594267",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Got 64 and 18 (The offending index is 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 151\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 151\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 144\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# 训练和评估\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m--> 144\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     val_loss, accuracy, precision, recall, f1, auc \u001b[38;5;241m=\u001b[39m evaluate_model(model, test_loader1, test_loader2, criterion, device)\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 76\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader1, train_loader2, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     74\u001b[0m X1_batch, X2_batch, y1_batch \u001b[38;5;241m=\u001b[39m X1_batch\u001b[38;5;241m.\u001b[39mto(device), X2_batch\u001b[38;5;241m.\u001b[39mto(device), y1_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     75\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 76\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX2_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y1_batch)\n\u001b[0;32m     78\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[2], line 65\u001b[0m, in \u001b[0;36mDualTabTransformer.forward\u001b[1;34m(self, x1, x2)\u001b[0m\n\u001b[0;32m     63\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer1(x1)\n\u001b[0;32m     64\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer2(x2)\n\u001b[1;32m---> 65\u001b[0m combined \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 拼接两个特征\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(combined)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Got 64 and 18 (The offending index is 0)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 数据预处理\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# 加载数据\n",
    "def load_data(file_path, target_column, batch_size=64):\n",
    "    df = pd.read_csv(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "    test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# TabTransformer 模型\n",
    "class TabTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_layers, dropout=0.1):\n",
    "        super(TabTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # (batch_size, embed_dim)\n",
    "        x = x.unsqueeze(1)  # (batch_size, 1, embed_dim)\n",
    "        x = x.transpose(0, 1)  # (sequence_length=1, batch_size, embed_dim)\n",
    "        x = self.transformer(x)  # (sequence_length=1, batch_size, embed_dim)\n",
    "        x = x.squeeze(0)  # (batch_size, embed_dim)\n",
    "        return x\n",
    "\n",
    "# 联合 TabTransformer 模型\n",
    "class DualTabTransformer(nn.Module):\n",
    "    def __init__(self, input_dim1, input_dim2, embed_dim, num_heads, num_layers, dropout=0.1):\n",
    "        super(DualTabTransformer, self).__init__()\n",
    "        self.transformer1 = TabTransformer(input_dim1, embed_dim, num_heads, num_layers, dropout)\n",
    "        self.transformer2 = TabTransformer(input_dim2, embed_dim, num_heads, num_layers, dropout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 2, 128),  # 拼接两个特征\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 1)  # 输出单个值\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.transformer1(x1)\n",
    "        x2 = self.transformer2(x2)\n",
    "        combined = torch.cat((x1, x2), dim=1)  # 拼接两个特征\n",
    "        return self.fc(combined).squeeze(1)  # 输出 (batch_size, )\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "def train_model(model, train_loader1, train_loader2, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for (X1_batch, y1_batch), (X2_batch, _) in zip(train_loader1, train_loader2):\n",
    "        X1_batch, X2_batch, y1_batch = X1_batch.to(device), X2_batch.to(device), y1_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X1_batch, X2_batch)\n",
    "        loss = criterion(outputs, y1_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader1)\n",
    "\n",
    "# 评估模型\n",
    "def evaluate_model(model, test_loader1, test_loader2, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_pred_proba = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (X1_batch, y1_batch), (X2_batch, _) in zip(test_loader1, test_loader2):\n",
    "            X1_batch, X2_batch, y1_batch = X1_batch.to(device), X2_batch.to(device), y1_batch.to(device)\n",
    "            outputs = model(X1_batch, X2_batch)\n",
    "            loss = criterion(outputs, y1_batch)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            probs = torch.sigmoid(outputs)\n",
    "\n",
    "            y_true.extend(y1_batch.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_pred_proba.extend(probs.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred_proba)\n",
    "\n",
    "    return total_loss / len(test_loader1), accuracy, precision, recall, f1, auc\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    file_path1 = './data/cleaned_urine_output_first_day.csv'\n",
    "    file_path2 = './data/cleaned_vitals_first_day.csv'\n",
    "    target_column = 'match_flag'\n",
    "\n",
    "    # 加载两个文件的数据\n",
    "    train_loader1, test_loader1 = load_data(file_path1, target_column)\n",
    "    train_loader2, test_loader2 = load_data(file_path2, target_column)\n",
    "\n",
    "    # 模型参数\n",
    "    input_dim1 = next(iter(train_loader1))[0].shape[1]\n",
    "    input_dim2 = next(iter(train_loader2))[0].shape[1]\n",
    "    embed_dim = 64\n",
    "    num_heads = 4\n",
    "    num_layers = 2\n",
    "    dropout = 0.1\n",
    "    epochs = 30\n",
    "\n",
    "    # 模型初始化\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = DualTabTransformer(input_dim1, input_dim2, embed_dim, num_heads, num_layers, dropout).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()  # 替换为 BCEWithLogitsLoss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # 训练和评估\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_model(model, train_loader1, train_loader2, criterion, optimizer, device)\n",
    "        val_loss, accuracy, precision, recall, f1, auc = evaluate_model(model, test_loader1, test_loader2, criterion, device)\n",
    "        print(f\"Epoch {epoch + 1}:\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85622e87-1018-474b-aa79-2cc29eab85d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'urine_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 155\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# 主程序\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# 加载数据\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m     urine_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murine_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m     vitals_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvitals_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m     target_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch_flag\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'urine_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 自动特征列生成器\n",
    "class FeatureGenerator:\n",
    "    @staticmethod\n",
    "    def auto_detect(df, \n",
    "                   target_column, \n",
    "                   exclude_patterns=[r'_id$', r'_date$', r'timestamp'],\n",
    "                   explicit_exclude=[]):\n",
    "        \"\"\"\n",
    "        智能特征列检测\n",
    "        参数：\n",
    "            df: 数据框\n",
    "            target_column: 目标列名\n",
    "            exclude_patterns: 要排除的列名正则模式\n",
    "            explicit_exclude: 显式排除的列名列表\n",
    "        \"\"\"\n",
    "        # 初始化排除列\n",
    "        exclude_columns = set(explicit_exclude)\n",
    "        \n",
    "        # 正则匹配排除\n",
    "        pattern = re.compile('|'.join(exclude_patterns), re.IGNORECASE)\n",
    "        for col in df.columns:\n",
    "            if pattern.search(col):\n",
    "                exclude_columns.add(col)\n",
    "                \n",
    "        # 确保排除目标列\n",
    "        exclude_columns.add(target_column)\n",
    "        \n",
    "        # 生成特征列\n",
    "        features = [col for col in df.columns if col not in exclude_columns]\n",
    "        \n",
    "        # 验证特征有效性\n",
    "        valid_dtypes = ['int64', 'float64', 'bool']\n",
    "        features = [col for col in features if df[col].dtype in valid_dtypes]\n",
    "        \n",
    "        return features \n",
    "\n",
    "# --------------------------\n",
    "# 核心模型架构\n",
    "# --------------------------\n",
    "\n",
    "class FeatureSpecificModel(nn.Module):\n",
    "    \"\"\"特征专用分类模型\"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "# --------------------------\n",
    "# 训练流水线\n",
    "# --------------------------\n",
    "\n",
    "def train_model(data_loader, epochs=30):\n",
    "    \"\"\"独立训练流程\"\"\"\n",
    "    model = FeatureSpecificModel(\n",
    "        input_dim=data_loader.dataset[0][0].shape[0]\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss/len(data_loader):.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# --------------------------\n",
    "# 智能预测系统\n",
    "# --------------------------\n",
    "\n",
    "class HybridPredictor:\n",
    "    \"\"\"混合预测系统\"\"\"\n",
    "    def __init__(self, modelA, modelB):\n",
    "        self.modelA = modelA.to(device).eval()\n",
    "        self.modelB = modelB.to(device).eval()\n",
    "        \n",
    "    def predict(self, X_dict):\n",
    "        \"\"\"\n",
    "        输入格式：{'feature_set1': X1_tensor, 'feature_set2': X2_tensor}\n",
    "        至少包含一个特征集\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            results = {}\n",
    "            \n",
    "            # 处理第一个特征集\n",
    "            if 'feature_set1' in X_dict:\n",
    "                X1 = X_dict['feature_set1'].to(device)\n",
    "                results['prob1'] = torch.sigmoid(self.modelA(X1))\n",
    "                \n",
    "            # 处理第二个特征集\n",
    "            if 'feature_set2' in X_dict:\n",
    "                X2 = X_dict['feature_set2'].to(device)\n",
    "                results['prob2'] = torch.sigmoid(self.modelB(X2))\n",
    "                \n",
    "            # 动态融合策略\n",
    "            if len(results) == 2:\n",
    "                final_prob = 0.7*results['prob1'] + 0.3*results['prob2']\n",
    "            elif 'prob1' in results:\n",
    "                final_prob = results['prob1']\n",
    "            else:\n",
    "                final_prob = results['prob2']\n",
    "            \n",
    "            return (final_prob > 0.5).float().cpu().numpy()\n",
    "\n",
    "# --------------------------\n",
    "# 数据预处理\n",
    "# --------------------------\n",
    "\n",
    "def prepare_dataset(df, feature_columns, target_column):\n",
    "    \"\"\"创建特征特定的数据集\"\"\"\n",
    "    X = df[feature_columns].values.astype(np.float32)\n",
    "    y = df[target_column].values.astype(np.float32)\n",
    "    dataset = TensorDataset(torch.tensor(X), torch.tensor(y))\n",
    "    return DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# --------------------------\n",
    "# 使用示例\n",
    "# --------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 假设两个数据文件结构\n",
    "    # urine_data.csv: urine_feature1, urine_feature2..., match_flag\n",
    "    # vitals_data.csv: vital_feature1, vital_feature2..., match_flag\n",
    "    \n",
    "    # 加载数据（示例路径）\n",
    "    urine_df = pd.read_csv(\"./data/cleaned_urine_output.csv\")\n",
    "    vitals_df = pd.read_csv(\"./data/cleaned_vitals_first_day.csv\")\n",
    "    \n",
    "    # 定义特征列（根据实际数据修改）\n",
    "# 自动生成特征列\n",
    "    urine_features = FeatureGenerator.auto_detect(\n",
    "        urine_df,\n",
    "        target_column='match_flag',\n",
    "    )\n",
    "    \n",
    "    vitals_features = FeatureGenerator.auto_detect(\n",
    "        vitals_df,\n",
    "        target_column='match_flag',\n",
    "    )\n",
    "    \n",
    "    # 准备训练数据\n",
    "    print(\"训练尿液特征模型...\")\n",
    "    urine_loader = prepare_dataset(urine_df, urine_features, target_col)\n",
    "    modelA = train_model(urine_loader)\n",
    "    \n",
    "    print(\"\\n训练生命体征模型...\")\n",
    "    vitals_loader = prepare_dataset(vitals_df, vitals_features, target_col)\n",
    "    modelB = train_model(vitals_loader)\n",
    "    \n",
    "    # 初始化预测系统\n",
    "    predictor = HybridPredictor(modelA, modelB)\n",
    "    \n",
    "    # 模拟测试数据（三种情况）\n",
    "    test_case1 = {  # 只有尿液特征\n",
    "        'feature_set1': torch.randn(5, len(urine_features))  \n",
    "    }\n",
    "    test_case2 = {  # 只有生命体征\n",
    "        'feature_set2': torch.randn(3, len(vitals_features))\n",
    "    }\n",
    "    test_case3 = {  # 两者都有\n",
    "        'feature_set1': torch.randn(2, len(urine_features)),\n",
    "        'feature_set2': torch.randn(2, len(vitals_features))\n",
    "    }\n",
    "    \n",
    "    # 执行预测\n",
    "    print(\"\\n测试案例1预测结果:\", predictor.predict(test_case1))\n",
    "    print(\"测试案例2预测结果:\", predictor.predict(test_case2))\n",
    "    print(\"测试案例3预测结果:\", predictor.predict(test_case3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c991ab64-0677-476f-8a5e-e5f5d8e64a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Train Loss: 0.6860, Val Loss: 0.6902\n",
      "Accuracy: 0.5424, Precision: 0.5235, Recall: 0.9432, F1: 0.6733, AUC: 0.6304\n",
      "Epoch 2:\n",
      "Train Loss: 0.6736, Val Loss: 0.6630\n",
      "Accuracy: 0.6039, Precision: 0.6383, Recall: 0.4797, F1: 0.5477, AUC: 0.6512\n",
      "Epoch 3:\n",
      "Train Loss: 0.6626, Val Loss: 0.6506\n",
      "Accuracy: 0.6272, Precision: 0.6267, Recall: 0.6292, F1: 0.6279, AUC: 0.6675\n",
      "Epoch 4:\n",
      "Train Loss: 0.6572, Val Loss: 0.6689\n",
      "Accuracy: 0.5934, Precision: 0.5584, Recall: 0.8932, F1: 0.6872, AUC: 0.6731\n",
      "Epoch 5:\n",
      "Train Loss: 0.6535, Val Loss: 0.6450\n",
      "Accuracy: 0.6310, Precision: 0.6425, Recall: 0.5905, F1: 0.6154, AUC: 0.6804\n",
      "Epoch 6:\n",
      "Train Loss: 0.6499, Val Loss: 0.6469\n",
      "Accuracy: 0.6281, Precision: 0.6647, Recall: 0.5168, F1: 0.5815, AUC: 0.6867\n",
      "Epoch 7:\n",
      "Train Loss: 0.6452, Val Loss: 0.6542\n",
      "Accuracy: 0.6193, Precision: 0.6090, Recall: 0.6665, F1: 0.6365, AUC: 0.6660\n",
      "Epoch 8:\n",
      "Train Loss: 0.6461, Val Loss: 0.6422\n",
      "Accuracy: 0.6312, Precision: 0.6419, Recall: 0.5933, F1: 0.6167, AUC: 0.6819\n",
      "Epoch 9:\n",
      "Train Loss: 0.6372, Val Loss: 0.6488\n",
      "Accuracy: 0.6179, Precision: 0.6928, Recall: 0.4237, F1: 0.5258, AUC: 0.6888\n",
      "Epoch 10:\n",
      "Train Loss: 0.6378, Val Loss: 0.6333\n",
      "Accuracy: 0.6417, Precision: 0.6160, Recall: 0.7522, F1: 0.6773, AUC: 0.7010\n",
      "Epoch 11:\n",
      "Train Loss: 0.6363, Val Loss: 0.6336\n",
      "Accuracy: 0.6420, Precision: 0.6331, Recall: 0.6755, F1: 0.6536, AUC: 0.6937\n",
      "Epoch 12:\n",
      "Train Loss: 0.6325, Val Loss: 0.6373\n",
      "Accuracy: 0.6312, Precision: 0.6874, Recall: 0.4812, F1: 0.5661, AUC: 0.7040\n",
      "Epoch 13:\n",
      "Train Loss: 0.6290, Val Loss: 0.6344\n",
      "Accuracy: 0.6425, Precision: 0.6265, Recall: 0.7057, F1: 0.6637, AUC: 0.6973\n",
      "Epoch 14:\n",
      "Train Loss: 0.6233, Val Loss: 0.6293\n",
      "Accuracy: 0.6472, Precision: 0.6597, Recall: 0.6078, F1: 0.6327, AUC: 0.7077\n",
      "Epoch 15:\n",
      "Train Loss: 0.6170, Val Loss: 0.6297\n",
      "Accuracy: 0.6380, Precision: 0.6133, Recall: 0.7472, F1: 0.6736, AUC: 0.7004\n",
      "Epoch 16:\n",
      "Train Loss: 0.6156, Val Loss: 0.6173\n",
      "Accuracy: 0.6507, Precision: 0.6529, Recall: 0.6433, F1: 0.6481, AUC: 0.7147\n",
      "Epoch 17:\n",
      "Train Loss: 0.6101, Val Loss: 0.6104\n",
      "Accuracy: 0.6501, Precision: 0.6851, Recall: 0.5555, F1: 0.6135, AUC: 0.7226\n",
      "Epoch 18:\n",
      "Train Loss: 0.6086, Val Loss: 0.6037\n",
      "Accuracy: 0.6594, Precision: 0.6675, Recall: 0.6352, F1: 0.6510, AUC: 0.7283\n",
      "Epoch 19:\n",
      "Train Loss: 0.6004, Val Loss: 0.6024\n",
      "Accuracy: 0.6625, Precision: 0.6504, Recall: 0.7028, F1: 0.6756, AUC: 0.7354\n",
      "Epoch 20:\n",
      "Train Loss: 0.5940, Val Loss: 0.6048\n",
      "Accuracy: 0.6589, Precision: 0.6728, Recall: 0.6188, F1: 0.6447, AUC: 0.7286\n",
      "Epoch 21:\n",
      "Train Loss: 0.5864, Val Loss: 0.5888\n",
      "Accuracy: 0.6643, Precision: 0.6810, Recall: 0.6180, F1: 0.6480, AUC: 0.7426\n",
      "Epoch 22:\n",
      "Train Loss: 0.5825, Val Loss: 0.5880\n",
      "Accuracy: 0.6653, Precision: 0.6804, Recall: 0.6232, F1: 0.6505, AUC: 0.7434\n",
      "Epoch 23:\n",
      "Train Loss: 0.5762, Val Loss: 0.5875\n",
      "Accuracy: 0.6608, Precision: 0.6427, Recall: 0.7243, F1: 0.6811, AUC: 0.7416\n",
      "Epoch 24:\n",
      "Train Loss: 0.5681, Val Loss: 0.5811\n",
      "Accuracy: 0.6711, Precision: 0.6960, Recall: 0.6075, F1: 0.6487, AUC: 0.7547\n",
      "Epoch 25:\n",
      "Train Loss: 0.5650, Val Loss: 0.5780\n",
      "Accuracy: 0.6722, Precision: 0.6932, Recall: 0.6177, F1: 0.6533, AUC: 0.7559\n",
      "Epoch 26:\n",
      "Train Loss: 0.5591, Val Loss: 0.5905\n",
      "Accuracy: 0.6636, Precision: 0.6905, Recall: 0.5928, F1: 0.6380, AUC: 0.7478\n",
      "Epoch 27:\n",
      "Train Loss: 0.5502, Val Loss: 0.5756\n",
      "Accuracy: 0.6760, Precision: 0.6596, Recall: 0.7273, F1: 0.6918, AUC: 0.7599\n",
      "Epoch 28:\n",
      "Train Loss: 0.5438, Val Loss: 0.5624\n",
      "Accuracy: 0.6841, Precision: 0.6823, Recall: 0.6890, F1: 0.6856, AUC: 0.7699\n",
      "Epoch 29:\n",
      "Train Loss: 0.5366, Val Loss: 0.5739\n",
      "Accuracy: 0.6754, Precision: 0.6500, Recall: 0.7600, F1: 0.7007, AUC: 0.7618\n",
      "Epoch 30:\n",
      "Train Loss: 0.5330, Val Loss: 0.6091\n",
      "Accuracy: 0.6795, Precision: 0.6651, Recall: 0.7232, F1: 0.6929, AUC: 0.7581\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# 数据预处理\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# 加载数据\n",
    "def load_data(file_path, target_column, batch_size=64):\n",
    "    df = pd.read_csv(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "    test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# FT-Transformer 模型\n",
    "class FTTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_layers, dropout=0.1):\n",
    "        super(FTTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.layer_norms = nn.ModuleList([nn.LayerNorm(embed_dim) for _ in range(num_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # (batch_size, embed_dim)\n",
    "        x = x.unsqueeze(1)  # (batch_size, 1, embed_dim)\n",
    "        x = x.transpose(0, 1)  # (sequence_length=1, batch_size, embed_dim)\n",
    "        \n",
    "        for layer, layer_norm in zip(self.transformer_layers, self.layer_norms):\n",
    "            residual = x\n",
    "            x = layer(x)  # Transformer layer\n",
    "            x = self.dropout(x)\n",
    "            x = layer_norm(x + residual)  # 残差连接 + Layer Normalization\n",
    "        \n",
    "        x = x.squeeze(0)  # (batch_size, embed_dim)\n",
    "        return x  # 返回 (batch_size, embed_dim)\n",
    "\n",
    "# 联合 FT-Transformer 模型\n",
    "class DualFTTransformer(nn.Module):\n",
    "    def __init__(self, input_dim1, input_dim2, embed_dim, num_heads, num_layers, dropout=0.1):\n",
    "        super(DualFTTransformer, self).__init__()\n",
    "        self.transformer1 = FTTransformer(input_dim1, embed_dim, num_heads, num_layers, dropout)\n",
    "        self.transformer2 = FTTransformer(input_dim2, embed_dim, num_heads, num_layers, dropout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 2, 128),  # 拼接两个特征\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 1)  # 输出单个值\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.transformer1(x1)  # (batch_size, embed_dim)\n",
    "        x2 = self.transformer2(x2)  # (batch_size, embed_dim)\n",
    "        combined = torch.cat((x1, x2), dim=1)  # 拼接两个特征 (batch_size, embed_dim * 2)\n",
    "        return self.fc(combined).squeeze(1)  # 输出 (batch_size, )\n",
    "\n",
    "# 训练模型\n",
    "def train_model(model, train_loader1, train_loader2, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for (X1_batch, y1_batch), (X2_batch, _) in zip(train_loader1, train_loader2):\n",
    "        X1_batch, X2_batch, y1_batch = X1_batch.to(device), X2_batch.to(device), y1_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X1_batch, X2_batch)\n",
    "        loss = criterion(outputs, y1_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader1)\n",
    "\n",
    "# 评估模型\n",
    "def evaluate_model(model, test_loader1, test_loader2, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_pred_proba = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (X1_batch, y1_batch), (X2_batch, _) in zip(test_loader1, test_loader2):\n",
    "            X1_batch, X2_batch, y1_batch = X1_batch.to(device), X2_batch.to(device), y1_batch.to(device)\n",
    "            outputs = model(X1_batch, X2_batch)\n",
    "            loss = criterion(outputs, y1_batch)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            probs = torch.sigmoid(outputs)\n",
    "\n",
    "            y_true.extend(y1_batch.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_pred_proba.extend(probs.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred_proba)\n",
    "\n",
    "    return total_loss / len(test_loader1), accuracy, precision, recall, f1, auc\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    file_path1 = 'cleaned_aki_data1.csv'\n",
    "    file_path2 = 'cleaned_aki_data2.csv'\n",
    "    target_column = 'match_flag'\n",
    "\n",
    "    # 加载两个文件的数据\n",
    "    train_loader1, test_loader1 = load_data(file_path1, target_column)\n",
    "    train_loader2, test_loader2 = load_data(file_path2, target_column)\n",
    "\n",
    "    # 模型参数\n",
    "    input_dim1 = next(iter(train_loader1))[0].shape[1]\n",
    "    input_dim2 = next(iter(train_loader2))[0].shape[1]\n",
    "    embed_dim = 32  # 增加宽度\n",
    "    num_heads = 8    # 增加多头注意力机制\n",
    "    num_layers = 2   # 增加深度\n",
    "    dropout = 0.1\n",
    "    epochs = 30\n",
    "\n",
    "    # 模型初始化\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = DualFTTransformer(input_dim1, input_dim2, embed_dim, num_heads, num_layers, dropout).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)  # 学习率调度器\n",
    "\n",
    "    # 训练和评估\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_model(model, train_loader1, train_loader2, criterion, optimizer, device)\n",
    "        val_loss, accuracy, precision, recall, f1, auc = evaluate_model(model, test_loader1, test_loader2, criterion, device)\n",
    "        \n",
    "        # 更新学习率\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}:\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc73d8b6-b187-4e5a-b3b4-53b62131a8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Train Loss: 0.6934, Val Loss: 0.6931\n",
      "Accuracy: 0.5000, Precision: 0.0000, Recall: 0.0000, F1: 0.0000, AUC: 0.4988\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 159\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 159\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 148\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# 训练和评估\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m--> 148\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m     val_loss, accuracy, precision, recall, f1, auc \u001b[38;5;241m=\u001b[39m evaluate_model(model, test_loader, criterion, device)\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;66;03m# 更新学习率\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 84\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     82\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     83\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 84\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# 数据预处理\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# 加载数据\n",
    "def load_data(file_path, target_column, batch_size=64):\n",
    "    df = pd.read_csv(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    # 将标签转换为 torch.long 类型\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "    test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# SwinLSTM 模型\n",
    "class SwinLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_layers, hidden_dim, dropout=0.1):\n",
    "        super(SwinLSTM, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        \n",
    "        # Swin Transformer 模块\n",
    "        self.swin_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        # LSTM 模块\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 2)  # 输出维度改为 2（二分类问题）\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 嵌入层\n",
    "        x = self.embedding(x)  # (batch_size, embed_dim)\n",
    "        x = x.unsqueeze(1)  # (batch_size, 1, embed_dim)\n",
    "        \n",
    "        # Swin Transformer\n",
    "        x = x.transpose(0, 1)  # (sequence_length=1, batch_size, embed_dim)\n",
    "        x = self.swin_transformer(x)  # (sequence_length=1, batch_size, embed_dim)\n",
    "        x = x.transpose(0, 1)  # (batch_size, 1, embed_dim)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, _ = self.lstm(x)  # (batch_size, 1, hidden_dim)\n",
    "        lstm_out = lstm_out.squeeze(1)  # (batch_size, hidden_dim)\n",
    "        \n",
    "        # 全连接层\n",
    "        return self.fc(lstm_out)  # 输出 (batch_size, 2)\n",
    "\n",
    "# 训练模型\n",
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# 评估模型\n",
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_pred_proba = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 获取预测类别和概率\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]  # 取正类的概率\n",
    "            preds = torch.argmax(outputs, dim=1)  # 取预测类别\n",
    "\n",
    "            y_true.extend(y_batch.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_pred_proba.extend(probs.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred_proba) if len(set(y_true)) > 1 else 0.0\n",
    "\n",
    "    return total_loss / len(test_loader), accuracy, precision, recall, f1, auc\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    file_path = 'cleaned_aki_data4.csv'  # 仅使用 data1.csv\n",
    "    target_column = 'match_flag'\n",
    "\n",
    "    # 加载数据\n",
    "    train_loader, test_loader = load_data(file_path, target_column)\n",
    "\n",
    "    # 模型参数\n",
    "    input_dim = next(iter(train_loader))[0].shape[1]\n",
    "    embed_dim = 128\n",
    "    num_heads = 8\n",
    "    num_layers = 8\n",
    "    hidden_dim = 128\n",
    "    dropout = 0.3\n",
    "    epochs = 15\n",
    "\n",
    "    # 模型初始化\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = SwinLSTM(input_dim, embed_dim, num_heads, num_layers, hidden_dim, dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()  # 使用交叉熵损失\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)  # 学习率调度器\n",
    "\n",
    "    # 训练和评估\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_model(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, accuracy, precision, recall, f1, auc = evaluate_model(model, test_loader, criterion, device)\n",
    "        \n",
    "        # 更新学习率\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}:\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52942582-08d6-424d-8ff9-f709162bd272",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------第1轮训练-------\n",
      "训练损失: 282.0862\n",
      "测试损失: 112.6526, 准确率: 0.6692\n",
      "------第2轮训练-------\n",
      "训练损失: 259.1579\n",
      "测试损失: 110.2535, 准确率: 0.6773\n",
      "------第3轮训练-------\n",
      "训练损失: 254.4266\n",
      "测试损失: 107.8549, 准确率: 0.6902\n",
      "------第4轮训练-------\n",
      "训练损失: 251.1169\n",
      "测试损失: 106.6084, 准确率: 0.6943\n",
      "------第5轮训练-------\n",
      "训练损失: 248.6360\n",
      "测试损失: 106.8097, 准确率: 0.6919\n",
      "------第6轮训练-------\n",
      "训练损失: 247.1097\n",
      "测试损失: 105.7158, 准确率: 0.6999\n",
      "------第7轮训练-------\n",
      "训练损失: 246.0206\n",
      "测试损失: 107.0438, 准确率: 0.6905\n",
      "------第8轮训练-------\n",
      "训练损失: 244.9165\n",
      "测试损失: 105.7287, 准确率: 0.7000\n",
      "------第9轮训练-------\n",
      "训练损失: 243.4746\n",
      "测试损失: 104.7938, 准确率: 0.7015\n",
      "------第10轮训练-------\n",
      "训练损失: 242.3866\n",
      "测试损失: 104.8042, 准确率: 0.7027\n",
      "------第11轮训练-------\n",
      "训练损失: 241.2682\n",
      "测试损失: 104.4832, 准确率: 0.7013\n",
      "------第12轮训练-------\n",
      "训练损失: 239.9584\n",
      "测试损失: 103.7318, 准确率: 0.7040\n",
      "------第13轮训练-------\n",
      "训练损失: 239.0094\n",
      "测试损失: 103.2659, 准确率: 0.7055\n",
      "------第14轮训练-------\n",
      "训练损失: 238.6424\n",
      "测试损失: 104.6873, 准确率: 0.6999\n",
      "------第15轮训练-------\n",
      "训练损失: 237.4868\n",
      "测试损失: 103.2907, 准确率: 0.7027\n",
      "------第16轮训练-------\n",
      "训练损失: 236.5372\n",
      "测试损失: 103.1025, 准确率: 0.7004\n",
      "------第17轮训练-------\n",
      "训练损失: 235.6993\n",
      "测试损失: 102.8714, 准确率: 0.7057\n",
      "------第18轮训练-------\n",
      "训练损失: 234.7587\n",
      "测试损失: 104.3871, 准确率: 0.7023\n",
      "------第19轮训练-------\n",
      "训练损失: 233.1635\n",
      "测试损失: 102.5834, 准确率: 0.7034\n",
      "------第20轮训练-------\n",
      "训练损失: 232.1823\n",
      "测试损失: 101.8015, 准确率: 0.7037\n",
      "------第21轮训练-------\n",
      "训练损失: 230.7881\n",
      "测试损失: 101.8226, 准确率: 0.7048\n",
      "------第22轮训练-------\n",
      "训练损失: 229.6167\n",
      "测试损失: 101.4417, 准确率: 0.7055\n",
      "------第23轮训练-------\n",
      "训练损失: 229.1551\n",
      "测试损失: 101.4696, 准确率: 0.7017\n",
      "------第24轮训练-------\n",
      "训练损失: 227.7004\n",
      "测试损失: 101.4326, 准确率: 0.7053\n",
      "------第25轮训练-------\n",
      "训练损失: 226.7526\n",
      "测试损失: 100.2618, 准确率: 0.7103\n",
      "------第26轮训练-------\n",
      "训练损失: 223.8944\n",
      "测试损失: 101.6833, 准确率: 0.7044\n",
      "------第27轮训练-------\n",
      "训练损失: 223.4690\n",
      "测试损失: 99.9993, 准确率: 0.7080\n",
      "------第28轮训练-------\n",
      "训练损失: 222.6399\n",
      "测试损失: 100.3685, 准确率: 0.7127\n",
      "------第29轮训练-------\n",
      "训练损失: 221.8088\n",
      "测试损失: 99.2249, 准确率: 0.7145\n",
      "------第30轮训练-------\n",
      "训练损失: 220.6473\n",
      "测试损失: 101.8064, 准确率: 0.7119\n",
      "------第31轮训练-------\n",
      "训练损失: 219.7808\n",
      "测试损失: 99.2062, 准确率: 0.7143\n",
      "------第32轮训练-------\n",
      "训练损失: 217.7647\n",
      "测试损失: 99.8236, 准确率: 0.7093\n",
      "------第33轮训练-------\n",
      "训练损失: 217.3182\n",
      "测试损失: 98.4165, 准确率: 0.7159\n",
      "------第34轮训练-------\n",
      "训练损失: 216.0496\n",
      "测试损失: 98.2663, 准确率: 0.7094\n",
      "------第35轮训练-------\n",
      "训练损失: 214.2833\n",
      "测试损失: 98.9693, 准确率: 0.7108\n",
      "------第36轮训练-------\n",
      "训练损失: 213.3054\n",
      "测试损失: 96.9510, 准确率: 0.7192\n",
      "------第37轮训练-------\n",
      "训练损失: 212.1808\n",
      "测试损失: 97.5745, 准确率: 0.7206\n",
      "------第38轮训练-------\n",
      "训练损失: 210.8164\n",
      "测试损失: 97.1193, 准确率: 0.7231\n",
      "------第39轮训练-------\n",
      "训练损失: 209.6611\n",
      "测试损失: 97.9396, 准确率: 0.7182\n",
      "------第40轮训练-------\n",
      "训练损失: 208.2939\n",
      "测试损失: 96.7284, 准确率: 0.7179\n",
      "------第41轮训练-------\n",
      "训练损失: 207.5937\n",
      "测试损失: 95.7728, 准确率: 0.7238\n",
      "------第42轮训练-------\n",
      "训练损失: 205.9881\n",
      "测试损失: 96.8730, 准确率: 0.7212\n",
      "------第43轮训练-------\n",
      "训练损失: 205.4406\n",
      "测试损失: 96.1607, 准确率: 0.7206\n",
      "------第44轮训练-------\n",
      "训练损失: 204.5290\n",
      "测试损失: 95.8567, 准确率: 0.7243\n",
      "------第45轮训练-------\n",
      "训练损失: 203.5897\n",
      "测试损失: 94.3036, 准确率: 0.7238\n",
      "------第46轮训练-------\n",
      "训练损失: 201.7627\n",
      "测试损失: 96.9823, 准确率: 0.7210\n",
      "------第47轮训练-------\n",
      "训练损失: 200.9711\n",
      "测试损失: 96.8364, 准确率: 0.7184\n",
      "------第48轮训练-------\n",
      "训练损失: 200.9152\n",
      "测试损失: 96.7041, 准确率: 0.7151\n",
      "------第49轮训练-------\n",
      "训练损失: 198.9733\n",
      "测试损失: 94.2373, 准确率: 0.7234\n",
      "------第50轮训练-------\n",
      "训练损失: 198.1136\n",
      "测试损失: 95.4886, 准确率: 0.7260\n",
      "------第51轮训练-------\n",
      "训练损失: 196.4248\n",
      "测试损失: 94.2577, 准确率: 0.7239\n",
      "------第52轮训练-------\n",
      "训练损失: 195.9273\n",
      "测试损失: 95.9843, 准确率: 0.7260\n",
      "------第53轮训练-------\n",
      "训练损失: 195.4028\n",
      "测试损失: 94.1411, 准确率: 0.7239\n",
      "------第54轮训练-------\n",
      "训练损失: 194.4343\n",
      "测试损失: 94.4631, 准确率: 0.7159\n",
      "------第55轮训练-------\n",
      "训练损失: 194.1378\n",
      "测试损失: 92.6192, 准确率: 0.7293\n",
      "------第56轮训练-------\n",
      "训练损失: 192.3882\n",
      "测试损失: 93.2629, 准确率: 0.7308\n",
      "------第57轮训练-------\n",
      "训练损失: 191.6083\n",
      "测试损失: 95.8487, 准确率: 0.7275\n",
      "------第58轮训练-------\n",
      "训练损失: 191.2191\n",
      "测试损失: 95.3993, 准确率: 0.7228\n",
      "------第59轮训练-------\n",
      "训练损失: 190.0261\n",
      "测试损失: 92.8231, 准确率: 0.7337\n",
      "------第60轮训练-------\n",
      "训练损失: 189.0453\n",
      "测试损失: 91.9118, 准确率: 0.7315\n",
      "------第61轮训练-------\n",
      "训练损失: 188.0813\n",
      "测试损失: 92.2987, 准确率: 0.7330\n",
      "------第62轮训练-------\n",
      "训练损失: 188.0707\n",
      "测试损失: 92.4561, 准确率: 0.7317\n",
      "------第63轮训练-------\n",
      "训练损失: 187.5821\n",
      "测试损失: 93.5574, 准确率: 0.7347\n",
      "------第64轮训练-------\n",
      "训练损失: 186.6405\n",
      "测试损失: 91.6878, 准确率: 0.7316\n",
      "------第65轮训练-------\n",
      "训练损失: 185.3277\n",
      "测试损失: 90.4402, 准确率: 0.7381\n",
      "------第66轮训练-------\n",
      "训练损失: 184.4285\n",
      "测试损失: 93.8701, 准确率: 0.7272\n",
      "------第67轮训练-------\n",
      "训练损失: 185.2650\n",
      "测试损失: 90.5630, 准确率: 0.7332\n",
      "------第68轮训练-------\n",
      "训练损失: 182.7709\n",
      "测试损失: 90.6300, 准确率: 0.7321\n",
      "------第69轮训练-------\n",
      "训练损失: 183.1592\n",
      "测试损失: 90.0813, 准确率: 0.7334\n",
      "------第70轮训练-------\n",
      "训练损失: 182.1619\n",
      "测试损失: 90.7196, 准确率: 0.7292\n",
      "------第71轮训练-------\n",
      "训练损失: 182.4487\n",
      "测试损失: 90.1465, 准确率: 0.7415\n",
      "------第72轮训练-------\n",
      "训练损失: 180.6445\n",
      "测试损失: 91.8655, 准确率: 0.7323\n",
      "------第73轮训练-------\n",
      "训练损失: 179.6300\n",
      "测试损失: 91.3024, 准确率: 0.7332\n",
      "------第74轮训练-------\n",
      "训练损失: 179.9927\n",
      "测试损失: 91.1930, 准确率: 0.7419\n",
      "------第75轮训练-------\n",
      "训练损失: 179.8584\n",
      "测试损失: 90.2162, 准确率: 0.7362\n",
      "------第76轮训练-------\n",
      "训练损失: 177.9512\n",
      "测试损失: 90.1911, 准确率: 0.7382\n",
      "------第77轮训练-------\n",
      "训练损失: 178.4011\n",
      "测试损失: 92.0675, 准确率: 0.7336\n",
      "------第78轮训练-------\n",
      "训练损失: 177.0199\n",
      "测试损失: 91.6925, 准确率: 0.7340\n",
      "------第79轮训练-------\n",
      "训练损失: 176.5939\n",
      "测试损失: 90.7663, 准确率: 0.7348\n",
      "------第80轮训练-------\n",
      "训练损失: 175.2115\n",
      "测试损失: 91.8315, 准确率: 0.7403\n",
      "------第81轮训练-------\n",
      "训练损失: 175.5185\n",
      "测试损失: 90.4999, 准确率: 0.7348\n",
      "------第82轮训练-------\n",
      "训练损失: 175.5920\n",
      "测试损失: 97.9219, 准确率: 0.7395\n",
      "------第83轮训练-------\n",
      "训练损失: 174.5684\n",
      "测试损失: 90.5726, 准确率: 0.7378\n",
      "------第84轮训练-------\n",
      "训练损失: 173.9472\n",
      "测试损失: 89.4988, 准确率: 0.7372\n",
      "------第85轮训练-------\n",
      "训练损失: 173.0116\n",
      "测试损失: 91.0372, 准确率: 0.7332\n",
      "------第86轮训练-------\n",
      "训练损失: 172.7083\n",
      "测试损失: 87.5487, 准确率: 0.7422\n",
      "------第87轮训练-------\n",
      "训练损失: 171.9178\n",
      "测试损失: 88.4663, 准确率: 0.7417\n",
      "------第88轮训练-------\n",
      "训练损失: 171.9424\n",
      "测试损失: 88.4134, 准确率: 0.7416\n",
      "------第89轮训练-------\n",
      "训练损失: 171.0544\n",
      "测试损失: 88.1988, 准确率: 0.7441\n",
      "------第90轮训练-------\n",
      "训练损失: 171.7327\n",
      "测试损失: 89.5884, 准确率: 0.7408\n",
      "------第91轮训练-------\n",
      "训练损失: 169.4166\n",
      "测试损失: 89.8422, 准确率: 0.7377\n",
      "------第92轮训练-------\n",
      "训练损失: 169.7139\n",
      "测试损失: 90.4740, 准确率: 0.7408\n",
      "------第93轮训练-------\n",
      "训练损失: 170.1894\n",
      "测试损失: 88.0640, 准确率: 0.7438\n",
      "------第94轮训练-------\n",
      "训练损失: 169.0404\n",
      "测试损失: 89.3573, 准确率: 0.7471\n",
      "------第95轮训练-------\n",
      "训练损失: 168.0557\n",
      "测试损失: 88.7715, 准确率: 0.7445\n",
      "------第96轮训练-------\n",
      "训练损失: 168.2958\n",
      "测试损失: 86.7246, 准确率: 0.7458\n",
      "------第97轮训练-------\n",
      "训练损失: 168.7303\n",
      "测试损失: 89.4761, 准确率: 0.7403\n",
      "------第98轮训练-------\n",
      "训练损失: 167.3579\n",
      "测试损失: 89.9916, 准确率: 0.7387\n",
      "------第99轮训练-------\n",
      "训练损失: 167.4668\n",
      "测试损失: 87.0896, 准确率: 0.7438\n",
      "------第100轮训练-------\n",
      "训练损失: 166.6992\n",
      "测试损失: 87.7480, 准确率: 0.7457\n",
      "模型已保存到 cnn_model.pth\n",
      "总训练时间: 338.32 秒\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 检测设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 读取数据\n",
    "file_path = 'cleaned_aki_data2.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "X = df.iloc[:, :-1].values  # 特征\n",
    "Y = df['match_flag'].values  # 标签\n",
    "\n",
    "# 数据分割\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 转换为 PyTorch 张量\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # 添加通道维度\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)  # 转换为浮点型\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)  # 转换为浮点型\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# 定义 CNN 模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.model1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=2, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(1),\n",
    "            nn.Conv1d(16, 32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(1),\n",
    "            nn.Conv1d(32, 64, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(1),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.model2 = nn.Sequential(\n",
    "            nn.Linear(in_features=2560, out_features=128, bias=True),\n",
    "            nn.ReLU(),  # 使用 ReLU 代替 Sigmoid\n",
    "            nn.Linear(in_features=128, out_features=1, bias=True),  # 单个输出值\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.model1(input)\n",
    "        x = self.model2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 实例化模型并移动到设备\n",
    "cnn = CNN().to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n",
    "\n",
    "# 超参数设置\n",
    "epoch = 100\n",
    "\n",
    "# TensorBoard 日志记录\n",
    "writer = SummaryWriter('loss_train')\n",
    "start_time = time.time()\n",
    "\n",
    "# 开始训练\n",
    "for i in range(epoch):\n",
    "    print(f'------第{i + 1}轮训练-------')\n",
    "\n",
    "    cnn.train()\n",
    "    total_train_loss = 0\n",
    "    for batch_data, batch_labels in train_loader:\n",
    "        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = cnn(batch_data).squeeze(1)  # 去掉通道维度\n",
    "        loss = loss_fn(outputs, batch_labels)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    print(f'训练损失: {total_train_loss:.4f}')\n",
    "    writer.add_scalar('Train Loss', total_train_loss, i)\n",
    "\n",
    "    # 测试阶段\n",
    "    cnn.eval()\n",
    "    total_test_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in test_loader:\n",
    "            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "\n",
    "            outputs = cnn(batch_data).squeeze(1)  # 去掉通道维度\n",
    "            loss = loss_fn(outputs, batch_labels)\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            # 计算准确率\n",
    "            predictions = torch.sigmoid(outputs) > 0.5  # 转为概率并判断大于0.5\n",
    "            total_correct += (predictions == batch_labels).sum().item()\n",
    "\n",
    "    accuracy = total_correct / len(test_dataset)\n",
    "    print(f'测试损失: {total_test_loss:.4f}, 准确率: {accuracy:.4f}')\n",
    "    writer.add_scalar('Test Loss', total_test_loss, i)\n",
    "    writer.add_scalar('Accuracy', accuracy, i)\n",
    "\n",
    "# 保存模型\n",
    "model_path = 'cnn_model.pth'\n",
    "torch.save(cnn.state_dict(), model_path)\n",
    "print(f'模型已保存到 {model_path}')\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'总训练时间: {end_time - start_time:.2f} 秒')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b87026-8fa5-4e0e-a06a-b83a7d5e7e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829361ec-91ae-4a92-a7d9-2eeb1b8b0f94",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73ca5507-ba30-4d10-b434-6b893d3e45a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "特征数不能被序列长度整除，请调整 sequence_length。",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 152\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest model saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_lstm_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 125\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    123\u001b[0m sequence_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# 请根据特征数调整此参数\u001b[39;00m\n\u001b[0;32m    124\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/cleaned_microbiologyevents.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 125\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# 检查预处理后的数据形状\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX shape after preprocessing:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# 应为 (num_samples, sequence_length, input_size)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 37\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(df, target_column, sequence_length)\u001b[0m\n\u001b[0;32m     35\u001b[0m num_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_features \u001b[38;5;241m%\u001b[39m sequence_length \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m特征数不能被序列长度整除，请调整 sequence_length。\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m input_size \u001b[38;5;241m=\u001b[39m num_features \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m sequence_length\n\u001b[0;32m     39\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape(num_samples, sequence_length, input_size)\n",
      "\u001b[1;31mValueError\u001b[0m: 特征数不能被序列长度整除，请调整 sequence_length。"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 定义 LSTM 模型\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, num_layers, dropout, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_dim, num_layers=num_layers, \n",
    "                            batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]  # 取最后一个时间步的输出\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# 数据预处理\n",
    "def preprocess_data(df, target_column, sequence_length):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # 将数据转换为 LSTM 的输入格式 (batch_size, sequence_length, input_size)\n",
    "    num_samples = X.shape[0]\n",
    "    num_features = X.shape[1]\n",
    "    if num_features % sequence_length != 0:\n",
    "        raise ValueError(\"特征数不能被序列长度整除，请调整 sequence_length。\")\n",
    "    input_size = num_features // sequence_length\n",
    "    X = X.reshape(num_samples, sequence_length, input_size)\n",
    "    return X, y\n",
    "\n",
    "# 模型训练函数\n",
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 模型评估函数\n",
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]  # 取正类的概率\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    # 计算指标\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "    roc_auc = roc_auc_score(all_labels, all_probs) if len(set(all_labels)) > 1 else 0.0\n",
    "    return val_loss / len(test_loader), accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# Optuna 目标函数\n",
    "def objective(trial, X_train, y_train, X_test, y_test, train_loader, test_loader, device):\n",
    "    global best_accuracy, best_model_state\n",
    "\n",
    "    # 超参数搜索空间\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "\n",
    "    # 模型初始化\n",
    "    model = LSTMModel(input_size=X_train.shape[2], hidden_dim=hidden_dim, num_layers=num_layers, \n",
    "                      dropout=dropout, output_dim=2).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # 模型训练和评估\n",
    "    for epoch in range(10):  # 每次试验训练 10 个 epoch\n",
    "        train_model(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, accuracy, precision, recall, f1, roc_auc = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "        # 打印每轮指标\n",
    "        print(f\"Trial {trial.number} | Epoch {epoch + 1}: Loss={val_loss:.4f}, \"\n",
    "              f\"Accuracy={accuracy:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, \"\n",
    "              f\"F1={f1:.4f}, ROC_AUC={roc_auc:.4f}\")\n",
    "\n",
    "        # 保存最佳模型\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    global train_loader, test_loader, device, best_accuracy, best_model_state\n",
    "\n",
    "    # 初始化全局变量\n",
    "    best_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "\n",
    "    # 加载数据\n",
    "    target_column = 'match_flag'\n",
    "    sequence_length = 10  # 请根据特征数调整此参数\n",
    "    df = pd.read_csv('cleaned_aki_patients_labs_sampled_with_flags.csv')\n",
    "    X, y = preprocess_data(df, target_column, sequence_length)\n",
    "\n",
    "    # 检查预处理后的数据形状\n",
    "    print(\"X shape after preprocessing:\", X.shape)  # 应为 (num_samples, sequence_length, input_size)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    # 数据加载器\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "    test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # 贝叶斯优化\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_test, y_test, train_loader, test_loader, device), n_trials=50)\n",
    "\n",
    "    # 输出最佳参数\n",
    "    print(\"Best parameters:\", study.best_params)\n",
    "    print(\"Best accuracy:\", best_accuracy)\n",
    "\n",
    "    # 保存最佳模型\n",
    "    torch.save(best_model_state, \"best_lstm_model.pth\")\n",
    "    print(\"Best model saved as 'best_lstm_model.pth'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d362d8f-3bf0-4522-bdcc-5399555cc596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 09:41:46,882] A new study created in memory with name: no-name-ebdf5121-3127-443e-b046-7e55add0bb0a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape after preprocessing: (60000, 34, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.43228922254176383 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 | Epoch 1: Loss=0.6841, Accuracy=0.5559, Precision=0.5526, Recall=0.5876, F1=0.5696, ROC_AUC=0.5782\n",
      "Trial 0 | Epoch 2: Loss=0.6842, Accuracy=0.5585, Precision=0.5544, Recall=0.5967, F1=0.5747, ROC_AUC=0.5796\n",
      "Trial 0 | Epoch 3: Loss=0.6838, Accuracy=0.5598, Precision=0.5539, Recall=0.6141, F1=0.5825, ROC_AUC=0.5818\n",
      "Trial 0 | Epoch 4: Loss=0.6832, Accuracy=0.5590, Precision=0.5541, Recall=0.6042, F1=0.5781, ROC_AUC=0.5834\n",
      "Trial 0 | Epoch 5: Loss=0.6826, Accuracy=0.5619, Precision=0.5592, Recall=0.5848, F1=0.5717, ROC_AUC=0.5851\n",
      "Trial 0 | Epoch 6: Loss=0.6847, Accuracy=0.5610, Precision=0.5629, Recall=0.5457, F1=0.5542, ROC_AUC=0.5859\n",
      "Trial 0 | Epoch 7: Loss=0.6820, Accuracy=0.5634, Precision=0.5622, Recall=0.5732, F1=0.5677, ROC_AUC=0.5889\n",
      "Trial 0 | Epoch 8: Loss=0.6807, Accuracy=0.5672, Precision=0.5613, Recall=0.6156, F1=0.5872, ROC_AUC=0.5915\n",
      "Trial 0 | Epoch 9: Loss=0.6818, Accuracy=0.5623, Precision=0.5757, Recall=0.4738, F1=0.5198, ROC_AUC=0.5933\n",
      "Trial 0 | Epoch 10: Loss=0.6800, Accuracy=0.5692, Precision=0.5615, Recall=0.6319, F1=0.5946, ROC_AUC=0.5935\n",
      "Trial 0 | Epoch 11: Loss=0.6795, Accuracy=0.5666, Precision=0.5688, Recall=0.5506, F1=0.5595, ROC_AUC=0.5954\n",
      "Trial 0 | Epoch 12: Loss=0.6795, Accuracy=0.5656, Precision=0.5696, Recall=0.5367, F1=0.5527, ROC_AUC=0.5960\n",
      "Trial 0 | Epoch 13: Loss=0.6793, Accuracy=0.5668, Precision=0.5679, Recall=0.5591, F1=0.5635, ROC_AUC=0.5965\n",
      "Trial 0 | Epoch 14: Loss=0.6797, Accuracy=0.5653, Precision=0.5696, Recall=0.5346, F1=0.5515, ROC_AUC=0.5971\n",
      "Trial 0 | Epoch 15: Loss=0.6801, Accuracy=0.5745, Precision=0.5650, Recall=0.6476, F1=0.6035, ROC_AUC=0.5963\n",
      "Trial 0 | Epoch 16: Loss=0.6786, Accuracy=0.5716, Precision=0.5719, Recall=0.5698, F1=0.5708, ROC_AUC=0.5987\n",
      "Trial 0 | Epoch 17: Loss=0.6776, Accuracy=0.5704, Precision=0.5677, Recall=0.5908, F1=0.5790, ROC_AUC=0.5997\n",
      "Trial 0 | Epoch 18: Loss=0.6780, Accuracy=0.5712, Precision=0.5749, Recall=0.5463, F1=0.5602, ROC_AUC=0.6009\n",
      "Trial 0 | Epoch 19: Loss=0.6782, Accuracy=0.5760, Precision=0.5640, Recall=0.6700, F1=0.6124, ROC_AUC=0.5992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 09:46:32,299] Trial 0 finished with value: 0.5747222222222222 and parameters: {'hidden_dim': 310, 'num_layers': 1, 'dropout': 0.43228922254176383, 'lr': 4.687153088813999e-05}. Best is trial 0 with value: 0.5747222222222222.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 | Epoch 20: Loss=0.6763, Accuracy=0.5747, Precision=0.5652, Recall=0.6481, F1=0.6038, ROC_AUC=0.6014\n",
      "Trial 1 | Epoch 1: Loss=0.6923, Accuracy=0.4989, Precision=0.4994, Recall=0.9877, F1=0.6634, ROC_AUC=0.5293\n",
      "Trial 1 | Epoch 2: Loss=0.6886, Accuracy=0.5491, Precision=0.5525, Recall=0.5167, F1=0.5340, ROC_AUC=0.5551\n",
      "Trial 1 | Epoch 3: Loss=0.6795, Accuracy=0.5683, Precision=0.5804, Recall=0.4928, F1=0.5330, ROC_AUC=0.6004\n",
      "Trial 1 | Epoch 4: Loss=0.6768, Accuracy=0.5784, Precision=0.5753, Recall=0.5992, F1=0.5870, ROC_AUC=0.6055\n",
      "Trial 1 | Epoch 5: Loss=0.6731, Accuracy=0.5827, Precision=0.5834, Recall=0.5786, F1=0.5810, ROC_AUC=0.6156\n",
      "Trial 1 | Epoch 6: Loss=0.6718, Accuracy=0.5867, Precision=0.5790, Recall=0.6358, F1=0.6060, ROC_AUC=0.6184\n",
      "Trial 1 | Epoch 7: Loss=0.6764, Accuracy=0.5785, Precision=0.5975, Recall=0.4810, F1=0.5330, ROC_AUC=0.6107\n",
      "Trial 1 | Epoch 8: Loss=0.6711, Accuracy=0.5916, Precision=0.5914, Recall=0.5928, F1=0.5921, ROC_AUC=0.6187\n",
      "Trial 1 | Epoch 9: Loss=0.6744, Accuracy=0.5849, Precision=0.5918, Recall=0.5470, F1=0.5685, ROC_AUC=0.6133\n",
      "Trial 1 | Epoch 10: Loss=0.6658, Accuracy=0.5934, Precision=0.5932, Recall=0.5949, F1=0.5940, ROC_AUC=0.6313\n",
      "Trial 1 | Epoch 11: Loss=0.6707, Accuracy=0.5869, Precision=0.5776, Recall=0.6469, F1=0.6103, ROC_AUC=0.6169\n",
      "Trial 1 | Epoch 12: Loss=0.6507, Accuracy=0.6066, Precision=0.5969, Recall=0.6563, F1=0.6252, ROC_AUC=0.6553\n",
      "Trial 1 | Epoch 13: Loss=0.6571, Accuracy=0.5981, Precision=0.5849, Recall=0.6760, F1=0.6272, ROC_AUC=0.6459\n",
      "Trial 1 | Epoch 14: Loss=0.6468, Accuracy=0.6073, Precision=0.5943, Recall=0.6760, F1=0.6325, ROC_AUC=0.6576\n",
      "Trial 1 | Epoch 15: Loss=0.6316, Accuracy=0.6247, Precision=0.6187, Recall=0.6501, F1=0.6340, ROC_AUC=0.6806\n",
      "Trial 1 | Epoch 16: Loss=0.6252, Accuracy=0.6253, Precision=0.6220, Recall=0.6389, F1=0.6303, ROC_AUC=0.6904\n",
      "Trial 1 | Epoch 17: Loss=0.6222, Accuracy=0.6369, Precision=0.6228, Recall=0.6943, F1=0.6566, ROC_AUC=0.6987\n",
      "Trial 1 | Epoch 18: Loss=0.6062, Accuracy=0.6422, Precision=0.6527, Recall=0.6077, F1=0.6294, ROC_AUC=0.7154\n",
      "Trial 1 | Epoch 19: Loss=0.5950, Accuracy=0.6531, Precision=0.6333, Recall=0.7272, F1=0.6770, ROC_AUC=0.7292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 09:56:40,593] Trial 1 finished with value: 0.6596111111111111 and parameters: {'hidden_dim': 191, 'num_layers': 3, 'dropout': 0.39613443858322284, 'lr': 0.0008705189828171966}. Best is trial 1 with value: 0.6596111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 | Epoch 20: Loss=0.5841, Accuracy=0.6596, Precision=0.6577, Recall=0.6658, F1=0.6617, ROC_AUC=0.7424\n",
      "Trial 2 | Epoch 1: Loss=0.6852, Accuracy=0.5568, Precision=0.5488, Recall=0.6389, F1=0.5904, ROC_AUC=0.5775\n",
      "Trial 2 | Epoch 2: Loss=0.6828, Accuracy=0.5611, Precision=0.5599, Recall=0.5709, F1=0.5653, ROC_AUC=0.5842\n",
      "Trial 2 | Epoch 3: Loss=0.6837, Accuracy=0.5583, Precision=0.5682, Recall=0.4856, F1=0.5236, ROC_AUC=0.5849\n",
      "Trial 2 | Epoch 4: Loss=0.6823, Accuracy=0.5642, Precision=0.5778, Recall=0.4770, F1=0.5226, ROC_AUC=0.5881\n",
      "Trial 2 | Epoch 5: Loss=0.6818, Accuracy=0.5667, Precision=0.5610, Recall=0.6136, F1=0.5861, ROC_AUC=0.5879\n",
      "Trial 2 | Epoch 6: Loss=0.6820, Accuracy=0.5631, Precision=0.5564, Recall=0.6222, F1=0.5875, ROC_AUC=0.5889\n",
      "Trial 2 | Epoch 7: Loss=0.6802, Accuracy=0.5696, Precision=0.5660, Recall=0.5970, F1=0.5811, ROC_AUC=0.5920\n",
      "Trial 2 | Epoch 8: Loss=0.6828, Accuracy=0.5642, Precision=0.5541, Recall=0.6582, F1=0.6017, ROC_AUC=0.5861\n",
      "Trial 2 | Epoch 9: Loss=0.6797, Accuracy=0.5694, Precision=0.5642, Recall=0.6104, F1=0.5864, ROC_AUC=0.5935\n",
      "Trial 2 | Epoch 10: Loss=0.6786, Accuracy=0.5700, Precision=0.5725, Recall=0.5524, F1=0.5623, ROC_AUC=0.5971\n",
      "Trial 2 | Epoch 11: Loss=0.6790, Accuracy=0.5733, Precision=0.5737, Recall=0.5703, F1=0.5720, ROC_AUC=0.5975\n",
      "Trial 2 | Epoch 12: Loss=0.6777, Accuracy=0.5753, Precision=0.5671, Recall=0.6370, F1=0.6000, ROC_AUC=0.6005\n",
      "Trial 2 | Epoch 13: Loss=0.6780, Accuracy=0.5703, Precision=0.5816, Recall=0.5013, F1=0.5385, ROC_AUC=0.6009\n",
      "Trial 2 | Epoch 14: Loss=0.6776, Accuracy=0.5732, Precision=0.5746, Recall=0.5642, F1=0.5693, ROC_AUC=0.6015\n",
      "Trial 2 | Epoch 15: Loss=0.6763, Accuracy=0.5766, Precision=0.5643, Recall=0.6722, F1=0.6135, ROC_AUC=0.6031\n",
      "Trial 2 | Epoch 16: Loss=0.6746, Accuracy=0.5782, Precision=0.5691, Recall=0.6437, F1=0.6041, ROC_AUC=0.6076\n",
      "Trial 2 | Epoch 17: Loss=0.6743, Accuracy=0.5786, Precision=0.5689, Recall=0.6483, F1=0.6060, ROC_AUC=0.6096\n",
      "Trial 2 | Epoch 18: Loss=0.6715, Accuracy=0.5807, Precision=0.5727, Recall=0.6354, F1=0.6024, ROC_AUC=0.6132\n",
      "Trial 2 | Epoch 19: Loss=0.6731, Accuracy=0.5791, Precision=0.5592, Recall=0.7469, F1=0.6396, ROC_AUC=0.6134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 11:00:40,126] Trial 2 finished with value: 0.5827222222222223 and parameters: {'hidden_dim': 476, 'num_layers': 5, 'dropout': 0.3893086381720563, 'lr': 3.461937397726362e-05}. Best is trial 1 with value: 0.6596111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 | Epoch 20: Loss=0.6709, Accuracy=0.5827, Precision=0.5750, Recall=0.6343, F1=0.6032, ROC_AUC=0.6124\n",
      "Trial 3 | Epoch 1: Loss=0.6840, Accuracy=0.5586, Precision=0.5532, Recall=0.6098, F1=0.5801, ROC_AUC=0.5809\n",
      "Trial 3 | Epoch 2: Loss=0.6826, Accuracy=0.5652, Precision=0.5771, Recall=0.4876, F1=0.5286, ROC_AUC=0.5881\n",
      "Trial 3 | Epoch 3: Loss=0.6827, Accuracy=0.5690, Precision=0.5603, Recall=0.6407, F1=0.5978, ROC_AUC=0.5908\n",
      "Trial 3 | Epoch 4: Loss=0.6792, Accuracy=0.5717, Precision=0.5785, Recall=0.5286, F1=0.5524, ROC_AUC=0.5974\n",
      "Trial 3 | Epoch 5: Loss=0.6771, Accuracy=0.5744, Precision=0.5781, Recall=0.5512, F1=0.5643, ROC_AUC=0.6023\n",
      "Trial 3 | Epoch 6: Loss=0.6792, Accuracy=0.5706, Precision=0.5544, Recall=0.7192, F1=0.6261, ROC_AUC=0.5983\n",
      "Trial 3 | Epoch 7: Loss=0.6730, Accuracy=0.5783, Precision=0.5696, Recall=0.6410, F1=0.6032, ROC_AUC=0.6123\n",
      "Trial 3 | Epoch 8: Loss=0.6760, Accuracy=0.5797, Precision=0.5597, Recall=0.7469, F1=0.6399, ROC_AUC=0.6146\n",
      "Trial 3 | Epoch 9: Loss=0.6690, Accuracy=0.5898, Precision=0.5771, Recall=0.6726, F1=0.6212, ROC_AUC=0.6259\n",
      "Trial 3 | Epoch 10: Loss=0.6663, Accuracy=0.5896, Precision=0.5957, Recall=0.5578, F1=0.5761, ROC_AUC=0.6283\n",
      "Trial 3 | Epoch 11: Loss=0.6653, Accuracy=0.5934, Precision=0.5994, Recall=0.5631, F1=0.5807, ROC_AUC=0.6321\n",
      "Trial 3 | Epoch 12: Loss=0.6643, Accuracy=0.5947, Precision=0.5846, Recall=0.6543, F1=0.6175, ROC_AUC=0.6341\n",
      "Trial 3 | Epoch 13: Loss=0.6618, Accuracy=0.5975, Precision=0.5933, Recall=0.6199, F1=0.6063, ROC_AUC=0.6371\n",
      "Trial 3 | Epoch 14: Loss=0.6626, Accuracy=0.5936, Precision=0.5906, Recall=0.6100, F1=0.6001, ROC_AUC=0.6369\n",
      "Trial 3 | Epoch 15: Loss=0.6607, Accuracy=0.5976, Precision=0.6127, Recall=0.5306, F1=0.5687, ROC_AUC=0.6418\n",
      "Trial 3 | Epoch 16: Loss=0.6582, Accuracy=0.5979, Precision=0.5921, Recall=0.6296, F1=0.6102, ROC_AUC=0.6434\n",
      "Trial 3 | Epoch 17: Loss=0.6549, Accuracy=0.6023, Precision=0.5968, Recall=0.6308, F1=0.6133, ROC_AUC=0.6495\n",
      "Trial 3 | Epoch 18: Loss=0.6518, Accuracy=0.6061, Precision=0.6120, Recall=0.5793, F1=0.5952, ROC_AUC=0.6564\n",
      "Trial 3 | Epoch 19: Loss=0.6519, Accuracy=0.6054, Precision=0.6046, Recall=0.6097, F1=0.6071, ROC_AUC=0.6549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 11:35:26,164] Trial 3 finished with value: 0.6130555555555556 and parameters: {'hidden_dim': 508, 'num_layers': 3, 'dropout': 0.3510048797938311, 'lr': 5.019442737680919e-05}. Best is trial 1 with value: 0.6596111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 | Epoch 20: Loss=0.6488, Accuracy=0.6131, Precision=0.6180, Recall=0.5921, F1=0.6048, ROC_AUC=0.6638\n",
      "Trial 4 | Epoch 1: Loss=0.6838, Accuracy=0.5644, Precision=0.5552, Recall=0.6479, F1=0.5980, ROC_AUC=0.5841\n",
      "Trial 4 | Epoch 2: Loss=0.6784, Accuracy=0.5754, Precision=0.5760, Recall=0.5718, F1=0.5739, ROC_AUC=0.6019\n",
      "Trial 4 | Epoch 3: Loss=0.6804, Accuracy=0.5703, Precision=0.5488, Recall=0.7899, F1=0.6477, ROC_AUC=0.6145\n",
      "Trial 4 | Epoch 4: Loss=0.6690, Accuracy=0.5923, Precision=0.5876, Recall=0.6192, F1=0.6030, ROC_AUC=0.6299\n",
      "Trial 4 | Epoch 5: Loss=0.6610, Accuracy=0.5960, Precision=0.6009, Recall=0.5717, F1=0.5859, ROC_AUC=0.6401\n",
      "Trial 4 | Epoch 6: Loss=0.6652, Accuracy=0.5921, Precision=0.5951, Recall=0.5762, F1=0.5855, ROC_AUC=0.6325\n",
      "Trial 4 | Epoch 7: Loss=0.6433, Accuracy=0.6233, Precision=0.6119, Recall=0.6739, F1=0.6414, ROC_AUC=0.6749\n",
      "Trial 4 | Epoch 8: Loss=0.6304, Accuracy=0.6282, Precision=0.6380, Recall=0.5924, F1=0.6144, ROC_AUC=0.6895\n",
      "Trial 4 | Epoch 9: Loss=0.5989, Accuracy=0.6563, Precision=0.6342, Recall=0.7386, F1=0.6824, ROC_AUC=0.7313\n",
      "Trial 4 | Epoch 10: Loss=0.5767, Accuracy=0.6745, Precision=0.6791, Recall=0.6616, F1=0.6702, ROC_AUC=0.7558\n",
      "Trial 4 | Epoch 11: Loss=0.5306, Accuracy=0.6959, Precision=0.6886, Recall=0.7152, F1=0.7017, ROC_AUC=0.7910\n",
      "Trial 4 | Epoch 12: Loss=0.4949, Accuracy=0.7148, Precision=0.7237, Recall=0.6949, F1=0.7090, ROC_AUC=0.8222\n",
      "Trial 4 | Epoch 13: Loss=0.4876, Accuracy=0.7176, Precision=0.7168, Recall=0.7193, F1=0.7181, ROC_AUC=0.8296\n",
      "Trial 4 | Epoch 14: Loss=0.4755, Accuracy=0.7256, Precision=0.7255, Recall=0.7258, F1=0.7256, ROC_AUC=0.8414\n",
      "Trial 4 | Epoch 15: Loss=0.4699, Accuracy=0.7274, Precision=0.7325, Recall=0.7163, F1=0.7243, ROC_AUC=0.8470\n",
      "Trial 4 | Epoch 16: Loss=0.4646, Accuracy=0.7297, Precision=0.7300, Recall=0.7292, F1=0.7296, ROC_AUC=0.8525\n",
      "Trial 4 | Epoch 17: Loss=0.4731, Accuracy=0.7314, Precision=0.7201, Recall=0.7572, F1=0.7382, ROC_AUC=0.8563\n",
      "Trial 4 | Epoch 18: Loss=0.4857, Accuracy=0.7313, Precision=0.7344, Recall=0.7249, F1=0.7296, ROC_AUC=0.8551\n",
      "Trial 4 | Epoch 19: Loss=0.4704, Accuracy=0.7298, Precision=0.7333, Recall=0.7223, F1=0.7278, ROC_AUC=0.8567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 12:25:40,084] Trial 4 finished with value: 0.7318888888888889 and parameters: {'hidden_dim': 498, 'num_layers': 4, 'dropout': 0.12580597539344698, 'lr': 0.0003222969336076591}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 | Epoch 20: Loss=0.4710, Accuracy=0.7319, Precision=0.7411, Recall=0.7128, F1=0.7267, ROC_AUC=0.8603\n",
      "Trial 5 | Epoch 1: Loss=0.6844, Accuracy=0.5622, Precision=0.5559, Recall=0.6182, F1=0.5854, ROC_AUC=0.5823\n",
      "Trial 5 | Epoch 2: Loss=0.6818, Accuracy=0.5612, Precision=0.5550, Recall=0.6179, F1=0.5848, ROC_AUC=0.5863\n",
      "Trial 5 | Epoch 3: Loss=0.6824, Accuracy=0.5645, Precision=0.5780, Recall=0.4782, F1=0.5234, ROC_AUC=0.5919\n",
      "Trial 5 | Epoch 4: Loss=0.6797, Accuracy=0.5719, Precision=0.5654, Recall=0.6213, F1=0.5921, ROC_AUC=0.5949\n",
      "Trial 5 | Epoch 5: Loss=0.6802, Accuracy=0.5694, Precision=0.5641, Recall=0.6114, F1=0.5868, ROC_AUC=0.5922\n",
      "Trial 5 | Epoch 6: Loss=0.6784, Accuracy=0.5726, Precision=0.5669, Recall=0.6157, F1=0.5903, ROC_AUC=0.5978\n",
      "Trial 5 | Epoch 7: Loss=0.6772, Accuracy=0.5711, Precision=0.5685, Recall=0.5900, F1=0.5790, ROC_AUC=0.5996\n",
      "Trial 5 | Epoch 8: Loss=0.6772, Accuracy=0.5747, Precision=0.5659, Recall=0.6413, F1=0.6013, ROC_AUC=0.6000\n",
      "Trial 5 | Epoch 9: Loss=0.6759, Accuracy=0.5768, Precision=0.5696, Recall=0.6286, F1=0.5976, ROC_AUC=0.6054\n",
      "Trial 5 | Epoch 10: Loss=0.6747, Accuracy=0.5800, Precision=0.5630, Recall=0.7147, F1=0.6298, ROC_AUC=0.6099\n",
      "Trial 5 | Epoch 11: Loss=0.6729, Accuracy=0.5847, Precision=0.5728, Recall=0.6661, F1=0.6159, ROC_AUC=0.6139\n",
      "Trial 5 | Epoch 12: Loss=0.6711, Accuracy=0.5857, Precision=0.5772, Recall=0.6403, F1=0.6071, ROC_AUC=0.6178\n",
      "Trial 5 | Epoch 13: Loss=0.6713, Accuracy=0.5846, Precision=0.5799, Recall=0.6137, F1=0.5963, ROC_AUC=0.6170\n",
      "Trial 5 | Epoch 14: Loss=0.6679, Accuracy=0.5876, Precision=0.5953, Recall=0.5468, F1=0.5700, ROC_AUC=0.6243\n",
      "Trial 5 | Epoch 15: Loss=0.6666, Accuracy=0.5872, Precision=0.5848, Recall=0.6017, F1=0.5931, ROC_AUC=0.6256\n",
      "Trial 5 | Epoch 16: Loss=0.6648, Accuracy=0.5927, Precision=0.5880, Recall=0.6190, F1=0.6031, ROC_AUC=0.6291\n",
      "Trial 5 | Epoch 17: Loss=0.6653, Accuracy=0.5942, Precision=0.5984, Recall=0.5728, F1=0.5853, ROC_AUC=0.6348\n",
      "Trial 5 | Epoch 18: Loss=0.6617, Accuracy=0.5948, Precision=0.5963, Recall=0.5874, F1=0.5918, ROC_AUC=0.6370\n",
      "Trial 5 | Epoch 19: Loss=0.6561, Accuracy=0.6002, Precision=0.5960, Recall=0.6221, F1=0.6088, ROC_AUC=0.6469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 12:42:47,923] Trial 5 finished with value: 0.6012777777777778 and parameters: {'hidden_dim': 221, 'num_layers': 4, 'dropout': 0.24021684930426815, 'lr': 7.850183548074455e-05}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 | Epoch 20: Loss=0.6540, Accuracy=0.6013, Precision=0.5993, Recall=0.6113, F1=0.6052, ROC_AUC=0.6491\n",
      "Trial 6 | Epoch 1: Loss=0.6848, Accuracy=0.5584, Precision=0.5620, Recall=0.5299, F1=0.5455, ROC_AUC=0.5791\n",
      "Trial 6 | Epoch 2: Loss=0.6819, Accuracy=0.5598, Precision=0.5549, Recall=0.6046, F1=0.5786, ROC_AUC=0.5864\n",
      "Trial 6 | Epoch 3: Loss=0.6833, Accuracy=0.5584, Precision=0.5880, Recall=0.3900, F1=0.4690, ROC_AUC=0.5898\n",
      "Trial 6 | Epoch 4: Loss=0.6834, Accuracy=0.5680, Precision=0.5583, Recall=0.6517, F1=0.6014, ROC_AUC=0.5909\n",
      "Trial 6 | Epoch 5: Loss=0.6828, Accuracy=0.5714, Precision=0.5695, Recall=0.5856, F1=0.5774, ROC_AUC=0.5942\n",
      "Trial 6 | Epoch 6: Loss=0.6799, Accuracy=0.5687, Precision=0.5697, Recall=0.5614, F1=0.5655, ROC_AUC=0.5953\n",
      "Trial 6 | Epoch 7: Loss=0.6777, Accuracy=0.5733, Precision=0.5715, Recall=0.5856, F1=0.5785, ROC_AUC=0.6006\n",
      "Trial 6 | Epoch 8: Loss=0.6778, Accuracy=0.5742, Precision=0.5614, Recall=0.6789, F1=0.6146, ROC_AUC=0.6023\n",
      "Trial 6 | Epoch 9: Loss=0.6754, Accuracy=0.5735, Precision=0.5639, Recall=0.6486, F1=0.6033, ROC_AUC=0.6062\n",
      "Trial 6 | Epoch 10: Loss=0.6739, Accuracy=0.5819, Precision=0.5735, Recall=0.6393, F1=0.6046, ROC_AUC=0.6082\n",
      "Trial 6 | Epoch 11: Loss=0.6754, Accuracy=0.5796, Precision=0.5786, Recall=0.5860, F1=0.5823, ROC_AUC=0.6100\n",
      "Trial 6 | Epoch 12: Loss=0.6705, Accuracy=0.5798, Precision=0.5736, Recall=0.6218, F1=0.5967, ROC_AUC=0.6172\n",
      "Trial 6 | Epoch 13: Loss=0.6691, Accuracy=0.5859, Precision=0.5850, Recall=0.5912, F1=0.5881, ROC_AUC=0.6229\n",
      "Trial 6 | Epoch 14: Loss=0.6659, Accuracy=0.5927, Precision=0.5811, Recall=0.6641, F1=0.6198, ROC_AUC=0.6274\n",
      "Trial 6 | Epoch 15: Loss=0.6626, Accuracy=0.5970, Precision=0.5825, Recall=0.6846, F1=0.6294, ROC_AUC=0.6348\n",
      "Trial 6 | Epoch 16: Loss=0.6590, Accuracy=0.5959, Precision=0.5838, Recall=0.6680, F1=0.6231, ROC_AUC=0.6404\n",
      "Trial 6 | Epoch 17: Loss=0.6506, Accuracy=0.6017, Precision=0.5988, Recall=0.6161, F1=0.6073, ROC_AUC=0.6532\n",
      "Trial 6 | Epoch 18: Loss=0.6521, Accuracy=0.6046, Precision=0.5946, Recall=0.6569, F1=0.6242, ROC_AUC=0.6528\n",
      "Trial 6 | Epoch 19: Loss=0.6416, Accuracy=0.6198, Precision=0.6077, Recall=0.6762, F1=0.6401, ROC_AUC=0.6693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 13:14:47,354] Trial 6 finished with value: 0.6199444444444444 and parameters: {'hidden_dim': 312, 'num_layers': 5, 'dropout': 0.20959820405164598, 'lr': 7.73932864758439e-05}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 | Epoch 20: Loss=0.6341, Accuracy=0.6199, Precision=0.6098, Recall=0.6661, F1=0.6367, ROC_AUC=0.6801\n",
      "Trial 7 | Epoch 1: Loss=0.6868, Accuracy=0.5519, Precision=0.5464, Recall=0.6109, F1=0.5769, ROC_AUC=0.5715\n",
      "Trial 7 | Epoch 2: Loss=0.6836, Accuracy=0.5593, Precision=0.5685, Recall=0.4926, F1=0.5278, ROC_AUC=0.5851\n",
      "Trial 7 | Epoch 3: Loss=0.6817, Accuracy=0.5617, Precision=0.5612, Recall=0.5656, F1=0.5634, ROC_AUC=0.5880\n",
      "Trial 7 | Epoch 4: Loss=0.6814, Accuracy=0.5673, Precision=0.5644, Recall=0.5896, F1=0.5767, ROC_AUC=0.5908\n",
      "Trial 7 | Epoch 5: Loss=0.6798, Accuracy=0.5705, Precision=0.5680, Recall=0.5890, F1=0.5783, ROC_AUC=0.5946\n",
      "Trial 7 | Epoch 6: Loss=0.6793, Accuracy=0.5721, Precision=0.5648, Recall=0.6277, F1=0.5946, ROC_AUC=0.5959\n",
      "Trial 7 | Epoch 7: Loss=0.6784, Accuracy=0.5705, Precision=0.5689, Recall=0.5821, F1=0.5754, ROC_AUC=0.5983\n",
      "Trial 7 | Epoch 8: Loss=0.6780, Accuracy=0.5709, Precision=0.5613, Recall=0.6489, F1=0.6019, ROC_AUC=0.5996\n",
      "Trial 7 | Epoch 9: Loss=0.6780, Accuracy=0.5725, Precision=0.5628, Recall=0.6496, F1=0.6031, ROC_AUC=0.5994\n",
      "Trial 7 | Epoch 10: Loss=0.6781, Accuracy=0.5731, Precision=0.5582, Recall=0.7013, F1=0.6216, ROC_AUC=0.5998\n",
      "Trial 7 | Epoch 11: Loss=0.6777, Accuracy=0.5702, Precision=0.5777, Recall=0.5221, F1=0.5485, ROC_AUC=0.5995\n",
      "Trial 7 | Epoch 12: Loss=0.6763, Accuracy=0.5776, Precision=0.5649, Recall=0.6748, F1=0.6150, ROC_AUC=0.6026\n",
      "Trial 7 | Epoch 13: Loss=0.6766, Accuracy=0.5755, Precision=0.5679, Recall=0.6313, F1=0.5979, ROC_AUC=0.6025\n",
      "Trial 7 | Epoch 14: Loss=0.6774, Accuracy=0.5776, Precision=0.5623, Recall=0.7003, F1=0.6238, ROC_AUC=0.6036\n",
      "Trial 7 | Epoch 15: Loss=0.6754, Accuracy=0.5761, Precision=0.5745, Recall=0.5869, F1=0.5806, ROC_AUC=0.6059\n",
      "Trial 7 | Epoch 16: Loss=0.6749, Accuracy=0.5779, Precision=0.5690, Recall=0.6422, F1=0.6034, ROC_AUC=0.6058\n",
      "Trial 7 | Epoch 17: Loss=0.6745, Accuracy=0.5789, Precision=0.5727, Recall=0.6221, F1=0.5964, ROC_AUC=0.6074\n",
      "Trial 7 | Epoch 18: Loss=0.6739, Accuracy=0.5773, Precision=0.5725, Recall=0.6107, F1=0.5910, ROC_AUC=0.6076\n",
      "Trial 7 | Epoch 19: Loss=0.6725, Accuracy=0.5804, Precision=0.5730, Recall=0.6309, F1=0.6006, ROC_AUC=0.6107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 16:25:07,693] Trial 7 finished with value: 0.5812222222222222 and parameters: {'hidden_dim': 197, 'num_layers': 3, 'dropout': 0.1353917276160536, 'lr': 5.253148203847825e-05}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 | Epoch 20: Loss=0.6734, Accuracy=0.5812, Precision=0.5686, Recall=0.6734, F1=0.6166, ROC_AUC=0.6110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2919268562288362 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 | Epoch 1: Loss=0.6850, Accuracy=0.5571, Precision=0.5511, Recall=0.6150, F1=0.5813, ROC_AUC=0.5793\n",
      "Trial 8 | Epoch 2: Loss=0.6833, Accuracy=0.5640, Precision=0.5621, Recall=0.5794, F1=0.5706, ROC_AUC=0.5839\n",
      "Trial 8 | Epoch 3: Loss=0.6823, Accuracy=0.5623, Precision=0.5490, Recall=0.6972, F1=0.6143, ROC_AUC=0.5883\n",
      "Trial 8 | Epoch 4: Loss=0.6806, Accuracy=0.5706, Precision=0.5622, Recall=0.6379, F1=0.5977, ROC_AUC=0.5937\n",
      "Trial 8 | Epoch 5: Loss=0.6800, Accuracy=0.5681, Precision=0.5537, Recall=0.7028, F1=0.6194, ROC_AUC=0.5939\n",
      "Trial 8 | Epoch 6: Loss=0.6765, Accuracy=0.5742, Precision=0.5807, Recall=0.5341, F1=0.5564, ROC_AUC=0.6066\n",
      "Trial 8 | Epoch 7: Loss=0.6758, Accuracy=0.5751, Precision=0.5879, Recall=0.5022, F1=0.5417, ROC_AUC=0.6083\n",
      "Trial 8 | Epoch 8: Loss=0.6743, Accuracy=0.5776, Precision=0.5753, Recall=0.5928, F1=0.5839, ROC_AUC=0.6110\n",
      "Trial 8 | Epoch 9: Loss=0.6736, Accuracy=0.5782, Precision=0.5847, Recall=0.5399, F1=0.5614, ROC_AUC=0.6128\n",
      "Trial 8 | Epoch 10: Loss=0.6729, Accuracy=0.5824, Precision=0.5846, Recall=0.5694, F1=0.5769, ROC_AUC=0.6136\n",
      "Trial 8 | Epoch 11: Loss=0.6741, Accuracy=0.5819, Precision=0.5794, Recall=0.5974, F1=0.5883, ROC_AUC=0.6131\n",
      "Trial 8 | Epoch 12: Loss=0.6730, Accuracy=0.5796, Precision=0.5802, Recall=0.5757, F1=0.5779, ROC_AUC=0.6151\n",
      "Trial 8 | Epoch 13: Loss=0.6724, Accuracy=0.5842, Precision=0.5818, Recall=0.5993, F1=0.5904, ROC_AUC=0.6149\n",
      "Trial 8 | Epoch 14: Loss=0.6722, Accuracy=0.5794, Precision=0.5860, Recall=0.5410, F1=0.5626, ROC_AUC=0.6160\n",
      "Trial 8 | Epoch 15: Loss=0.6718, Accuracy=0.5844, Precision=0.5825, Recall=0.5960, F1=0.5892, ROC_AUC=0.6168\n",
      "Trial 8 | Epoch 16: Loss=0.6733, Accuracy=0.5826, Precision=0.5821, Recall=0.5851, F1=0.5836, ROC_AUC=0.6140\n",
      "Trial 8 | Epoch 17: Loss=0.6715, Accuracy=0.5832, Precision=0.5832, Recall=0.5827, F1=0.5830, ROC_AUC=0.6187\n",
      "Trial 8 | Epoch 18: Loss=0.6741, Accuracy=0.5818, Precision=0.5956, Recall=0.5094, F1=0.5492, ROC_AUC=0.6164\n",
      "Trial 8 | Epoch 19: Loss=0.6739, Accuracy=0.5806, Precision=0.5850, Recall=0.5542, F1=0.5692, ROC_AUC=0.6123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 16:29:34,882] Trial 8 finished with value: 0.5840555555555556 and parameters: {'hidden_dim': 434, 'num_layers': 1, 'dropout': 0.2919268562288362, 'lr': 8.482229420644452e-05}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 | Epoch 20: Loss=0.6706, Accuracy=0.5841, Precision=0.5837, Recall=0.5861, F1=0.5849, ROC_AUC=0.6191\n",
      "Trial 9 | Epoch 1: Loss=0.6842, Accuracy=0.5613, Precision=0.5510, Recall=0.6623, F1=0.6015, ROC_AUC=0.5851\n",
      "Trial 9 | Epoch 2: Loss=0.6837, Accuracy=0.5615, Precision=0.5473, Recall=0.7117, F1=0.6188, ROC_AUC=0.5881\n",
      "Trial 9 | Epoch 3: Loss=0.6797, Accuracy=0.5720, Precision=0.5682, Recall=0.6002, F1=0.5837, ROC_AUC=0.5970\n",
      "Trial 9 | Epoch 4: Loss=0.6791, Accuracy=0.5737, Precision=0.5549, Recall=0.7448, F1=0.6360, ROC_AUC=0.6064\n",
      "Trial 9 | Epoch 5: Loss=0.6771, Accuracy=0.5741, Precision=0.5927, Recall=0.4736, F1=0.5265, ROC_AUC=0.6080\n",
      "Trial 9 | Epoch 6: Loss=0.6730, Accuracy=0.5831, Precision=0.5890, Recall=0.5498, F1=0.5687, ROC_AUC=0.6149\n",
      "Trial 9 | Epoch 7: Loss=0.6727, Accuracy=0.5833, Precision=0.5836, Recall=0.5816, F1=0.5826, ROC_AUC=0.6138\n",
      "Trial 9 | Epoch 8: Loss=0.6717, Accuracy=0.5807, Precision=0.5861, Recall=0.5496, F1=0.5672, ROC_AUC=0.6159\n",
      "Trial 9 | Epoch 9: Loss=0.6718, Accuracy=0.5814, Precision=0.5802, Recall=0.5891, F1=0.5846, ROC_AUC=0.6151\n",
      "Trial 9 | Epoch 10: Loss=0.6698, Accuracy=0.5893, Precision=0.5788, Recall=0.6559, F1=0.6149, ROC_AUC=0.6208\n",
      "Trial 9 | Epoch 11: Loss=0.6690, Accuracy=0.5845, Precision=0.6044, Recall=0.4891, F1=0.5407, ROC_AUC=0.6225\n",
      "Trial 9 | Epoch 12: Loss=0.6685, Accuracy=0.5861, Precision=0.5937, Recall=0.5457, F1=0.5687, ROC_AUC=0.6233\n",
      "Trial 9 | Epoch 13: Loss=0.6663, Accuracy=0.5910, Precision=0.5951, Recall=0.5697, F1=0.5821, ROC_AUC=0.6288\n",
      "Trial 9 | Epoch 14: Loss=0.6670, Accuracy=0.5917, Precision=0.6107, Recall=0.5057, F1=0.5532, ROC_AUC=0.6300\n",
      "Trial 9 | Epoch 15: Loss=0.6657, Accuracy=0.5951, Precision=0.5827, Recall=0.6700, F1=0.6233, ROC_AUC=0.6318\n",
      "Trial 9 | Epoch 16: Loss=0.6614, Accuracy=0.5978, Precision=0.6019, Recall=0.5774, F1=0.5894, ROC_AUC=0.6383\n",
      "Trial 9 | Epoch 17: Loss=0.6621, Accuracy=0.5993, Precision=0.6099, Recall=0.5508, F1=0.5789, ROC_AUC=0.6385\n",
      "Trial 9 | Epoch 18: Loss=0.6603, Accuracy=0.6008, Precision=0.6026, Recall=0.5924, F1=0.5975, ROC_AUC=0.6391\n",
      "Trial 9 | Epoch 19: Loss=0.6642, Accuracy=0.5967, Precision=0.5915, Recall=0.6250, F1=0.6078, ROC_AUC=0.6347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 16:47:03,751] Trial 9 finished with value: 0.6013333333333334 and parameters: {'hidden_dim': 386, 'num_layers': 2, 'dropout': 0.488488315310723, 'lr': 9.555575411261533e-05}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 | Epoch 20: Loss=0.6592, Accuracy=0.6013, Precision=0.6113, Recall=0.5566, F1=0.5826, ROC_AUC=0.6435\n",
      "Trial 10 | Epoch 1: Loss=0.6842, Accuracy=0.5611, Precision=0.5634, Recall=0.5428, F1=0.5529, ROC_AUC=0.5781\n",
      "Trial 10 | Epoch 2: Loss=0.6824, Accuracy=0.5608, Precision=0.5429, Recall=0.7691, F1=0.6365, ROC_AUC=0.5932\n",
      "Trial 10 | Epoch 3: Loss=0.6786, Accuracy=0.5730, Precision=0.5701, Recall=0.5940, F1=0.5818, ROC_AUC=0.6013\n",
      "Trial 10 | Epoch 4: Loss=0.6774, Accuracy=0.5768, Precision=0.5574, Recall=0.7459, F1=0.6380, ROC_AUC=0.6041\n",
      "Trial 10 | Epoch 5: Loss=0.6743, Accuracy=0.5778, Precision=0.5863, Recall=0.5289, F1=0.5561, ROC_AUC=0.6112\n",
      "Trial 10 | Epoch 6: Loss=0.6736, Accuracy=0.5834, Precision=0.5871, Recall=0.5627, F1=0.5746, ROC_AUC=0.6153\n",
      "Trial 10 | Epoch 7: Loss=0.6696, Accuracy=0.5858, Precision=0.5806, Recall=0.6180, F1=0.5987, ROC_AUC=0.6194\n",
      "Trial 10 | Epoch 8: Loss=0.6715, Accuracy=0.5814, Precision=0.5957, Recall=0.5071, F1=0.5478, ROC_AUC=0.6201\n",
      "Trial 10 | Epoch 9: Loss=0.6634, Accuracy=0.5879, Precision=0.5881, Recall=0.5866, F1=0.5873, ROC_AUC=0.6316\n",
      "Trial 10 | Epoch 10: Loss=0.6633, Accuracy=0.5938, Precision=0.5973, Recall=0.5760, F1=0.5865, ROC_AUC=0.6399\n",
      "Trial 10 | Epoch 11: Loss=0.6582, Accuracy=0.5989, Precision=0.5871, Recall=0.6672, F1=0.6246, ROC_AUC=0.6413\n",
      "Trial 10 | Epoch 12: Loss=0.6521, Accuracy=0.6004, Precision=0.5940, Recall=0.6344, F1=0.6135, ROC_AUC=0.6494\n",
      "Trial 10 | Epoch 13: Loss=0.6617, Accuracy=0.6021, Precision=0.5983, Recall=0.6211, F1=0.6095, ROC_AUC=0.6487\n",
      "Trial 10 | Epoch 14: Loss=0.6452, Accuracy=0.6094, Precision=0.6123, Recall=0.5968, F1=0.6044, ROC_AUC=0.6643\n",
      "Trial 10 | Epoch 15: Loss=0.6418, Accuracy=0.6167, Precision=0.6130, Recall=0.6333, F1=0.6230, ROC_AUC=0.6702\n",
      "Trial 10 | Epoch 16: Loss=0.6372, Accuracy=0.6178, Precision=0.6049, Recall=0.6792, F1=0.6399, ROC_AUC=0.6774\n",
      "Trial 10 | Epoch 17: Loss=0.6253, Accuracy=0.6277, Precision=0.6248, Recall=0.6391, F1=0.6319, ROC_AUC=0.6922\n",
      "Trial 10 | Epoch 18: Loss=0.6182, Accuracy=0.6343, Precision=0.6330, Recall=0.6394, F1=0.6362, ROC_AUC=0.6995\n",
      "Trial 10 | Epoch 19: Loss=0.6125, Accuracy=0.6351, Precision=0.6336, Recall=0.6407, F1=0.6371, ROC_AUC=0.7091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 16:53:20,616] Trial 10 finished with value: 0.6371111111111111 and parameters: {'hidden_dim': 67, 'num_layers': 4, 'dropout': 0.10326333827597398, 'lr': 0.00036965583764274383}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 | Epoch 20: Loss=0.6100, Accuracy=0.6371, Precision=0.6454, Recall=0.6087, F1=0.6265, ROC_AUC=0.7114\n",
      "Trial 11 | Epoch 1: Loss=0.6875, Accuracy=0.5423, Precision=0.5320, Recall=0.7034, F1=0.6058, ROC_AUC=0.5664\n",
      "Trial 11 | Epoch 2: Loss=0.6801, Accuracy=0.5697, Precision=0.5584, Recall=0.6660, F1=0.6075, ROC_AUC=0.5930\n",
      "Trial 11 | Epoch 3: Loss=0.6810, Accuracy=0.5626, Precision=0.5404, Recall=0.8361, F1=0.6565, ROC_AUC=0.6026\n",
      "Trial 11 | Epoch 4: Loss=0.6713, Accuracy=0.5898, Precision=0.5800, Recall=0.6510, F1=0.6134, ROC_AUC=0.6186\n",
      "Trial 11 | Epoch 5: Loss=0.6701, Accuracy=0.5843, Precision=0.5673, Recall=0.7100, F1=0.6307, ROC_AUC=0.6217\n",
      "Trial 11 | Epoch 6: Loss=0.6584, Accuracy=0.6034, Precision=0.5873, Recall=0.6962, F1=0.6371, ROC_AUC=0.6443\n",
      "Trial 11 | Epoch 7: Loss=0.6512, Accuracy=0.6083, Precision=0.5980, Recall=0.6613, F1=0.6280, ROC_AUC=0.6557\n",
      "Trial 11 | Epoch 8: Loss=0.6450, Accuracy=0.6147, Precision=0.6020, Recall=0.6772, F1=0.6374, ROC_AUC=0.6660\n",
      "Trial 11 | Epoch 9: Loss=0.6343, Accuracy=0.6196, Precision=0.6291, Recall=0.5830, F1=0.6052, ROC_AUC=0.6822\n",
      "Trial 11 | Epoch 10: Loss=0.6206, Accuracy=0.6384, Precision=0.6460, Recall=0.6127, F1=0.6289, ROC_AUC=0.7033\n",
      "Trial 11 | Epoch 11: Loss=0.6056, Accuracy=0.6477, Precision=0.6514, Recall=0.6354, F1=0.6433, ROC_AUC=0.7199\n",
      "Trial 11 | Epoch 12: Loss=0.5877, Accuracy=0.6647, Precision=0.6603, Recall=0.6783, F1=0.6692, ROC_AUC=0.7405\n",
      "Trial 11 | Epoch 13: Loss=0.5709, Accuracy=0.6746, Precision=0.6784, Recall=0.6640, F1=0.6711, ROC_AUC=0.7586\n",
      "Trial 11 | Epoch 14: Loss=0.5678, Accuracy=0.6724, Precision=0.7073, Recall=0.5881, F1=0.6422, ROC_AUC=0.7621\n",
      "Trial 11 | Epoch 15: Loss=0.5504, Accuracy=0.6866, Precision=0.7122, Recall=0.6263, F1=0.6665, ROC_AUC=0.7807\n",
      "Trial 11 | Epoch 16: Loss=0.5379, Accuracy=0.6893, Precision=0.6998, Recall=0.6629, F1=0.6809, ROC_AUC=0.7886\n",
      "Trial 11 | Epoch 17: Loss=0.5228, Accuracy=0.6951, Precision=0.7003, Recall=0.6821, F1=0.6911, ROC_AUC=0.7972\n",
      "Trial 11 | Epoch 18: Loss=0.5110, Accuracy=0.7047, Precision=0.7275, Recall=0.6546, F1=0.6891, ROC_AUC=0.8095\n",
      "Trial 11 | Epoch 19: Loss=0.5029, Accuracy=0.7128, Precision=0.7185, Recall=0.6997, F1=0.7090, ROC_AUC=0.8175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 17:01:27,789] Trial 11 finished with value: 0.7128333333333333 and parameters: {'hidden_dim': 110, 'num_layers': 4, 'dropout': 0.3232698147295837, 'lr': 0.0009368917991532698}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 | Epoch 20: Loss=0.5074, Accuracy=0.7128, Precision=0.7294, Recall=0.6767, F1=0.7021, ROC_AUC=0.8194\n",
      "Trial 12 | Epoch 1: Loss=0.6832, Accuracy=0.5588, Precision=0.5570, Recall=0.5749, F1=0.5658, ROC_AUC=0.5835\n",
      "Trial 12 | Epoch 2: Loss=0.6821, Accuracy=0.5707, Precision=0.5707, Recall=0.5710, F1=0.5708, ROC_AUC=0.5887\n",
      "Trial 12 | Epoch 3: Loss=0.6805, Accuracy=0.5697, Precision=0.5723, Recall=0.5512, F1=0.5616, ROC_AUC=0.5926\n",
      "Trial 12 | Epoch 4: Loss=0.6798, Accuracy=0.5720, Precision=0.5741, Recall=0.5579, F1=0.5659, ROC_AUC=0.5982\n",
      "Trial 12 | Epoch 5: Loss=0.6774, Accuracy=0.5731, Precision=0.5703, Recall=0.5929, F1=0.5814, ROC_AUC=0.6007\n",
      "Trial 12 | Epoch 6: Loss=0.6781, Accuracy=0.5746, Precision=0.5845, Recall=0.5159, F1=0.5480, ROC_AUC=0.6041\n",
      "Trial 12 | Epoch 7: Loss=0.6755, Accuracy=0.5787, Precision=0.5645, Recall=0.6890, F1=0.6206, ROC_AUC=0.6083\n",
      "Trial 12 | Epoch 8: Loss=0.6773, Accuracy=0.5780, Precision=0.5795, Recall=0.5688, F1=0.5741, ROC_AUC=0.6033\n",
      "Trial 12 | Epoch 9: Loss=0.6711, Accuracy=0.5887, Precision=0.5801, Recall=0.6422, F1=0.6096, ROC_AUC=0.6183\n",
      "Trial 12 | Epoch 10: Loss=0.6690, Accuracy=0.5896, Precision=0.5891, Recall=0.5922, F1=0.5906, ROC_AUC=0.6252\n",
      "Trial 12 | Epoch 11: Loss=0.6652, Accuracy=0.5908, Precision=0.5908, Recall=0.5904, F1=0.5906, ROC_AUC=0.6315\n",
      "Trial 12 | Epoch 12: Loss=0.6630, Accuracy=0.5928, Precision=0.5881, Recall=0.6199, F1=0.6036, ROC_AUC=0.6347\n",
      "Trial 12 | Epoch 13: Loss=0.6636, Accuracy=0.6008, Precision=0.5928, Recall=0.6442, F1=0.6174, ROC_AUC=0.6396\n",
      "Trial 12 | Epoch 14: Loss=0.6571, Accuracy=0.5976, Precision=0.5964, Recall=0.6033, F1=0.5999, ROC_AUC=0.6438\n",
      "Trial 12 | Epoch 15: Loss=0.6493, Accuracy=0.6104, Precision=0.5986, Recall=0.6707, F1=0.6326, ROC_AUC=0.6569\n",
      "Trial 12 | Epoch 16: Loss=0.6504, Accuracy=0.6075, Precision=0.6037, Recall=0.6259, F1=0.6146, ROC_AUC=0.6564\n",
      "Trial 12 | Epoch 17: Loss=0.6374, Accuracy=0.6228, Precision=0.6274, Recall=0.6047, F1=0.6158, ROC_AUC=0.6771\n",
      "Trial 12 | Epoch 18: Loss=0.6308, Accuracy=0.6268, Precision=0.6076, Recall=0.7164, F1=0.6575, ROC_AUC=0.6893\n",
      "Trial 12 | Epoch 19: Loss=0.6247, Accuracy=0.6356, Precision=0.6253, Recall=0.6763, F1=0.6498, ROC_AUC=0.6978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 17:08:48,446] Trial 12 finished with value: 0.6378888888888888 and parameters: {'hidden_dim': 89, 'num_layers': 4, 'dropout': 0.1976905937930369, 'lr': 0.000287735529974525}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 | Epoch 20: Loss=0.6164, Accuracy=0.6379, Precision=0.6405, Recall=0.6284, F1=0.6344, ROC_AUC=0.7054\n",
      "Trial 13 | Epoch 1: Loss=0.6848, Accuracy=0.5609, Precision=0.5564, Recall=0.6017, F1=0.5781, ROC_AUC=0.5790\n",
      "Trial 13 | Epoch 2: Loss=0.6808, Accuracy=0.5676, Precision=0.5622, Recall=0.6114, F1=0.5858, ROC_AUC=0.5955\n",
      "Trial 13 | Epoch 3: Loss=0.6827, Accuracy=0.5651, Precision=0.5707, Recall=0.5257, F1=0.5473, ROC_AUC=0.5894\n",
      "Trial 13 | Epoch 4: Loss=0.6756, Accuracy=0.5822, Precision=0.5834, Recall=0.5753, F1=0.5793, ROC_AUC=0.6113\n",
      "Trial 13 | Epoch 5: Loss=0.6718, Accuracy=0.5809, Precision=0.5910, Recall=0.5257, F1=0.5564, ROC_AUC=0.6202\n",
      "Trial 13 | Epoch 6: Loss=0.6709, Accuracy=0.5845, Precision=0.5942, Recall=0.5332, F1=0.5620, ROC_AUC=0.6240\n",
      "Trial 13 | Epoch 7: Loss=0.6651, Accuracy=0.5892, Precision=0.5861, Recall=0.6074, F1=0.5966, ROC_AUC=0.6320\n",
      "Trial 13 | Epoch 8: Loss=0.6626, Accuracy=0.5952, Precision=0.5811, Recall=0.6824, F1=0.6277, ROC_AUC=0.6386\n",
      "Trial 13 | Epoch 9: Loss=0.6534, Accuracy=0.6113, Precision=0.6070, Recall=0.6312, F1=0.6189, ROC_AUC=0.6565\n",
      "Trial 13 | Epoch 10: Loss=0.6410, Accuracy=0.6179, Precision=0.6116, Recall=0.6459, F1=0.6283, ROC_AUC=0.6713\n",
      "Trial 13 | Epoch 11: Loss=0.6300, Accuracy=0.6352, Precision=0.6421, Recall=0.6108, F1=0.6260, ROC_AUC=0.6912\n",
      "Trial 13 | Epoch 12: Loss=0.6198, Accuracy=0.6394, Precision=0.6325, Recall=0.6653, F1=0.6485, ROC_AUC=0.7049\n",
      "Trial 13 | Epoch 13: Loss=0.6101, Accuracy=0.6496, Precision=0.6554, Recall=0.6307, F1=0.6428, ROC_AUC=0.7179\n",
      "Trial 13 | Epoch 14: Loss=0.5975, Accuracy=0.6608, Precision=0.6918, Recall=0.5800, F1=0.6310, ROC_AUC=0.7385\n",
      "Trial 13 | Epoch 15: Loss=0.5782, Accuracy=0.6631, Precision=0.6665, Recall=0.6530, F1=0.6597, ROC_AUC=0.7482\n",
      "Trial 13 | Epoch 16: Loss=0.5632, Accuracy=0.6806, Precision=0.7072, Recall=0.6163, F1=0.6586, ROC_AUC=0.7682\n",
      "Trial 13 | Epoch 17: Loss=0.5501, Accuracy=0.6878, Precision=0.6934, Recall=0.6733, F1=0.6832, ROC_AUC=0.7776\n",
      "Trial 13 | Epoch 18: Loss=0.5374, Accuracy=0.6939, Precision=0.6941, Recall=0.6937, F1=0.6939, ROC_AUC=0.7881\n",
      "Trial 13 | Epoch 19: Loss=0.5287, Accuracy=0.6971, Precision=0.6931, Recall=0.7076, F1=0.7002, ROC_AUC=0.7970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 17:19:04,818] Trial 13 finished with value: 0.7057222222222223 and parameters: {'hidden_dim': 137, 'num_layers': 4, 'dropout': 0.29642669982561765, 'lr': 0.0009889238561060249}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 | Epoch 20: Loss=0.5112, Accuracy=0.7057, Precision=0.6978, Recall=0.7258, F1=0.7115, ROC_AUC=0.8118\n",
      "Trial 14 | Epoch 1: Loss=0.6894, Accuracy=0.5318, Precision=0.5327, Recall=0.5173, F1=0.5249, ROC_AUC=0.5504\n",
      "Trial 14 | Epoch 2: Loss=0.6902, Accuracy=0.5492, Precision=0.5505, Recall=0.5360, F1=0.5432, ROC_AUC=0.5702\n",
      "Trial 14 | Epoch 3: Loss=0.6847, Accuracy=0.5538, Precision=0.5570, Recall=0.5259, F1=0.5410, ROC_AUC=0.5768\n",
      "Trial 14 | Epoch 4: Loss=0.6841, Accuracy=0.5558, Precision=0.5499, Recall=0.6158, F1=0.5810, ROC_AUC=0.5800\n",
      "Trial 14 | Epoch 5: Loss=0.6821, Accuracy=0.5627, Precision=0.5585, Recall=0.5981, F1=0.5776, ROC_AUC=0.5857\n",
      "Trial 14 | Epoch 6: Loss=0.6822, Accuracy=0.5658, Precision=0.5631, Recall=0.5878, F1=0.5752, ROC_AUC=0.5883\n",
      "Trial 14 | Epoch 7: Loss=0.6817, Accuracy=0.5647, Precision=0.5722, Recall=0.5128, F1=0.5408, ROC_AUC=0.5897\n",
      "Trial 14 | Epoch 8: Loss=0.6807, Accuracy=0.5678, Precision=0.5605, Recall=0.6286, F1=0.5926, ROC_AUC=0.5913\n",
      "Trial 14 | Epoch 9: Loss=0.6809, Accuracy=0.5674, Precision=0.5578, Recall=0.6503, F1=0.6005, ROC_AUC=0.5907\n",
      "Trial 14 | Epoch 10: Loss=0.6812, Accuracy=0.5681, Precision=0.5599, Recall=0.6369, F1=0.5959, ROC_AUC=0.5913\n",
      "Trial 14 | Epoch 11: Loss=0.6803, Accuracy=0.5681, Precision=0.5581, Recall=0.6547, F1=0.6025, ROC_AUC=0.5928\n",
      "Trial 14 | Epoch 12: Loss=0.6802, Accuracy=0.5700, Precision=0.5654, Recall=0.6054, F1=0.5847, ROC_AUC=0.5929\n",
      "Trial 14 | Epoch 13: Loss=0.6804, Accuracy=0.5671, Precision=0.5772, Recall=0.5011, F1=0.5365, ROC_AUC=0.5938\n",
      "Trial 14 | Epoch 14: Loss=0.6797, Accuracy=0.5698, Precision=0.5657, Recall=0.6009, F1=0.5828, ROC_AUC=0.5938\n",
      "Trial 14 | Epoch 15: Loss=0.6797, Accuracy=0.5689, Precision=0.5661, Recall=0.5901, F1=0.5778, ROC_AUC=0.5944\n",
      "Trial 14 | Epoch 16: Loss=0.6790, Accuracy=0.5722, Precision=0.5721, Recall=0.5728, F1=0.5724, ROC_AUC=0.5954\n",
      "Trial 14 | Epoch 17: Loss=0.6801, Accuracy=0.5691, Precision=0.5639, Recall=0.6093, F1=0.5857, ROC_AUC=0.5942\n",
      "Trial 14 | Epoch 18: Loss=0.6794, Accuracy=0.5684, Precision=0.5710, Recall=0.5501, F1=0.5604, ROC_AUC=0.5956\n",
      "Trial 14 | Epoch 19: Loss=0.6794, Accuracy=0.5668, Precision=0.5689, Recall=0.5516, F1=0.5601, ROC_AUC=0.5949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 18:00:29,843] Trial 14 finished with value: 0.5701666666666667 and parameters: {'hidden_dim': 365, 'num_layers': 5, 'dropout': 0.16332510856753238, 'lr': 1.1635313846862305e-05}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 | Epoch 20: Loss=0.6794, Accuracy=0.5702, Precision=0.5715, Recall=0.5611, F1=0.5662, ROC_AUC=0.5957\n",
      "Trial 15 | Epoch 1: Loss=0.6832, Accuracy=0.5661, Precision=0.5570, Recall=0.6461, F1=0.5983, ROC_AUC=0.5867\n",
      "Trial 15 | Epoch 2: Loss=0.6818, Accuracy=0.5726, Precision=0.5862, Recall=0.4933, F1=0.5358, ROC_AUC=0.5974\n",
      "Trial 15 | Epoch 3: Loss=0.6774, Accuracy=0.5747, Precision=0.5819, Recall=0.5307, F1=0.5551, ROC_AUC=0.6030\n",
      "Trial 15 | Epoch 4: Loss=0.6741, Accuracy=0.5814, Precision=0.5856, Recall=0.5570, F1=0.5710, ROC_AUC=0.6122\n",
      "Trial 15 | Epoch 5: Loss=0.6725, Accuracy=0.5848, Precision=0.5763, Recall=0.6408, F1=0.6068, ROC_AUC=0.6153\n",
      "Trial 15 | Epoch 6: Loss=0.6694, Accuracy=0.5855, Precision=0.5866, Recall=0.5792, F1=0.5829, ROC_AUC=0.6227\n",
      "Trial 15 | Epoch 7: Loss=0.6635, Accuracy=0.5933, Precision=0.5842, Recall=0.6469, F1=0.6140, ROC_AUC=0.6352\n",
      "Trial 15 | Epoch 8: Loss=0.6652, Accuracy=0.5962, Precision=0.5955, Recall=0.5999, F1=0.5977, ROC_AUC=0.6311\n",
      "Trial 15 | Epoch 9: Loss=0.6571, Accuracy=0.6072, Precision=0.6117, Recall=0.5873, F1=0.5993, ROC_AUC=0.6485\n",
      "Trial 15 | Epoch 10: Loss=0.6551, Accuracy=0.6068, Precision=0.6119, Recall=0.5841, F1=0.5977, ROC_AUC=0.6542\n",
      "Trial 15 | Epoch 11: Loss=0.6456, Accuracy=0.6245, Precision=0.6323, Recall=0.5949, F1=0.6130, ROC_AUC=0.6726\n",
      "Trial 15 | Epoch 12: Loss=0.6380, Accuracy=0.6311, Precision=0.6208, Recall=0.6736, F1=0.6461, ROC_AUC=0.6825\n",
      "Trial 15 | Epoch 13: Loss=0.6278, Accuracy=0.6349, Precision=0.6367, Recall=0.6283, F1=0.6325, ROC_AUC=0.6946\n",
      "Trial 15 | Epoch 14: Loss=0.6242, Accuracy=0.6373, Precision=0.6411, Recall=0.6237, F1=0.6323, ROC_AUC=0.6994\n",
      "Trial 15 | Epoch 15: Loss=0.6128, Accuracy=0.6493, Precision=0.6464, Recall=0.6594, F1=0.6528, ROC_AUC=0.7161\n",
      "Trial 15 | Epoch 16: Loss=0.6016, Accuracy=0.6603, Precision=0.6585, Recall=0.6662, F1=0.6623, ROC_AUC=0.7299\n",
      "Trial 15 | Epoch 17: Loss=0.5947, Accuracy=0.6639, Precision=0.6794, Recall=0.6207, F1=0.6487, ROC_AUC=0.7394\n",
      "Trial 15 | Epoch 18: Loss=0.5883, Accuracy=0.6709, Precision=0.6586, Recall=0.7099, F1=0.6833, ROC_AUC=0.7480\n",
      "Trial 15 | Epoch 19: Loss=0.5806, Accuracy=0.6707, Precision=0.6624, Recall=0.6960, F1=0.6788, ROC_AUC=0.7550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 18:09:36,596] Trial 15 finished with value: 0.68 and parameters: {'hidden_dim': 250, 'num_layers': 2, 'dropout': 0.24531113953765643, 'lr': 0.0003226279679688342}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 | Epoch 20: Loss=0.5735, Accuracy=0.6800, Precision=0.6788, Recall=0.6833, F1=0.6811, ROC_AUC=0.7633\n",
      "Trial 16 | Epoch 1: Loss=0.6857, Accuracy=0.5617, Precision=0.5619, Recall=0.5601, F1=0.5610, ROC_AUC=0.5805\n",
      "Trial 16 | Epoch 2: Loss=0.6777, Accuracy=0.5717, Precision=0.5653, Recall=0.6208, F1=0.5917, ROC_AUC=0.6026\n",
      "Trial 16 | Epoch 3: Loss=0.6746, Accuracy=0.5786, Precision=0.5712, Recall=0.6308, F1=0.5995, ROC_AUC=0.6091\n",
      "Trial 16 | Epoch 4: Loss=0.6722, Accuracy=0.5862, Precision=0.5897, Recall=0.5663, F1=0.5778, ROC_AUC=0.6222\n",
      "Trial 16 | Epoch 5: Loss=0.6698, Accuracy=0.5882, Precision=0.5925, Recall=0.5647, F1=0.5783, ROC_AUC=0.6235\n",
      "Trial 16 | Epoch 6: Loss=0.6643, Accuracy=0.5948, Precision=0.5860, Recall=0.6456, F1=0.6144, ROC_AUC=0.6356\n",
      "Trial 16 | Epoch 7: Loss=0.6588, Accuracy=0.5999, Precision=0.5801, Recall=0.7234, F1=0.6439, ROC_AUC=0.6480\n",
      "Trial 16 | Epoch 8: Loss=0.6515, Accuracy=0.6061, Precision=0.6035, Recall=0.6186, F1=0.6110, ROC_AUC=0.6567\n",
      "Trial 16 | Epoch 9: Loss=0.6447, Accuracy=0.6211, Precision=0.6149, Recall=0.6482, F1=0.6311, ROC_AUC=0.6699\n",
      "Trial 16 | Epoch 10: Loss=0.6408, Accuracy=0.6194, Precision=0.6101, Recall=0.6616, F1=0.6348, ROC_AUC=0.6768\n",
      "Trial 16 | Epoch 11: Loss=0.6274, Accuracy=0.6397, Precision=0.6294, Recall=0.6798, F1=0.6536, ROC_AUC=0.6960\n",
      "Trial 16 | Epoch 12: Loss=0.6160, Accuracy=0.6419, Precision=0.6498, Recall=0.6153, F1=0.6321, ROC_AUC=0.7099\n",
      "Trial 16 | Epoch 13: Loss=0.6024, Accuracy=0.6536, Precision=0.6415, Recall=0.6964, F1=0.6678, ROC_AUC=0.7258\n",
      "Trial 16 | Epoch 14: Loss=0.5952, Accuracy=0.6539, Precision=0.6737, Recall=0.5970, F1=0.6330, ROC_AUC=0.7351\n",
      "Trial 16 | Epoch 15: Loss=0.5676, Accuracy=0.6737, Precision=0.6775, Recall=0.6629, F1=0.6701, ROC_AUC=0.7607\n",
      "Trial 16 | Epoch 16: Loss=0.5576, Accuracy=0.6815, Precision=0.6774, Recall=0.6930, F1=0.6851, ROC_AUC=0.7727\n",
      "Trial 16 | Epoch 17: Loss=0.5418, Accuracy=0.6888, Precision=0.6934, Recall=0.6770, F1=0.6851, ROC_AUC=0.7832\n",
      "Trial 16 | Epoch 18: Loss=0.5352, Accuracy=0.6945, Precision=0.7034, Recall=0.6726, F1=0.6876, ROC_AUC=0.7927\n",
      "Trial 16 | Epoch 19: Loss=0.5273, Accuracy=0.7001, Precision=0.6986, Recall=0.7039, F1=0.7012, ROC_AUC=0.8004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 18:19:28,547] Trial 16 finished with value: 0.7028333333333333 and parameters: {'hidden_dim': 126, 'num_layers': 4, 'dropout': 0.3312634085574883, 'lr': 0.00047392378260642645}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 | Epoch 20: Loss=0.5155, Accuracy=0.7028, Precision=0.7061, Recall=0.6950, F1=0.7005, ROC_AUC=0.8103\n",
      "Trial 17 | Epoch 1: Loss=0.6823, Accuracy=0.5629, Precision=0.5706, Recall=0.5080, F1=0.5375, ROC_AUC=0.5895\n",
      "Trial 17 | Epoch 2: Loss=0.6811, Accuracy=0.5708, Precision=0.5695, Recall=0.5807, F1=0.5750, ROC_AUC=0.5912\n",
      "Trial 17 | Epoch 3: Loss=0.6795, Accuracy=0.5713, Precision=0.5748, Recall=0.5481, F1=0.5611, ROC_AUC=0.6018\n",
      "Trial 17 | Epoch 4: Loss=0.6739, Accuracy=0.5777, Precision=0.5705, Recall=0.6288, F1=0.5982, ROC_AUC=0.6126\n",
      "Trial 17 | Epoch 5: Loss=0.6715, Accuracy=0.5827, Precision=0.5793, Recall=0.6046, F1=0.5916, ROC_AUC=0.6163\n",
      "Trial 17 | Epoch 6: Loss=0.6716, Accuracy=0.5862, Precision=0.5935, Recall=0.5472, F1=0.5694, ROC_AUC=0.6191\n",
      "Trial 17 | Epoch 7: Loss=0.6680, Accuracy=0.5886, Precision=0.5893, Recall=0.5844, F1=0.5869, ROC_AUC=0.6247\n",
      "Trial 17 | Epoch 8: Loss=0.6685, Accuracy=0.5902, Precision=0.5884, Recall=0.6002, F1=0.5942, ROC_AUC=0.6231\n",
      "Trial 17 | Epoch 9: Loss=0.6653, Accuracy=0.5964, Precision=0.5858, Recall=0.6581, F1=0.6199, ROC_AUC=0.6332\n",
      "Trial 17 | Epoch 10: Loss=0.6659, Accuracy=0.5908, Precision=0.5940, Recall=0.5734, F1=0.5836, ROC_AUC=0.6271\n",
      "Trial 17 | Epoch 11: Loss=0.6562, Accuracy=0.6099, Precision=0.6059, Recall=0.6286, F1=0.6170, ROC_AUC=0.6494\n",
      "Trial 17 | Epoch 12: Loss=0.6556, Accuracy=0.6087, Precision=0.6159, Recall=0.5779, F1=0.5963, ROC_AUC=0.6508\n",
      "Trial 17 | Epoch 13: Loss=0.6515, Accuracy=0.6142, Precision=0.6110, Recall=0.6286, F1=0.6196, ROC_AUC=0.6589\n",
      "Trial 17 | Epoch 14: Loss=0.6481, Accuracy=0.6143, Precision=0.6391, Recall=0.5251, F1=0.5765, ROC_AUC=0.6665\n",
      "Trial 17 | Epoch 15: Loss=0.6441, Accuracy=0.6213, Precision=0.6122, Recall=0.6616, F1=0.6359, ROC_AUC=0.6707\n",
      "Trial 17 | Epoch 16: Loss=0.6398, Accuracy=0.6243, Precision=0.6186, Recall=0.6483, F1=0.6331, ROC_AUC=0.6773\n",
      "Trial 17 | Epoch 17: Loss=0.6295, Accuracy=0.6328, Precision=0.6280, Recall=0.6516, F1=0.6396, ROC_AUC=0.6910\n",
      "Trial 17 | Epoch 18: Loss=0.6283, Accuracy=0.6322, Precision=0.6450, Recall=0.5879, F1=0.6151, ROC_AUC=0.6939\n",
      "Trial 17 | Epoch 19: Loss=0.6179, Accuracy=0.6386, Precision=0.6402, Recall=0.6329, F1=0.6365, ROC_AUC=0.7054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 18:36:00,027] Trial 17 finished with value: 0.649 and parameters: {'hidden_dim': 381, 'num_layers': 2, 'dropout': 0.26363972056833956, 'lr': 0.00017054787332927137}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 | Epoch 20: Loss=0.6094, Accuracy=0.6490, Precision=0.6629, Recall=0.6062, F1=0.6333, ROC_AUC=0.7187\n",
      "Trial 18 | Epoch 1: Loss=0.6920, Accuracy=0.5311, Precision=0.5208, Recall=0.7760, F1=0.6233, ROC_AUC=0.5569\n",
      "Trial 18 | Epoch 2: Loss=0.6887, Accuracy=0.5347, Precision=0.5421, Recall=0.4461, F1=0.4895, ROC_AUC=0.5535\n",
      "Trial 18 | Epoch 3: Loss=0.6889, Accuracy=0.5309, Precision=0.5211, Recall=0.7646, F1=0.6197, ROC_AUC=0.5514\n",
      "Trial 18 | Epoch 4: Loss=0.6889, Accuracy=0.5348, Precision=0.5530, Recall=0.3632, F1=0.4385, ROC_AUC=0.5536\n",
      "Trial 18 | Epoch 5: Loss=0.6910, Accuracy=0.5344, Precision=0.5242, Recall=0.7466, F1=0.6159, ROC_AUC=0.5499\n",
      "Trial 18 | Epoch 6: Loss=0.6921, Accuracy=0.5224, Precision=0.5401, Recall=0.3018, F1=0.3872, ROC_AUC=0.5239\n",
      "Trial 18 | Epoch 7: Loss=0.6919, Accuracy=0.5219, Precision=0.5459, Recall=0.2612, F1=0.3533, ROC_AUC=0.5229\n",
      "Trial 18 | Epoch 8: Loss=0.6913, Accuracy=0.5270, Precision=0.5505, Recall=0.2944, F1=0.3837, ROC_AUC=0.5232\n",
      "Trial 18 | Epoch 9: Loss=0.6910, Accuracy=0.5206, Precision=0.5318, Recall=0.3442, F1=0.4179, ROC_AUC=0.5252\n",
      "Trial 18 | Epoch 10: Loss=0.6914, Accuracy=0.5255, Precision=0.5501, Recall=0.2799, F1=0.3710, ROC_AUC=0.5219\n",
      "Trial 18 | Epoch 11: Loss=0.6910, Accuracy=0.5254, Precision=0.5614, Recall=0.2327, F1=0.3290, ROC_AUC=0.5268\n",
      "Trial 18 | Epoch 12: Loss=0.6918, Accuracy=0.5257, Precision=0.5561, Recall=0.2548, F1=0.3495, ROC_AUC=0.5337\n",
      "Trial 18 | Epoch 13: Loss=0.6910, Accuracy=0.5256, Precision=0.5628, Recall=0.2297, F1=0.3262, ROC_AUC=0.5261\n",
      "Trial 18 | Epoch 14: Loss=0.6908, Accuracy=0.5242, Precision=0.5658, Recall=0.2082, F1=0.3044, ROC_AUC=0.5290\n",
      "Trial 18 | Epoch 15: Loss=0.6909, Accuracy=0.5265, Precision=0.5571, Recall=0.2586, F1=0.3532, ROC_AUC=0.5281\n",
      "Trial 18 | Epoch 16: Loss=0.6910, Accuracy=0.5238, Precision=0.5497, Recall=0.2638, F1=0.3565, ROC_AUC=0.5270\n",
      "Trial 18 | Epoch 17: Loss=0.6911, Accuracy=0.5249, Precision=0.5564, Recall=0.2462, F1=0.3414, ROC_AUC=0.5325\n",
      "Trial 18 | Epoch 18: Loss=0.6909, Accuracy=0.5247, Precision=0.5774, Recall=0.1840, F1=0.2791, ROC_AUC=0.5236\n",
      "Trial 18 | Epoch 19: Loss=0.6908, Accuracy=0.5242, Precision=0.5788, Recall=0.1780, F1=0.2723, ROC_AUC=0.5436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 19:05:20,097] Trial 18 finished with value: 0.5242777777777777 and parameters: {'hidden_dim': 271, 'num_layers': 5, 'dropout': 0.3492031506606737, 'lr': 0.0005742043827273779}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 | Epoch 20: Loss=0.6911, Accuracy=0.5243, Precision=0.5711, Recall=0.1950, F1=0.2907, ROC_AUC=0.5232\n",
      "Trial 19 | Epoch 1: Loss=0.6895, Accuracy=0.5441, Precision=0.5500, Recall=0.4853, F1=0.5156, ROC_AUC=0.5579\n",
      "Trial 19 | Epoch 2: Loss=0.6814, Accuracy=0.5698, Precision=0.5671, Recall=0.5906, F1=0.5786, ROC_AUC=0.5914\n",
      "Trial 19 | Epoch 3: Loss=0.6759, Accuracy=0.5845, Precision=0.5848, Recall=0.5826, F1=0.5837, ROC_AUC=0.6138\n",
      "Trial 19 | Epoch 4: Loss=0.6784, Accuracy=0.5773, Precision=0.5798, Recall=0.5621, F1=0.5708, ROC_AUC=0.6065\n",
      "Trial 19 | Epoch 5: Loss=0.6752, Accuracy=0.5836, Precision=0.5902, Recall=0.5467, F1=0.5676, ROC_AUC=0.6150\n",
      "Trial 19 | Epoch 6: Loss=0.6603, Accuracy=0.6009, Precision=0.5836, Recall=0.7040, F1=0.6382, ROC_AUC=0.6477\n",
      "Trial 19 | Epoch 7: Loss=0.6514, Accuracy=0.6114, Precision=0.6067, Recall=0.6337, F1=0.6199, ROC_AUC=0.6601\n",
      "Trial 19 | Epoch 8: Loss=0.6429, Accuracy=0.6187, Precision=0.6315, Recall=0.5698, F1=0.5991, ROC_AUC=0.6754\n",
      "Trial 19 | Epoch 9: Loss=0.6339, Accuracy=0.6279, Precision=0.6087, Recall=0.7166, F1=0.6582, ROC_AUC=0.6857\n",
      "Trial 19 | Epoch 10: Loss=0.6183, Accuracy=0.6420, Precision=0.6261, Recall=0.7052, F1=0.6633, ROC_AUC=0.7083\n",
      "Trial 19 | Epoch 11: Loss=0.6016, Accuracy=0.6479, Precision=0.6383, Recall=0.6827, F1=0.6597, ROC_AUC=0.7250\n",
      "Trial 19 | Epoch 12: Loss=0.5750, Accuracy=0.6709, Precision=0.6786, Recall=0.6493, F1=0.6636, ROC_AUC=0.7530\n",
      "Trial 19 | Epoch 13: Loss=0.5577, Accuracy=0.6808, Precision=0.6827, Recall=0.6754, F1=0.6791, ROC_AUC=0.7708\n",
      "Trial 19 | Epoch 14: Loss=0.5490, Accuracy=0.6932, Precision=0.6970, Recall=0.6837, F1=0.6903, ROC_AUC=0.7863\n",
      "Trial 19 | Epoch 15: Loss=0.5198, Accuracy=0.7063, Precision=0.7152, Recall=0.6857, F1=0.7001, ROC_AUC=0.8072\n",
      "Trial 19 | Epoch 16: Loss=0.5125, Accuracy=0.7074, Precision=0.6924, Recall=0.7464, F1=0.7184, ROC_AUC=0.8146\n",
      "Trial 19 | Epoch 17: Loss=0.4991, Accuracy=0.7168, Precision=0.7073, Recall=0.7398, F1=0.7232, ROC_AUC=0.8265\n",
      "Trial 19 | Epoch 18: Loss=0.4901, Accuracy=0.7209, Precision=0.7281, Recall=0.7051, F1=0.7164, ROC_AUC=0.8349\n",
      "Trial 19 | Epoch 19: Loss=0.4855, Accuracy=0.7244, Precision=0.7320, Recall=0.7079, F1=0.7198, ROC_AUC=0.8411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 19:51:49,197] Trial 19 finished with value: 0.7248333333333333 and parameters: {'hidden_dim': 444, 'num_layers': 4, 'dropout': 0.16293348166846625, 'lr': 0.00020987595426412333}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 | Epoch 20: Loss=0.4958, Accuracy=0.7248, Precision=0.7280, Recall=0.7179, F1=0.7229, ROC_AUC=0.8433\n",
      "Trial 20 | Epoch 1: Loss=0.6824, Accuracy=0.5688, Precision=0.5719, Recall=0.5469, F1=0.5591, ROC_AUC=0.5885\n",
      "Trial 20 | Epoch 2: Loss=0.6803, Accuracy=0.5693, Precision=0.5662, Recall=0.5926, F1=0.5791, ROC_AUC=0.5995\n",
      "Trial 20 | Epoch 3: Loss=0.6764, Accuracy=0.5781, Precision=0.5764, Recall=0.5893, F1=0.5828, ROC_AUC=0.6079\n",
      "Trial 20 | Epoch 4: Loss=0.6747, Accuracy=0.5763, Precision=0.5693, Recall=0.6263, F1=0.5965, ROC_AUC=0.6092\n",
      "Trial 20 | Epoch 5: Loss=0.6692, Accuracy=0.5892, Precision=0.5905, Recall=0.5817, F1=0.5861, ROC_AUC=0.6224\n",
      "Trial 20 | Epoch 6: Loss=0.6700, Accuracy=0.5862, Precision=0.5962, Recall=0.5340, F1=0.5634, ROC_AUC=0.6219\n",
      "Trial 20 | Epoch 7: Loss=0.6661, Accuracy=0.5959, Precision=0.5954, Recall=0.5987, F1=0.5970, ROC_AUC=0.6329\n",
      "Trial 20 | Epoch 8: Loss=0.6627, Accuracy=0.5972, Precision=0.6098, Recall=0.5399, F1=0.5727, ROC_AUC=0.6384\n",
      "Trial 20 | Epoch 9: Loss=0.6467, Accuracy=0.6129, Precision=0.6167, Recall=0.5967, F1=0.6065, ROC_AUC=0.6651\n",
      "Trial 20 | Epoch 10: Loss=0.6428, Accuracy=0.6182, Precision=0.6317, Recall=0.5669, F1=0.5976, ROC_AUC=0.6725\n",
      "Trial 20 | Epoch 11: Loss=0.6313, Accuracy=0.6299, Precision=0.6247, Recall=0.6508, F1=0.6375, ROC_AUC=0.6892\n",
      "Trial 20 | Epoch 12: Loss=0.6160, Accuracy=0.6475, Precision=0.6461, Recall=0.6523, F1=0.6492, ROC_AUC=0.7116\n",
      "Trial 20 | Epoch 13: Loss=0.6020, Accuracy=0.6586, Precision=0.6699, Recall=0.6252, F1=0.6468, ROC_AUC=0.7305\n",
      "Trial 20 | Epoch 14: Loss=0.5707, Accuracy=0.6760, Precision=0.6742, Recall=0.6811, F1=0.6776, ROC_AUC=0.7610\n",
      "Trial 20 | Epoch 15: Loss=0.5561, Accuracy=0.6879, Precision=0.6921, Recall=0.6769, F1=0.6844, ROC_AUC=0.7767\n",
      "Trial 20 | Epoch 16: Loss=0.5446, Accuracy=0.6956, Precision=0.6911, Recall=0.7073, F1=0.6991, ROC_AUC=0.7903\n",
      "Trial 20 | Epoch 17: Loss=0.5291, Accuracy=0.7011, Precision=0.7003, Recall=0.7029, F1=0.7016, ROC_AUC=0.8029\n",
      "Trial 20 | Epoch 18: Loss=0.5232, Accuracy=0.7067, Precision=0.7161, Recall=0.6848, F1=0.7001, ROC_AUC=0.8109\n",
      "Trial 20 | Epoch 19: Loss=0.5129, Accuracy=0.7132, Precision=0.7160, Recall=0.7069, F1=0.7114, ROC_AUC=0.8207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 20:28:40,177] Trial 20 finished with value: 0.7145 and parameters: {'hidden_dim': 455, 'num_layers': 3, 'dropout': 0.10927523766611896, 'lr': 0.00018405740979625078}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 | Epoch 20: Loss=0.5029, Accuracy=0.7145, Precision=0.7251, Recall=0.6909, F1=0.7076, ROC_AUC=0.8284\n",
      "Trial 21 | Epoch 1: Loss=0.6844, Accuracy=0.5652, Precision=0.5571, Recall=0.6362, F1=0.5940, ROC_AUC=0.5833\n",
      "Trial 21 | Epoch 2: Loss=0.6764, Accuracy=0.5744, Precision=0.5859, Recall=0.5079, F1=0.5441, ROC_AUC=0.6071\n",
      "Trial 21 | Epoch 3: Loss=0.6764, Accuracy=0.5758, Precision=0.5893, Recall=0.5007, F1=0.5414, ROC_AUC=0.6068\n",
      "Trial 21 | Epoch 4: Loss=0.6730, Accuracy=0.5878, Precision=0.5793, Recall=0.6409, F1=0.6086, ROC_AUC=0.6181\n",
      "Trial 21 | Epoch 5: Loss=0.6702, Accuracy=0.5857, Precision=0.5964, Recall=0.5300, F1=0.5612, ROC_AUC=0.6235\n",
      "Trial 21 | Epoch 6: Loss=0.6674, Accuracy=0.5889, Precision=0.5943, Recall=0.5600, F1=0.5767, ROC_AUC=0.6264\n",
      "Trial 21 | Epoch 7: Loss=0.6643, Accuracy=0.5978, Precision=0.5980, Recall=0.5964, F1=0.5972, ROC_AUC=0.6351\n",
      "Trial 21 | Epoch 8: Loss=0.6594, Accuracy=0.6012, Precision=0.6029, Recall=0.5929, F1=0.5979, ROC_AUC=0.6427\n",
      "Trial 21 | Epoch 9: Loss=0.6576, Accuracy=0.6031, Precision=0.6085, Recall=0.5778, F1=0.5928, ROC_AUC=0.6485\n",
      "Trial 21 | Epoch 10: Loss=0.6464, Accuracy=0.6169, Precision=0.6253, Recall=0.5838, F1=0.6038, ROC_AUC=0.6682\n",
      "Trial 21 | Epoch 11: Loss=0.6460, Accuracy=0.6158, Precision=0.6414, Recall=0.5251, F1=0.5775, ROC_AUC=0.6729\n",
      "Trial 21 | Epoch 12: Loss=0.6307, Accuracy=0.6294, Precision=0.6412, Recall=0.5876, F1=0.6132, ROC_AUC=0.6927\n",
      "Trial 21 | Epoch 13: Loss=0.6214, Accuracy=0.6411, Precision=0.6414, Recall=0.6401, F1=0.6408, ROC_AUC=0.7048\n",
      "Trial 21 | Epoch 14: Loss=0.6139, Accuracy=0.6451, Precision=0.6522, Recall=0.6217, F1=0.6366, ROC_AUC=0.7147\n",
      "Trial 21 | Epoch 15: Loss=0.6052, Accuracy=0.6570, Precision=0.6598, Recall=0.6483, F1=0.6540, ROC_AUC=0.7274\n",
      "Trial 21 | Epoch 16: Loss=0.5893, Accuracy=0.6626, Precision=0.6711, Recall=0.6377, F1=0.6539, ROC_AUC=0.7448\n",
      "Trial 21 | Epoch 17: Loss=0.5702, Accuracy=0.6759, Precision=0.6806, Recall=0.6631, F1=0.6717, ROC_AUC=0.7631\n",
      "Trial 21 | Epoch 18: Loss=0.5537, Accuracy=0.6844, Precision=0.6892, Recall=0.6719, F1=0.6804, ROC_AUC=0.7784\n",
      "Trial 21 | Epoch 19: Loss=0.5452, Accuracy=0.6929, Precision=0.6750, Recall=0.7442, F1=0.7079, ROC_AUC=0.7891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 21:01:48,600] Trial 21 finished with value: 0.6930555555555555 and parameters: {'hidden_dim': 443, 'num_layers': 3, 'dropout': 0.10537963085428154, 'lr': 0.00014706322188363607}. Best is trial 4 with value: 0.7318888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 | Epoch 20: Loss=0.5427, Accuracy=0.6931, Precision=0.6999, Recall=0.6759, F1=0.6877, ROC_AUC=0.7958\n",
      "Trial 22 | Epoch 1: Loss=0.6940, Accuracy=0.5460, Precision=0.5337, Recall=0.7290, F1=0.6162, ROC_AUC=0.5753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-16 21:04:13,750] Trial 22 failed with parameters: {'hidden_dim': 507, 'num_layers': 3, 'dropout': 0.167456972037691, 'lr': 0.00018031239600952288} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\.conda\\envs\\deeplearning\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_24628\\939395415.py\", line 148, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_test, y_test, train_loader, test_loader, device), n_trials=50)\n",
      "  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_24628\\939395415.py\", line 105, in objective\n",
      "    train_model(model, train_loader, criterion, optimizer, device)\n",
      "  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_24628\\939395415.py\", line 53, in train_model\n",
      "    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
      "KeyboardInterrupt\n",
      "[W 2025-01-16 21:04:13,774] Trial 22 failed with value None.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE  # 用于类别不平衡\n",
    "\n",
    "# 定义双向 LSTM 模型\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, num_layers, dropout, output_dim):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_dim, num_layers=num_layers, \n",
    "                            batch_first=True, dropout=dropout, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # 双向 LSTM 的输出维度是 hidden_dim * 2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]  # 取最后一个时间步的输出\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# 数据预处理\n",
    "def preprocess_data(df, target_column, sequence_length):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    \n",
    "    # 处理类别不平衡\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X, y = smote.fit_resample(X, y)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # 将数据转换为 LSTM 的输入格式 (batch_size, sequence_length, input_size)\n",
    "    num_samples = X.shape[0]\n",
    "    num_features = X.shape[1]\n",
    "    if num_features % sequence_length != 0:\n",
    "        print(num_features)\n",
    "        raise ValueError(\"特征数不能被序列长度整除，请调整 sequence_length。\")\n",
    "    input_size = num_features // sequence_length\n",
    "    X = X.reshape(num_samples, sequence_length, input_size)\n",
    "    return X, y\n",
    "\n",
    "# 模型训练函数\n",
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 模型评估函数\n",
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]  # 取正类的概率\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    # 计算指标\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "    roc_auc = roc_auc_score(all_labels, all_probs) if len(set(all_labels)) > 1 else 0.0\n",
    "    return val_loss / len(test_loader), accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# Optuna 目标函数\n",
    "def objective(trial, X_train, y_train, X_test, y_test, train_loader, test_loader, device):\n",
    "    global best_accuracy, best_model_state\n",
    "\n",
    "    # 超参数搜索空间\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 512)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-3, log=True)\n",
    "\n",
    "    # 模型初始化\n",
    "    model = BiLSTMModel(input_size=X_train.shape[2], hidden_dim=hidden_dim, num_layers=num_layers, \n",
    "                        dropout=dropout, output_dim=2).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # 模型训练和评估\n",
    "    for epoch in range(20):  # 每次试验训练 20 个 epoch\n",
    "        train_model(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, accuracy, precision, recall, f1, roc_auc = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "        # 打印每轮指标\n",
    "        print(f\"Trial {trial.number} | Epoch {epoch + 1}: Loss={val_loss:.4f}, \"\n",
    "              f\"Accuracy={accuracy:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, \"\n",
    "              f\"F1={f1:.4f}, ROC_AUC={roc_auc:.4f}\")\n",
    "\n",
    "        # 保存最佳模型\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    global train_loader, test_loader, device, best_accuracy, best_model_state\n",
    "\n",
    "    # 初始化全局变量\n",
    "    best_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "\n",
    "    # 加载数据\n",
    "    target_column = 'match_flag'\n",
    "    sequence_length = 34  # 请根据特征数调整此参数\n",
    "    df = pd.read_csv('cleaned_aki_data3.csv')\n",
    "    X, y = preprocess_data(df, target_column, sequence_length)\n",
    "\n",
    "    # 检查预处理后的数据形状\n",
    "    print(\"X shape after preprocessing:\", X.shape)  # 应为 (num_samples, sequence_length, input_size)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    # 数据加载器\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "    test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # 贝叶斯优化\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_test, y_test, train_loader, test_loader, device), n_trials=50)\n",
    "\n",
    "    # 输出最佳参数\n",
    "    print(\"Best parameters:\", study.best_params)\n",
    "    print(\"Best accuracy:\", best_accuracy)\n",
    "\n",
    "    # 保存最佳模型\n",
    "    torch.save(best_model_state, \"best_bilstm_model.pth\")\n",
    "    print(\"Best model saved as 'best_bilstm_model.pth'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3218b2e-80be-4db5-be4a-97b00a3d440a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d3aebcc-2b24-4f30-bf77-cb770bec7d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\deeplearning\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "C:\\Users\\admin\\.conda\\envs\\deeplearning\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ReduceLROnPlateau' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 177\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 177\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 162\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    160\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[0;32m    161\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m--> 162\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m \u001b[43mReduceLROnPlateau\u001b[49m(optimizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# 学习率调度器\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# 训练和评估\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ReduceLROnPlateau' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# 定义 LSTM 模型\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, num_layers, dropout, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_dim, num_layers=num_layers, \n",
    "                            batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]  # 取最后一个时间步的输出\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# 数据预处理\n",
    "def preprocess_data(df, target_column, sequence_length):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # 将数据转换为 LSTM 的输入格式 (batch_size, sequence_length, input_size)\n",
    "    num_samples = X.shape[0]\n",
    "    num_features = X.shape[1]\n",
    "    if num_features % sequence_length != 0:\n",
    "        raise ValueError(\"特征数不能被序列长度整除，请调整 sequence_length。\")\n",
    "    input_size = num_features // sequence_length\n",
    "    X = X.reshape(num_samples, sequence_length, input_size)\n",
    "    return X, y\n",
    "\n",
    "# 模型训练函数\n",
    "def train_model(model, train_loader, criterion, optimizer, device, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# 模型评估函数\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]  # 取正类的概率\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    # 计算指标\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "    roc_auc = roc_auc_score(all_labels, all_probs) if len(set(all_labels)) > 1 else 0.0\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, \"\n",
    "          f\"F1: {f1:.4f}, ROC_AUC: {roc_auc:.4f}\")\n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    # 加载新数据集\n",
    "    target_column = 'match_flag'  # 根据新数据集调整目标列名\n",
    "    sequence_length = 7         # 根据新数据集调整序列长度\n",
    "    df = pd.read_csv('cleaned_blood_gas_data.csv')\n",
    "    # df = pd.read_csv('cleaned_aki_urine_labs_sampled_with_flags.csv')  # 替换为新的数据集路径\n",
    "    X, y = preprocess_data(df, target_column, sequence_length)\n",
    "\n",
    "    # 数据集划分\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    # 数据加载器\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "    test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # 加载保存的模型\n",
    "    saved_model_path = \"best_lstm_model.pth\"\n",
    "    if not os.path.exists(saved_model_path):\n",
    "        raise FileNotFoundError(f\"Saved model not found at {saved_model_path}\")\n",
    "    \n",
    "    # 重新加载模型\n",
    "    input_size = X_train.shape[2]\n",
    "    hidden_dim = 236  # 从保存的模型中获取\n",
    "    num_layers = 1    # 从保存的模型中获取\n",
    "    dropout = 0.0     # 从保存的模型中获取\n",
    "    output_dim = 2    # 从保存的模型中获取\n",
    "    model = LSTMModel(input_size, hidden_dim, num_layers, dropout, output_dim).to(device)\n",
    "    \n",
    "    # 加载保存的权重\n",
    "    saved_state_dict = torch.load(saved_model_path)\n",
    "    model_dict = model.state_dict()\n",
    "    \n",
    "    # 部分迁移权重\n",
    "    for name, param in saved_state_dict.items():\n",
    "        if name in model_dict and param.shape == model_dict[name].shape:\n",
    "            model_dict[name] = param\n",
    "        else:\n",
    "            print(f\"Skipping weight {name} due to shape mismatch.\")\n",
    "    model.load_state_dict(model_dict)\n",
    "\n",
    "    # 再训练\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    train_model(model, train_loader, criterion, optimizer, device, epochs=10)\n",
    "\n",
    "    # 评估模型\n",
    "    evaluate_model(model, test_loader, device)\n",
    "\n",
    "    # 保存新的模型\n",
    "    # torch.save(model.state_dict(), \"new_best_lstm_model.pth\")\n",
    "    # print(\"Updated model saved as 'new_best_lstm_model.pth'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ca1c5de-e771-4a4b-bde3-1b1d95e687b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm.weight_ih_l0: torch.Size([944, 4])\n",
      "lstm.weight_hh_l0: torch.Size([944, 236])\n",
      "lstm.bias_ih_l0: torch.Size([944])\n",
      "lstm.bias_hh_l0: torch.Size([944])\n",
      "fc.weight: torch.Size([2, 236])\n",
      "fc.bias: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "saved_state_dict = torch.load('best_lstm_model.pth')\n",
    "for key, value in saved_state_dict.items():\n",
    "    print(f\"{key}: {value.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e9107-8645-475f-a13b-533f9f73558b",
   "metadata": {},
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48cd3d35-ddcc-4fdd-966b-561005775fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\deeplearning\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([40000, 1])) must be the same as input size (torch.Size([]))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 98\u001b[0m\n\u001b[0;32m     96\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     97\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data1, data2)\n\u001b[1;32m---> 98\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    100\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\loss.py:713\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 713\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\torch\\nn\\functional.py:2958\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   2955\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   2957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[1;32m-> 2958\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m   2960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[1;31mValueError\u001b[0m: Target size (torch.Size([40000, 1])) must be the same as input size (torch.Size([]))"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# 检测设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 定义单个 GAT 模块\n",
    "class GATBlock(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=1):\n",
    "        super(GATBlock, self).__init__()\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads, concat=True)\n",
    "        self.gat2 = GATConv(hidden_channels * heads, out_channels, heads=heads, concat=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.gat1(x, edge_index))\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 定义多模态组合模型\n",
    "class CombinedGATModel(nn.Module):\n",
    "    def __init__(self, in_channels1, in_channels2, hidden_channels, out_channels, heads=1):\n",
    "        super(CombinedGATModel, self).__init__()\n",
    "        self.gat1 = GATBlock(in_channels1, hidden_channels, out_channels, heads)\n",
    "        self.gat2 = GATBlock(in_channels2, hidden_channels, out_channels, heads)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data1, data2):\n",
    "        x1 = self.gat1(data1.x, data1.edge_index)\n",
    "        x2 = self.gat2(data2.x, data2.edge_index)\n",
    "        combined = torch.cat([x1.mean(dim=0), x2.mean(dim=0)], dim=0)  # 节点特征聚合\n",
    "        out = self.fc(combined)\n",
    "        return out\n",
    "\n",
    "# 数据加载函数\n",
    "def load_graph_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    x = torch.tensor(df.iloc[:, :-1].values, dtype=torch.float32)\n",
    "    y = torch.tensor(df['match_flag'].values, dtype=torch.float32)\n",
    "    edge_index = torch.randint(0, x.size(0), (2, x.size(0) * 2))  # 随机生成边\n",
    "    return Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "def prepare_data(file_path):\n",
    "    data = load_graph_data(file_path)\n",
    "    num_nodes = data.x.size(0)\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "    train_indices, test_indices = train_test_split(range(num_nodes), test_size=0.3, random_state=42)\n",
    "    train_mask[train_indices] = True\n",
    "    test_mask[test_indices] = True\n",
    "\n",
    "    data.train_mask = train_mask\n",
    "    data.test_mask = test_mask\n",
    "    return data\n",
    "\n",
    "# 加载两个数据集\n",
    "data1 = prepare_data('cleaned_aki_data1.csv')\n",
    "data2 = prepare_data('cleaned_aki_data2.csv')\n",
    "\n",
    "train_loader1 = DataLoader([data1], batch_size=1, shuffle=False)\n",
    "train_loader2 = DataLoader([data2], batch_size=1, shuffle=False)\n",
    "\n",
    "# 初始化模型\n",
    "in_channels = data1.x.shape[1]\n",
    "hidden_channels = 16\n",
    "out_channels = 32\n",
    "model = CombinedGATModel(in_channels, in_channels, hidden_channels, out_channels, heads=2).to(device)\n",
    "\n",
    "# 损失函数和优化器\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "epochs = 100\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data1, data2 in zip(train_loader1, train_loader2):\n",
    "        data1, data2 = data1[0].to(device), data2[0].to(device)  # data1 和 data2 是 Data 对象\n",
    "        labels = data1.y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data1, data2)\n",
    "        loss = loss_fn(output.squeeze(), labels.unsqueeze(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    losses.append(total_loss)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # 评估模型性能\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for data1, data2 in zip(train_loader1, train_loader2):\n",
    "            data1, data2 = data1[0].to(device), data2[0].to(device)\n",
    "            labels = data1.y.to(device)\n",
    "\n",
    "            outputs = model(data1, data2).squeeze()\n",
    "            predictions = torch.sigmoid(outputs) > 0.5\n",
    "            y_true.extend(labels.cpu().tolist())\n",
    "            y_pred.extend(predictions.cpu().tolist())\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Accuracy after Epoch {epoch+1}: {accuracy:.4f}\")\n",
    "\n",
    "# 保存模型\n",
    "model_path = 'gat_model_combined.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f'Model saved to {model_path}')\n",
    "\n",
    "# 可视化损失与精度\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs + 1), losses, label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs + 1), accuracies, label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "582b3b5b-9c8b-4185-8dc5-cf2ff39f3526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\deeplearning\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Train Loss: 0.6933, Val Loss: 0.6930\n",
      "Accuracy: 0.5000, Precision: 0.0000, Recall: 0.0000, F1: 0.0000, AUC: 0.5764\n",
      "Epoch 2:\n",
      "Train Loss: 0.6929, Val Loss: 0.6921\n",
      "Accuracy: 0.5333, Precision: 0.6406, Recall: 0.1518, F1: 0.2455, AUC: 0.5746\n",
      "Epoch 3:\n",
      "Train Loss: 0.6922, Val Loss: 0.6916\n",
      "Accuracy: 0.5337, Precision: 0.5199, Recall: 0.8813, F1: 0.6540, AUC: 0.5735\n",
      "Epoch 4:\n",
      "Train Loss: 0.6917, Val Loss: 0.6908\n",
      "Accuracy: 0.5333, Precision: 0.5254, Recall: 0.6878, F1: 0.5957, AUC: 0.5771\n",
      "Epoch 5:\n",
      "Train Loss: 0.6907, Val Loss: 0.6901\n",
      "Accuracy: 0.5580, Precision: 0.6023, Recall: 0.3415, F1: 0.4359, AUC: 0.5786\n",
      "Epoch 6:\n",
      "Train Loss: 0.6902, Val Loss: 0.6892\n",
      "Accuracy: 0.5582, Precision: 0.5641, Recall: 0.5118, F1: 0.5367, AUC: 0.5780\n",
      "Epoch 7:\n",
      "Train Loss: 0.6892, Val Loss: 0.6882\n",
      "Accuracy: 0.5367, Precision: 0.5298, Recall: 0.6520, F1: 0.5846, AUC: 0.5774\n",
      "Epoch 8:\n",
      "Train Loss: 0.6882, Val Loss: 0.6871\n",
      "Accuracy: 0.5482, Precision: 0.5445, Recall: 0.5897, F1: 0.5662, AUC: 0.5794\n",
      "Epoch 9:\n",
      "Train Loss: 0.6870, Val Loss: 0.6860\n",
      "Accuracy: 0.5607, Precision: 0.5675, Recall: 0.5108, F1: 0.5377, AUC: 0.5816\n",
      "Epoch 10:\n",
      "Train Loss: 0.6856, Val Loss: 0.6848\n",
      "Accuracy: 0.5457, Precision: 0.5394, Recall: 0.6253, F1: 0.5792, AUC: 0.5828\n",
      "Epoch 11:\n",
      "Train Loss: 0.6848, Val Loss: 0.6835\n",
      "Accuracy: 0.5597, Precision: 0.5644, Recall: 0.5240, F1: 0.5434, AUC: 0.5858\n",
      "Epoch 12:\n",
      "Train Loss: 0.6838, Val Loss: 0.6822\n",
      "Accuracy: 0.5548, Precision: 0.5509, Recall: 0.5935, F1: 0.5714, AUC: 0.5879\n",
      "Epoch 13:\n",
      "Train Loss: 0.6826, Val Loss: 0.6810\n",
      "Accuracy: 0.5637, Precision: 0.5696, Recall: 0.5212, F1: 0.5443, AUC: 0.5919\n",
      "Epoch 14:\n",
      "Train Loss: 0.6813, Val Loss: 0.6799\n",
      "Accuracy: 0.5610, Precision: 0.5547, Recall: 0.6187, F1: 0.5849, AUC: 0.5951\n",
      "Epoch 15:\n",
      "Train Loss: 0.6802, Val Loss: 0.6796\n",
      "Accuracy: 0.5713, Precision: 0.6054, Recall: 0.4098, F1: 0.4888, AUC: 0.5998\n",
      "Epoch 16:\n",
      "Train Loss: 0.6809, Val Loss: 0.6798\n",
      "Accuracy: 0.5653, Precision: 0.5488, Recall: 0.7343, F1: 0.6281, AUC: 0.6012\n",
      "Epoch 17:\n",
      "Train Loss: 0.6813, Val Loss: 0.6772\n",
      "Accuracy: 0.5764, Precision: 0.5880, Recall: 0.5108, F1: 0.5467, AUC: 0.6048\n",
      "Epoch 18:\n",
      "Train Loss: 0.6777, Val Loss: 0.6776\n",
      "Accuracy: 0.5724, Precision: 0.6077, Recall: 0.4087, F1: 0.4887, AUC: 0.6076\n",
      "Epoch 19:\n",
      "Train Loss: 0.6783, Val Loss: 0.6764\n",
      "Accuracy: 0.5770, Precision: 0.5678, Recall: 0.6452, F1: 0.6040, AUC: 0.6092\n",
      "Epoch 20:\n",
      "Train Loss: 0.6774, Val Loss: 0.6757\n",
      "Accuracy: 0.5801, Precision: 0.5707, Recall: 0.6465, F1: 0.6062, AUC: 0.6113\n",
      "Epoch 21:\n",
      "Train Loss: 0.6764, Val Loss: 0.6752\n",
      "Accuracy: 0.5814, Precision: 0.6061, Recall: 0.4652, F1: 0.5264, AUC: 0.6138\n",
      "Epoch 22:\n",
      "Train Loss: 0.6769, Val Loss: 0.6740\n",
      "Accuracy: 0.5865, Precision: 0.5924, Recall: 0.5545, F1: 0.5728, AUC: 0.6155\n",
      "Epoch 23:\n",
      "Train Loss: 0.6747, Val Loss: 0.6743\n",
      "Accuracy: 0.5819, Precision: 0.5683, Recall: 0.6818, F1: 0.6199, AUC: 0.6172\n",
      "Epoch 24:\n",
      "Train Loss: 0.6756, Val Loss: 0.6729\n",
      "Accuracy: 0.5929, Precision: 0.6066, Recall: 0.5287, F1: 0.5650, AUC: 0.6195\n",
      "Epoch 25:\n",
      "Train Loss: 0.6743, Val Loss: 0.6727\n",
      "Accuracy: 0.5867, Precision: 0.6101, Recall: 0.4802, F1: 0.5374, AUC: 0.6216\n",
      "Epoch 26:\n",
      "Train Loss: 0.6742, Val Loss: 0.6730\n",
      "Accuracy: 0.5818, Precision: 0.5658, Recall: 0.7038, F1: 0.6273, AUC: 0.6233\n",
      "Epoch 27:\n",
      "Train Loss: 0.6744, Val Loss: 0.6709\n",
      "Accuracy: 0.5958, Precision: 0.6017, Recall: 0.5663, F1: 0.5835, AUC: 0.6253\n",
      "Epoch 28:\n",
      "Train Loss: 0.6723, Val Loss: 0.6710\n",
      "Accuracy: 0.5940, Precision: 0.6186, Recall: 0.4903, F1: 0.5470, AUC: 0.6271\n",
      "Epoch 29:\n",
      "Train Loss: 0.6729, Val Loss: 0.6706\n",
      "Accuracy: 0.5898, Precision: 0.5766, Recall: 0.6760, F1: 0.6224, AUC: 0.6288\n",
      "Epoch 30:\n",
      "Train Loss: 0.6713, Val Loss: 0.6692\n",
      "Accuracy: 0.5996, Precision: 0.6021, Recall: 0.5872, F1: 0.5945, AUC: 0.6303\n",
      "Epoch 31:\n",
      "Train Loss: 0.6707, Val Loss: 0.6694\n",
      "Accuracy: 0.5955, Precision: 0.6237, Recall: 0.4815, F1: 0.5435, AUC: 0.6318\n",
      "Epoch 32:\n",
      "Train Loss: 0.6708, Val Loss: 0.6697\n",
      "Accuracy: 0.5903, Precision: 0.5729, Recall: 0.7100, F1: 0.6341, AUC: 0.6334\n",
      "Epoch 33:\n",
      "Train Loss: 0.6711, Val Loss: 0.6675\n",
      "Accuracy: 0.6008, Precision: 0.6128, Recall: 0.5477, F1: 0.5784, AUC: 0.6347\n",
      "Epoch 34:\n",
      "Train Loss: 0.6692, Val Loss: 0.6673\n",
      "Accuracy: 0.5995, Precision: 0.6212, Recall: 0.5098, F1: 0.5601, AUC: 0.6362\n",
      "Epoch 35:\n",
      "Train Loss: 0.6679, Val Loss: 0.6683\n",
      "Accuracy: 0.5962, Precision: 0.5772, Recall: 0.7188, F1: 0.6403, AUC: 0.6375\n",
      "Epoch 36:\n",
      "Train Loss: 0.6690, Val Loss: 0.6664\n",
      "Accuracy: 0.6010, Precision: 0.6248, Recall: 0.5057, F1: 0.5590, AUC: 0.6386\n",
      "Epoch 37:\n",
      "Train Loss: 0.6680, Val Loss: 0.6653\n",
      "Accuracy: 0.6038, Precision: 0.6100, Recall: 0.5760, F1: 0.5925, AUC: 0.6398\n",
      "Epoch 38:\n",
      "Train Loss: 0.6668, Val Loss: 0.6655\n",
      "Accuracy: 0.6004, Precision: 0.5894, Recall: 0.6618, F1: 0.6235, AUC: 0.6411\n",
      "Epoch 39:\n",
      "Train Loss: 0.6673, Val Loss: 0.6650\n",
      "Accuracy: 0.6024, Precision: 0.6284, Recall: 0.5013, F1: 0.5577, AUC: 0.6421\n",
      "Epoch 40:\n",
      "Train Loss: 0.6668, Val Loss: 0.6644\n",
      "Accuracy: 0.6008, Precision: 0.5917, Recall: 0.6507, F1: 0.6198, AUC: 0.6434\n",
      "Epoch 41:\n",
      "Train Loss: 0.6661, Val Loss: 0.6634\n",
      "Accuracy: 0.6059, Precision: 0.6055, Recall: 0.6078, F1: 0.6067, AUC: 0.6445\n",
      "Epoch 42:\n",
      "Train Loss: 0.6644, Val Loss: 0.6634\n",
      "Accuracy: 0.6042, Precision: 0.6274, Recall: 0.5135, F1: 0.5648, AUC: 0.6455\n",
      "Epoch 43:\n",
      "Train Loss: 0.6648, Val Loss: 0.6647\n",
      "Accuracy: 0.6043, Precision: 0.5839, Recall: 0.7260, F1: 0.6473, AUC: 0.6469\n",
      "Epoch 44:\n",
      "Train Loss: 0.6651, Val Loss: 0.6639\n",
      "Accuracy: 0.6027, Precision: 0.6441, Recall: 0.4588, F1: 0.5359, AUC: 0.6473\n",
      "Epoch 45:\n",
      "Train Loss: 0.6656, Val Loss: 0.6623\n",
      "Accuracy: 0.6082, Precision: 0.5966, Recall: 0.6688, F1: 0.6306, AUC: 0.6484\n",
      "Epoch 46:\n",
      "Train Loss: 0.6635, Val Loss: 0.6613\n",
      "Accuracy: 0.6118, Precision: 0.6085, Recall: 0.6265, F1: 0.6174, AUC: 0.6491\n",
      "Epoch 47:\n",
      "Train Loss: 0.6633, Val Loss: 0.6621\n",
      "Accuracy: 0.6017, Precision: 0.6331, Recall: 0.4837, F1: 0.5484, AUC: 0.6496\n",
      "Epoch 48:\n",
      "Train Loss: 0.6638, Val Loss: 0.6632\n",
      "Accuracy: 0.6062, Precision: 0.5840, Recall: 0.7383, F1: 0.6522, AUC: 0.6509\n",
      "Epoch 49:\n",
      "Train Loss: 0.6648, Val Loss: 0.6619\n",
      "Accuracy: 0.6021, Precision: 0.6385, Recall: 0.4707, F1: 0.5419, AUC: 0.6510\n",
      "Epoch 50:\n",
      "Train Loss: 0.6631, Val Loss: 0.6598\n",
      "Accuracy: 0.6153, Precision: 0.6110, Recall: 0.6350, F1: 0.6228, AUC: 0.6520\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATv2Conv  # 使用 GATv2\n",
    "from torch_geometric.data import DataLoader as GeometricDataLoader\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# 数据预处理\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# 构建 KNN 图\n",
    "def build_knn_graph(X, y, k=10):\n",
    "    # 使用 KNN 构建稀疏邻接矩阵\n",
    "    edge_index = kneighbors_graph(X, k, mode='connectivity', include_self=False)\n",
    "    edge_index = edge_index.nonzero()  # 转换为 COO 格式\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "    \n",
    "    # 构建图数据\n",
    "    x = torch.tensor(X, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    graph = Data(x=x, edge_index=edge_index, y=y)\n",
    "    return graph\n",
    "\n",
    "# 加载数据\n",
    "def load_data(file_path, target_column, batch_size=64, k=5):\n",
    "    df = pd.read_csv(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    # 构建训练图和测试图\n",
    "    train_graph = build_knn_graph(X_train, y_train, k=k)\n",
    "    test_graph = build_knn_graph(X_test, y_test, k=k)\n",
    "    \n",
    "    # 构建 DataLoader\n",
    "    train_loader = GeometricDataLoader([train_graph], batch_size=batch_size, shuffle=True)\n",
    "    test_loader = GeometricDataLoader([test_graph], batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# GATv2 模型\n",
    "class GATv2(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, heads=4, dropout=0.1):\n",
    "        super(GATv2, self).__init__()\n",
    "        self.conv1 = GATv2Conv(input_dim, hidden_dim, heads=heads, dropout=dropout)\n",
    "        self.conv2 = GATv2Conv(hidden_dim * heads, hidden_dim, heads=1, dropout=dropout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 128),  # 增加全连接层维度\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # 检查输入数据的形状和类型\n",
    "        if x.dim() != 2:\n",
    "            raise ValueError(f\"Expected input x to have 2 dimensions, but got {x.dim()}\")\n",
    "        if edge_index.dim() != 2:\n",
    "            raise ValueError(f\"Expected edge_index to have 2 dimensions, but got {edge_index.dim()}\")\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze(1)  # 输出 (num_nodes, )\n",
    "\n",
    "# 训练模型\n",
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data.x, data.edge_index)  # 单图训练\n",
    "        loss = criterion(outputs, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# 评估模型\n",
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_pred_proba = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            outputs = model(data.x, data.edge_index)  # 单图评估\n",
    "            loss = criterion(outputs, data.y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            probs = torch.sigmoid(outputs)\n",
    "\n",
    "            y_true.extend(data.y.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_pred_proba.extend(probs.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred_proba)\n",
    "\n",
    "    return total_loss / len(test_loader), accuracy, precision, recall, f1, auc\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    file_path = 'cleaned_aki_data1.csv'  # 只使用一个 CSV 文件\n",
    "    target_column = 'match_flag'\n",
    "\n",
    "    # 加载数据\n",
    "    train_loader, test_loader = load_data(file_path, target_column, k=5)  # 使用 KNN 图，k=5\n",
    "\n",
    "    # 模型参数\n",
    "    input_dim = next(iter(train_loader))[0].x.shape[1]\n",
    "    hidden_dim = 128  # 增加隐藏层维度\n",
    "    output_dim = 1    # 输出维度\n",
    "    heads = 8         # GATv2 的注意力头数\n",
    "    dropout = 0.3\n",
    "    epochs = 50       # 增加训练轮数\n",
    "\n",
    "    # 模型初始化\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = GATv2(input_dim, hidden_dim, output_dim, heads=heads, dropout=dropout).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)  # 学习率调度器\n",
    "\n",
    "    # 训练和评估\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_model(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, accuracy, precision, recall, f1, auc = evaluate_model(model, test_loader, criterion, device)\n",
    "        \n",
    "        # 更新学习率\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}:\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b56222-13e5-4cdf-92e1-bf0048c9f91f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 65\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# 在第一个数据集上训练初始模型\u001b[39;00m\n\u001b[0;32m     64\u001b[0m model \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 65\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# 在第一个数据集的验证集上评估模型\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m在第一个数据集的验证集上评估模型：\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:532\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    531\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 532\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:610\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    603\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    604\u001b[0m             y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    605\u001b[0m             raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    606\u001b[0m             sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    607\u001b[0m         )\n\u001b[0;32m    609\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 610\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:245\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    242\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    244\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 245\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    248\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    249\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[0;32m    250\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    258\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, matthews_corrcoef\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pickle\n",
    "\n",
    "# 定义评估模型的函数\n",
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # 使用随机过采样处理类别不平衡\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "    y_pred_resampled = model.predict(X_resampled)\n",
    "    y_pred_proba_resampled = model.predict_proba(X_resampled)[:, 1]\n",
    "\n",
    "    # 计算评估指标\n",
    "    fpr, tpr, thresholds = roc_curve(y_resampled, y_pred_proba_resampled)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    f1 = f1_score(y_resampled, y_pred_resampled)\n",
    "    precision = precision_score(y_resampled, y_pred_resampled)\n",
    "    recall = recall_score(y_resampled, y_pred_resampled)\n",
    "    mcc = matthews_corrcoef(y_resampled, y_pred_resampled)\n",
    "\n",
    "    # 计算校准曲线\n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(y_resampled, y_pred_proba_resampled, n_bins=10)\n",
    "    reg = LinearRegression(fit_intercept=False).fit(mean_predicted_value.reshape(-1, 1), fraction_of_positives.reshape(-1, 1))\n",
    "    calibration_slope = reg.coef_[0][0]\n",
    "    calibration_intercept = reg.intercept_\n",
    "\n",
    "    print(f\"AUC: {auc_score:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, MCC: {mcc:.4f}\")\n",
    "    print(f\"Calibration Slope: {calibration_slope:.4f}, Calibration Intercept: {calibration_intercept:.4f}\")\n",
    "\n",
    "    return auc_score, f1, precision, recall, mcc, calibration_slope, calibration_intercept\n",
    "\n",
    "# 加载数据集\n",
    "file_path1 = 'cleaned_aki_data1.csv'\n",
    "file_path2 = 'cleaned_aki_data2.csv'\n",
    "target_column = 'match_flag'\n",
    "\n",
    "# 加载第一个数据集\n",
    "data1 = pd.read_csv(file_path1)\n",
    "X1 = data1.drop(columns=[target_column])  # 特征\n",
    "y1 = data1[target_column]  # 标签\n",
    "\n",
    "# 将第一个数据集分为训练集和验证集\n",
    "X_train1, X_val1, y_train1, y_val1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "X_train1 = scaler.fit_transform(X_train1)\n",
    "X_val1 = scaler.transform(X_val1)\n",
    "\n",
    "# 在第一个数据集上训练初始模型\n",
    "model = GradientBoostingClassifier(random_state=42)\n",
    "model.fit(X_train1, y_train1)\n",
    "\n",
    "# 在第一个数据集的验证集上评估模型\n",
    "print(\"在第一个数据集的验证集上评估模型：\")\n",
    "evaluate_model(model, X_val1, y_val1)\n",
    "\n",
    "# 加载第二个数据集\n",
    "data2 = pd.read_csv(file_path2)\n",
    "X2 = data2.drop(columns=[target_column])  # 特征\n",
    "y2 = data2[target_column]  # 标签\n",
    "\n",
    "# 使用相同的标准化器对第二个数据集进行标准化\n",
    "X2 = scaler.transform(X2)\n",
    "\n",
    "# 在第二个数据集上继续训练模型\n",
    "model.fit(X2, y2)\n",
    "\n",
    "# 在第二个数据集上评估最终模型\n",
    "print(\"在第二个数据集上评估最终模型：\")\n",
    "evaluate_model(model, X2, y2)\n",
    "\n",
    "# 保存最终模型\n",
    "model_filename = 'final_aki_model.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(f\"最终模型已保存到 {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11f8a4ca-34a8-42c9-b804-78037f663750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26380\\2656226072.py:389: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  class_weights = 1. / class_counts\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 421\u001b[0m\n\u001b[0;32m    418\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 421\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[25], line 297\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    295\u001b[0m criterion1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss(pos_weight\u001b[38;5;241m=\u001b[39mcalc_pos_weight(y))\n\u001b[0;32m    296\u001b[0m scheduler1 \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer1, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m--> 297\u001b[0m model1, hist1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mcriterion1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model1.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;66;03m# 训练模型2\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining Model 2...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[25], line 235\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, train_loader, val_loader, optimizer, criterion, scheduler, epochs, save_path)\u001b[0m\n\u001b[0;32m    232\u001b[0m         y_probs\u001b[38;5;241m.\u001b[39mextend(torch\u001b[38;5;241m.\u001b[39msigmoid(outputs)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# 计算指标\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(y_probs)\n\u001b[0;32m    237\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_true, preds)\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:627\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    625\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[0;32m    626\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 627\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    636\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[0;32m    637\u001b[0m         y_true,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    640\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    641\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\metrics\\_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:382\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m     )\n\u001b[0;32m    387\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, roc_auc_score,\n",
    "                             roc_curve)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import (DataLoader, TensorDataset,\n",
    "                              WeightedRandomSampler)\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import Compose\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 固定随机种子\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# --------------------------\n",
    "# 时间序列增强模块\n",
    "# --------------------------\n",
    "class TemporalAugmentation:\n",
    "    \"\"\"时间序列数据增强\"\"\"\n",
    "    def __init__(self, sigma=0.1, p=0.5):\n",
    "        self.sigma = sigma  # 噪声强度\n",
    "        self.p = p  # 应用概率\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if np.random.rand() < self.p:\n",
    "            noise = torch.randn_like(x) * self.sigma\n",
    "            return x + noise\n",
    "        return x\n",
    "\n",
    "# --------------------------\n",
    "# 残差块模块（改进版）\n",
    "# --------------------------\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"带通道注意力机制的残差块\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        # 通道注意力机制\n",
    "        self.ca = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Conv1d(out_channels, out_channels // 8, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(out_channels // 8, out_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, 1,\n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.downsample(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # 通道注意力\n",
    "        ca_weight = self.ca(out)\n",
    "        out = out * ca_weight\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# --------------------------\n",
    "# 改进的CNN模型\n",
    "# --------------------------\n",
    "class DynamicCNN(nn.Module):\n",
    "    \"\"\"带数据增强和时间感知的CNN\"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        # 数据增强层\n",
    "        self.augment = Compose([TemporalAugmentation(sigma=0.05, p=0.3)])\n",
    "\n",
    "        # 特征预处理\n",
    "        self.preprocess = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        # 残差卷积模块\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 3, padding=1),\n",
    "            ResidualBlock(16, 16),\n",
    "            nn.MaxPool1d(2),\n",
    "            ResidualBlock(16, 32),\n",
    "            nn.AdaptiveAvgPool1d(8)\n",
    "        )\n",
    "\n",
    "        # 动态计算全连接输入维度\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.randn(2, input_dim)\n",
    "            dummy = self.preprocess(dummy).unsqueeze(1)\n",
    "            dummy = self.conv_layers(dummy)\n",
    "            self.fc_input = dummy.view(dummy.size(0), -1).shape[1]\n",
    "\n",
    "        # 分类器\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.fc_input, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, augment=True):\n",
    "        if self.training and augment:\n",
    "            x = self.augment(x)\n",
    "        x = self.preprocess(x).unsqueeze(1)\n",
    "        features = self.conv_layers(x).view(x.size(0), -1)\n",
    "        return self.classifier(features).squeeze(1)\n",
    "\n",
    "# --------------------------\n",
    "# 注意力融合模块\n",
    "# --------------------------\n",
    "class AttentionFusion(nn.Module):\n",
    "    \"\"\"基于注意力的模型融合\"\"\"\n",
    "    def __init__(self, modelA, modelB):\n",
    "        super().__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(2, 8),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(8, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        with torch.no_grad():\n",
    "            logitA = self.modelA(x1)\n",
    "            logitB = self.modelB(x2)\n",
    "        concat_logits = torch.stack([logitA, logitB], dim=1)\n",
    "        weights = self.attention(concat_logits)\n",
    "        probA = torch.sigmoid(logitA)\n",
    "        probB = torch.sigmoid(logitB)\n",
    "        return (weights[:, 0] * probA) + (weights[:, 1] * probB)\n",
    "\n",
    "# --------------------------\n",
    "# 模型解释模块\n",
    "# --------------------------\n",
    "def feature_importance(model, X, feature_names, n_samples=1000):\n",
    "    model.eval()\n",
    "    baseline = torch.mean(X, dim=0, keepdim=True)\n",
    "    delta_list = []\n",
    "\n",
    "    # 确保特征数量与特征名称数量一致\n",
    "    assert X.shape[1] == len(feature_names), \"特征数量与特征名称不匹配\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(X.shape[1])):\n",
    "            perturbed = X.clone()\n",
    "            perturbed[:, i] = baseline[0, i]\n",
    "            orig_output = torch.sigmoid(model(X))\n",
    "            perturbed_output = torch.sigmoid(model(perturbed))\n",
    "            delta = torch.mean(torch.abs(orig_output - perturbed_output)).item()\n",
    "            delta_list.append(delta)\n",
    "\n",
    "    # 动态确定显示数量\n",
    "    display_num = min(20, len(delta_list))  # 取特征数量和前20中的较小值\n",
    "    indices = np.argsort(delta_list)[::-1][:display_num]  # 只取实际存在的索引\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(range(display_num), [delta_list[i] for i in indices][::-1])\n",
    "    plt.yticks(range(display_num), [feature_names[i] for i in indices][::-1])\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.title(f'Top {display_num} Important Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# 训练评估模块（优化版）\n",
    "# --------------------------\n",
    "def train_and_evaluate(model, train_loader, val_loader, optimizer, criterion,\n",
    "                       scheduler=None, epochs=30, save_path='best_model.pth'):\n",
    "    history = {'train_loss': [], 'val_auc': [], 'val_f1': [],\n",
    "               'val_accuracy': [], 'val_precision': []}\n",
    "    best_auc = 0\n",
    "    early_stop = EarlyStopper(patience=10)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        y_true, y_probs = [], []\n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                X = X.to(device)\n",
    "                outputs = model(X)\n",
    "                y_true.extend(y.cpu().numpy())\n",
    "                y_probs.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "\n",
    "        # 计算指标\n",
    "        auc = roc_auc_score(y_true, y_probs)\n",
    "        preds = np.round(y_probs)\n",
    "        f1 = f1_score(y_true, preds)\n",
    "        accuracy = accuracy_score(y_true, preds)\n",
    "        precision = precision_score(y_true, preds)\n",
    "\n",
    "        history['val_auc'].append(auc)\n",
    "        history['val_f1'].append(f1)\n",
    "        history['val_accuracy'].append(accuracy)\n",
    "        history['val_precision'].append(precision)\n",
    "\n",
    "        # 学习率调度\n",
    "        if scheduler:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(auc)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val AUC: {auc:.4f} | F1: {f1:.4f} | Accuracy: {accuracy:.4f} | Precision: {precision:.4f}\")\n",
    "\n",
    "        # 保存最佳模型\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Saved new best model with AUC: {auc:.4f}\")\n",
    "\n",
    "        if early_stop(auc):\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    return model, history\n",
    "\n",
    "# --------------------------\n",
    "# 主流程\n",
    "# --------------------------\n",
    "def main():\n",
    "    # 加载数据\n",
    "    df1 = pd.read_csv('./data/cleaned_jigan.csv')\n",
    "    df2 = pd.read_csv('./data/cleaned_labs_first_day.csv')\n",
    "    target = 'match_flag'\n",
    "\n",
    "    # 数据对齐\n",
    "    min_len = min(len(df1), len(df2))\n",
    "    df1 = df1.iloc[:min_len].reset_index(drop=True)\n",
    "    df2 = df2.iloc[:min_len].reset_index(drop=True)\n",
    "\n",
    "    # 特征工程\n",
    "    X1 = df1.drop(columns=target).values.astype(np.float32)\n",
    "    X2 = df2.drop(columns=target).values.astype(np.float32)\n",
    "    y = df1[target].values.astype(np.float32)\n",
    "\n",
    "    # 训练模型1\n",
    "    print(\"\\nTraining Model 1...\")\n",
    "    dataset1 = TensorDataset(torch.FloatTensor(X1), torch.FloatTensor(y))\n",
    "    train_loader1, val_loader1 = create_loaders(dataset1)\n",
    "    model1 = DynamicCNN(X1.shape[1]).to(device)\n",
    "    optimizer1 = optim.Adam(model1.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    criterion1 = nn.BCEWithLogitsLoss(pos_weight=calc_pos_weight(y))\n",
    "    scheduler1 = optim.lr_scheduler.ReduceLROnPlateau(optimizer1, mode='max', factor=0.1, patience=3)\n",
    "    model1, hist1 = train_and_evaluate(model1, train_loader1, val_loader1, optimizer1,\n",
    "                                     criterion1, scheduler=scheduler1, save_path='best_model1.pth')\n",
    "\n",
    "    # 训练模型2\n",
    "    print(\"\\nTraining Model 2...\")\n",
    "    dataset2 = TensorDataset(torch.FloatTensor(X2), torch.FloatTensor(y))\n",
    "    train_loader2, val_loader2 = create_loaders(dataset2)\n",
    "    model2 = DynamicCNN(X2.shape[1]).to(device)\n",
    "    optimizer2 = optim.Adam(model2.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    criterion2 = nn.BCEWithLogitsLoss(pos_weight=calc_pos_weight(y))\n",
    "    scheduler2 = optim.lr_scheduler.ReduceLROnPlateau(optimizer2, mode='max', factor=0.1, patience=3)\n",
    "    model2, hist2 = train_and_evaluate(model2, train_loader2, val_loader2, optimizer2,\n",
    "                                     criterion2, scheduler=scheduler2, save_path='best_model2.pth')\n",
    "\n",
    "    # 加载最佳模型\n",
    "    model1.load_state_dict(torch.load('best_model1.pth'))\n",
    "    model2.load_state_dict(torch.load('best_model2.pth'))\n",
    "\n",
    "    # 训练融合模型\n",
    "    print(\"\\nTraining Fusion Model...\")\n",
    "    fusion_model = AttentionFusion(model1, model2).to(device)\n",
    "    optimizer = optim.Adam(fusion_model.parameters(), lr=0.001)\n",
    "    scheduler_fusion = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    dataset = TensorDataset(torch.FloatTensor(X1), torch.FloatTensor(X2), torch.FloatTensor(y))\n",
    "    train_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    for epoch in range(20):\n",
    "        total_loss = 0\n",
    "        fusion_model.train()\n",
    "        for X1_batch, X2_batch, y_batch in train_loader:\n",
    "            X1_batch, X2_batch = X1_batch.to(device), X2_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            probs = fusion_model(X1_batch, X2_batch)\n",
    "            loss = nn.BCELoss()(probs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler_fusion.step()\n",
    "        print(f\"Epoch {epoch + 1}: Loss={total_loss / len(train_loader):.4f}, LR={optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    # 模型解释与评估\n",
    "    print(\"\\nFeature Importance for Model 1:\")\n",
    "    feature_importance(model1, torch.FloatTensor(X1[:1000]).to(device), df1.drop(columns=target).columns.tolist())\n",
    "    print(\"\\nFeature Importance for Model 2:\")\n",
    "    feature_importance(model2, torch.FloatTensor(X2[:1000]).to(device), df2.drop(columns=target).columns.tolist())\n",
    "    evaluate_ensemble(fusion_model, X1, X2, y)\n",
    "\n",
    "# --------------------------\n",
    "# 辅助函数\n",
    "# --------------------------\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=10, min_delta=0.005):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "\n",
    "    def __call__(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        return False\n",
    "\n",
    "def create_loaders(dataset, val_ratio=0.2):\n",
    "    val_size = int(len(dataset) * val_ratio)\n",
    "    train_size = len(dataset) - val_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    y_train = dataset[train_dataset.indices][1].numpy()\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=calc_sample_weights(y_train),\n",
    "        num_samples=len(train_dataset),\n",
    "        replacement=True\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def calc_pos_weight(y):\n",
    "    pos = np.sum(y)\n",
    "    neg = len(y) - pos\n",
    "    return torch.tensor([neg / pos]).to(device) if pos > 0 else torch.tensor([1.0]).to(device)\n",
    "\n",
    "def calc_sample_weights(y):\n",
    "    class_counts = np.bincount(y.astype(int))\n",
    "    class_weights = 1. / class_counts\n",
    "    return torch.tensor([class_weights[int(label)] for label in y])\n",
    "\n",
    "def evaluate_ensemble(model, X1, X2, y):\n",
    "    loader = DataLoader(TensorDataset(torch.FloatTensor(X1), torch.FloatTensor(X2)), batch_size=256)\n",
    "    model.eval()\n",
    "    probs, truths = [], []\n",
    "    with torch.no_grad():\n",
    "        for X1_batch, X2_batch in loader:\n",
    "            X1_batch, X2_batch = X1_batch.to(device), X2_batch.to(device)\n",
    "            batch_probs = model(X1_batch, X2_batch).cpu().numpy()\n",
    "            probs.extend(batch_probs)\n",
    "            truths.extend(y[:len(X1_batch)])\n",
    "    preds = np.round(probs)\n",
    "    print(\"\\nFinal Ensemble Performance:\")\n",
    "    print(f\"AUC: {roc_auc_score(truths, probs):.4f}\")\n",
    "    print(f\"Accuracy: {accuracy_score(truths, preds):.4f}\")\n",
    "    print(f\"Precision: {precision_score(truths, preds):.4f}\")\n",
    "    print(f\"Recall: {recall_score(truths, preds):.4f}\")\n",
    "    print(f\"F1: {f1_score(truths, preds):.4f}\")\n",
    "    # 绘制ROC曲线\n",
    "    fpr, tpr, _ = roc_curve(truths, probs)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc_score(truths, probs):.2f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3435343-bd68-480f-99be-3c0f2aea0b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m criterion1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss(pos_weight\u001b[38;5;241m=\u001b[39mcalc_pos_weight(y))\n\u001b[0;32m     23\u001b[0m scheduler1 \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer1, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m model1, hist1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mcriterion1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model1.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 训练模型2\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining Model 2...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[21], line 235\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, train_loader, val_loader, optimizer, criterion, scheduler, epochs, save_path)\u001b[0m\n\u001b[0;32m    232\u001b[0m         y_probs\u001b[38;5;241m.\u001b[39mextend(torch\u001b[38;5;241m.\u001b[39msigmoid(outputs)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# 计算指标\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(y_probs)\n\u001b[0;32m    237\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_true, preds)\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:606\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    604\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    605\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 606\u001b[0m y_score \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    609\u001b[0m     y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    610\u001b[0m ):\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;66;03m# do not support partial ROC computation for multiclass\u001b[39;00m\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m max_fpr \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    954\u001b[0m         )\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 957\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "    # 加载数据\n",
    "    df1 = pd.read_csv('./data/cleaned_jigan1.csv')\n",
    "    df2 = pd.read_csv('./data/cleaned_labs_first_day1.csv')\n",
    "    target = 'match_flag'\n",
    "\n",
    "    # 数据对齐\n",
    "    min_len = min(len(df1), len(df2))\n",
    "    df1 = df1.iloc[:min_len].reset_index(drop=True)\n",
    "    df2 = df2.iloc[:min_len].reset_index(drop=True)\n",
    "\n",
    "    # 特征工程\n",
    "    X1 = df1.drop(columns=target).values.astype(np.float32)\n",
    "    X2 = df2.drop(columns=target).values.astype(np.float32)\n",
    "    y = df1[target].values.astype(np.float32)\n",
    "\n",
    "    # 训练模型1\n",
    "    print(\"\\nTraining Model 1...\")\n",
    "    dataset1 = TensorDataset(torch.FloatTensor(X1), torch.FloatTensor(y))\n",
    "    train_loader1, val_loader1 = create_loaders(dataset1)\n",
    "    model1 = DynamicCNN(X1.shape[1]).to(device)\n",
    "    optimizer1 = optim.Adam(model1.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    criterion1 = nn.BCEWithLogitsLoss(pos_weight=calc_pos_weight(y))\n",
    "    scheduler1 = optim.lr_scheduler.ReduceLROnPlateau(optimizer1, mode='max', factor=0.1, patience=3)\n",
    "    model1, hist1 = train_and_evaluate(model1, train_loader1, val_loader1, optimizer1,\n",
    "                                     criterion1, scheduler=scheduler1, save_path='best_model1.pth')\n",
    "\n",
    "    # 训练模型2\n",
    "    print(\"\\nTraining Model 2...\")\n",
    "    dataset2 = TensorDataset(torch.FloatTensor(X2), torch.FloatTensor(y))\n",
    "    train_loader2, val_loader2 = create_loaders(dataset2)\n",
    "    model2 = DynamicCNN(X2.shape[1]).to(device)\n",
    "    optimizer2 = optim.Adam(model2.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    criterion2 = nn.BCEWithLogitsLoss(pos_weight=calc_pos_weight(y))\n",
    "    scheduler2 = optim.lr_scheduler.ReduceLROnPlateau(optimizer2, mode='max', factor=0.1, patience=3)\n",
    "    model2, hist2 = train_and_evaluate(model2, train_loader2, val_loader2, optimizer2,\n",
    "                                     criterion2, scheduler=scheduler2, save_path='best_model2.pth')\n",
    "\n",
    "    # 加载最佳模型\n",
    "    model1.load_state_dict(torch.load('best_model1.pth'))\n",
    "    model2.load_state_dict(torch.load('best_model2.pth'))\n",
    "\n",
    "    # 训练融合模型\n",
    "    print(\"\\nTraining Fusion Model...\")\n",
    "    fusion_model = AttentionFusion(model1, model2).to(device)\n",
    "    optimizer = optim.Adam(fusion_model.parameters(), lr=0.001)\n",
    "    scheduler_fusion = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    dataset = TensorDataset(torch.FloatTensor(X1), torch.FloatTensor(X2), torch.FloatTensor(y))\n",
    "    train_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    for epoch in range(20):\n",
    "        total_loss = 0\n",
    "        fusion_model.train()\n",
    "        for X1_batch, X2_batch, y_batch in train_loader:\n",
    "            X1_batch, X2_batch = X1_batch.to(device), X2_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            probs = fusion_model(X1_batch, X2_batch)\n",
    "            loss = nn.BCELoss()(probs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler_fusion.step()\n",
    "        print(f\"Epoch {epoch + 1}: Loss={total_loss / len(train_loader):.4f}, LR={optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    # 模型解释与评估\n",
    "    print(\"\\nFeature Importance for Model 1:\")\n",
    "    feature_importance(model1, torch.FloatTensor(X1[:1000]).to(device), df1.drop(columns=target).columns.tolist())\n",
    "    print(\"\\nFeature Importance for Model 2:\")\n",
    "    feature_importance(model2, torch.FloatTensor(X2[:1000]).to(device), df2.drop(columns=target).columns.tolist())\n",
    "    evaluate_ensemble(fusion_model, X1, X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de48e1c1-8f8d-41a3-966c-b8177e7eb32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ensemble(model, X1, X2, y):\n",
    "    loader = DataLoader(TensorDataset(torch.FloatTensor(X1), torch.FloatTensor(X2)),\n",
    "                        batch_size=256, shuffle=False)  # 必须关闭shuffle\n",
    "    \n",
    "    model.eval()\n",
    "    probs, truths = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X1_batch, X2_batch) in enumerate(loader):\n",
    "            X1_batch, X2_batch = X1_batch.to(device), X2_batch.to(device)\n",
    "            batch_probs = model(X1_batch, X2_batch).cpu().numpy()\n",
    "            probs.extend(batch_probs)\n",
    "            \n",
    "            # 正确获取对应batch的标签\n",
    "            start_idx = batch_idx * loader.batch_size\n",
    "            end_idx = start_idx + len(X1_batch)\n",
    "            truths.extend(y[start_idx:end_idx])  # 按位置精确截取\n",
    "    \n",
    "    # 转换为numpy数组并验证\n",
    "    truths = np.array(truths)\n",
    "    probs = np.array(probs)\n",
    "    print(f\"\\n最终验证集类别分布 - 负类: {np.sum(truths==0)}, 正类: {np.sum(truths==1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae01a580-09eb-47f6-acaa-608f69639d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "警告：验证集只包含单一类别，无法计算AUC\n",
      "类别分布: {0: 0, 1: 450420}\n"
     ]
    }
   ],
   "source": [
    "evaluate_ensemble(fusion_model, X1, X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e1f867f-9072-4f6c-82e0-0c1039bf9d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "数据类别分布检查：\n",
      "总样本数: 450420\n",
      "正类比例: 50.00%\n",
      "负类数量: 225210\n",
      "正类数量: 225210\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed4baff4-4aaf-4f85-ae9a-e71151178f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "数据完整性验证：\n",
      "X1样本数: 21336, 特征数: 2, 特征名称数: 2\n",
      "X2样本数: 21336, 特征数: 39, 特征名称数: 39\n",
      "正类比例: 53.10%\n",
      "\n",
      "Training Model 1...\n",
      "Epoch 1/30\n",
      "Train Loss: 0.6368\n",
      "Val AUC: 0.6212 | F1: 0.5347 | Accuracy: 0.5881 | Precision: 0.6680\n",
      "Saved new best model with AUC: 0.6212\n",
      "Epoch 2/30\n",
      "Train Loss: 0.6325\n",
      "Val AUC: 0.6246 | F1: 0.5721 | Accuracy: 0.5970 | Precision: 0.6556\n",
      "Saved new best model with AUC: 0.6246\n",
      "Epoch 3/30\n",
      "Train Loss: 0.6327\n",
      "Val AUC: 0.6129 | F1: 0.5547 | Accuracy: 0.5783 | Precision: 0.6312\n",
      "Epoch 4/30\n",
      "Train Loss: 0.6324\n",
      "Val AUC: 0.6219 | F1: 0.5328 | Accuracy: 0.5916 | Precision: 0.6785\n",
      "Epoch 5/30\n",
      "Train Loss: 0.6325\n",
      "Val AUC: 0.6314 | F1: 0.4960 | Accuracy: 0.5815 | Precision: 0.6878\n",
      "Saved new best model with AUC: 0.6314\n",
      "Epoch 6/30\n",
      "Train Loss: 0.6324\n",
      "Val AUC: 0.6274 | F1: 0.5282 | Accuracy: 0.5876 | Precision: 0.6728\n",
      "Epoch 7/30\n",
      "Train Loss: 0.6285\n",
      "Val AUC: 0.6232 | F1: 0.5396 | Accuracy: 0.5890 | Precision: 0.6658\n",
      "Epoch 8/30\n",
      "Train Loss: 0.6293\n",
      "Val AUC: 0.6245 | F1: 0.5177 | Accuracy: 0.5843 | Precision: 0.6742\n",
      "Epoch 9/30\n",
      "Train Loss: 0.6303\n",
      "Val AUC: 0.6247 | F1: 0.4962 | Accuracy: 0.5761 | Precision: 0.6725\n",
      "Epoch 10/30\n",
      "Train Loss: 0.6275\n",
      "Val AUC: 0.6269 | F1: 0.4709 | Accuracy: 0.5715 | Precision: 0.6835\n",
      "Epoch 11/30\n",
      "Train Loss: 0.6254\n",
      "Val AUC: 0.6318 | F1: 0.5254 | Accuracy: 0.5860 | Precision: 0.6712\n",
      "Saved new best model with AUC: 0.6318\n",
      "Epoch 12/30\n",
      "Train Loss: 0.6253\n",
      "Val AUC: 0.6315 | F1: 0.5270 | Accuracy: 0.5869 | Precision: 0.6721\n",
      "Epoch 13/30\n",
      "Train Loss: 0.6296\n",
      "Val AUC: 0.6287 | F1: 0.4701 | Accuracy: 0.5722 | Precision: 0.6864\n",
      "Epoch 14/30\n",
      "Train Loss: 0.6249\n",
      "Val AUC: 0.6310 | F1: 0.4661 | Accuracy: 0.5705 | Precision: 0.6855\n",
      "Epoch 15/30\n",
      "Train Loss: 0.6258\n",
      "Val AUC: 0.6307 | F1: 0.4976 | Accuracy: 0.5818 | Precision: 0.6869\n",
      "Early stopping triggered!\n",
      "\n",
      "Training Model 2...\n",
      "Epoch 1/30\n",
      "Train Loss: 0.5114\n",
      "Val AUC: 0.8237 | F1: 0.7488 | Accuracy: 0.7460 | Precision: 0.7883\n",
      "Saved new best model with AUC: 0.8237\n",
      "Epoch 2/30\n",
      "Train Loss: 0.4869\n",
      "Val AUC: 0.8293 | F1: 0.7771 | Accuracy: 0.7631 | Precision: 0.7766\n",
      "Saved new best model with AUC: 0.8293\n",
      "Epoch 3/30\n",
      "Train Loss: 0.4721\n",
      "Val AUC: 0.8425 | F1: 0.7422 | Accuracy: 0.7505 | Precision: 0.8220\n",
      "Saved new best model with AUC: 0.8425\n",
      "Epoch 4/30\n",
      "Train Loss: 0.4561\n",
      "Val AUC: 0.8457 | F1: 0.7480 | Accuracy: 0.7566 | Precision: 0.8304\n",
      "Saved new best model with AUC: 0.8457\n",
      "Epoch 5/30\n",
      "Train Loss: 0.4630\n",
      "Val AUC: 0.8513 | F1: 0.7836 | Accuracy: 0.7760 | Precision: 0.8044\n",
      "Saved new best model with AUC: 0.8513\n",
      "Epoch 6/30\n",
      "Train Loss: 0.4551\n",
      "Val AUC: 0.8522 | F1: 0.7900 | Accuracy: 0.7795 | Precision: 0.7991\n",
      "Saved new best model with AUC: 0.8522\n",
      "Epoch 7/30\n",
      "Train Loss: 0.4601\n",
      "Val AUC: 0.8490 | F1: 0.7743 | Accuracy: 0.7704 | Precision: 0.8097\n",
      "Epoch 8/30\n",
      "Train Loss: 0.4511\n",
      "Val AUC: 0.8552 | F1: 0.7664 | Accuracy: 0.7694 | Precision: 0.8294\n",
      "Saved new best model with AUC: 0.8552\n",
      "Epoch 9/30\n",
      "Train Loss: 0.4441\n",
      "Val AUC: 0.8572 | F1: 0.7499 | Accuracy: 0.7629 | Precision: 0.8522\n",
      "Saved new best model with AUC: 0.8572\n",
      "Epoch 10/30\n",
      "Train Loss: 0.4385\n",
      "Val AUC: 0.8547 | F1: 0.7604 | Accuracy: 0.7669 | Precision: 0.8368\n",
      "Epoch 11/30\n",
      "Train Loss: 0.4438\n",
      "Val AUC: 0.8565 | F1: 0.8073 | Accuracy: 0.7858 | Precision: 0.7730\n",
      "Epoch 12/30\n",
      "Train Loss: 0.4371\n",
      "Val AUC: 0.8530 | F1: 0.7676 | Accuracy: 0.7694 | Precision: 0.8257\n",
      "Epoch 13/30\n",
      "Train Loss: 0.4532\n",
      "Val AUC: 0.8575 | F1: 0.7944 | Accuracy: 0.7851 | Precision: 0.8073\n",
      "Saved new best model with AUC: 0.8575\n",
      "Epoch 14/30\n",
      "Train Loss: 0.4428\n",
      "Val AUC: 0.8613 | F1: 0.8010 | Accuracy: 0.7903 | Precision: 0.8073\n",
      "Saved new best model with AUC: 0.8613\n",
      "Epoch 15/30\n",
      "Train Loss: 0.4498\n",
      "Val AUC: 0.8603 | F1: 0.7761 | Accuracy: 0.7781 | Precision: 0.8360\n",
      "Epoch 16/30\n",
      "Train Loss: 0.4428\n",
      "Val AUC: 0.8595 | F1: 0.7864 | Accuracy: 0.7814 | Precision: 0.8169\n",
      "Epoch 17/30\n",
      "Train Loss: 0.4423\n",
      "Val AUC: 0.8636 | F1: 0.7921 | Accuracy: 0.7861 | Precision: 0.8184\n",
      "Saved new best model with AUC: 0.8636\n",
      "Epoch 18/30\n",
      "Train Loss: 0.4404\n",
      "Val AUC: 0.8579 | F1: 0.8037 | Accuracy: 0.7894 | Precision: 0.7955\n",
      "Epoch 19/30\n",
      "Train Loss: 0.4340\n",
      "Val AUC: 0.8625 | F1: 0.7913 | Accuracy: 0.7840 | Precision: 0.8123\n",
      "Epoch 20/30\n",
      "Train Loss: 0.4281\n",
      "Val AUC: 0.8622 | F1: 0.7860 | Accuracy: 0.7830 | Precision: 0.8249\n",
      "Epoch 21/30\n",
      "Train Loss: 0.4336\n",
      "Val AUC: 0.8570 | F1: 0.7918 | Accuracy: 0.7816 | Precision: 0.8018\n",
      "Epoch 22/30\n",
      "Train Loss: 0.4372\n",
      "Val AUC: 0.8655 | F1: 0.8000 | Accuracy: 0.7922 | Precision: 0.8179\n",
      "Saved new best model with AUC: 0.8655\n",
      "Epoch 23/30\n",
      "Train Loss: 0.4267\n",
      "Val AUC: 0.8664 | F1: 0.7911 | Accuracy: 0.7877 | Precision: 0.8282\n",
      "Saved new best model with AUC: 0.8664\n",
      "Epoch 24/30\n",
      "Train Loss: 0.4322\n",
      "Val AUC: 0.8667 | F1: 0.8016 | Accuracy: 0.7929 | Precision: 0.8155\n",
      "Saved new best model with AUC: 0.8667\n",
      "Epoch 25/30\n",
      "Train Loss: 0.4188\n",
      "Val AUC: 0.8664 | F1: 0.8114 | Accuracy: 0.7945 | Precision: 0.7912\n",
      "Epoch 26/30\n",
      "Train Loss: 0.4183\n",
      "Val AUC: 0.8673 | F1: 0.7988 | Accuracy: 0.7917 | Precision: 0.8198\n",
      "Saved new best model with AUC: 0.8673\n",
      "Epoch 27/30\n",
      "Train Loss: 0.4158\n",
      "Val AUC: 0.8677 | F1: 0.8004 | Accuracy: 0.7931 | Precision: 0.8206\n",
      "Saved new best model with AUC: 0.8677\n",
      "Early stopping triggered!\n",
      "\n",
      "Training Fusion Model...\n",
      "Epoch 1: Loss=0.4817, LR=0.001000\n",
      "Epoch 2: Loss=0.4738, LR=0.001000\n",
      "Epoch 3: Loss=0.4659, LR=0.001000\n",
      "Epoch 4: Loss=0.4648, LR=0.001000\n",
      "Epoch 5: Loss=0.4631, LR=0.000500\n",
      "Epoch 6: Loss=0.4669, LR=0.000500\n",
      "Epoch 7: Loss=0.4637, LR=0.000500\n",
      "Epoch 8: Loss=0.4714, LR=0.000500\n",
      "Epoch 9: Loss=0.4681, LR=0.000500\n",
      "Epoch 10: Loss=0.4570, LR=0.000250\n",
      "Epoch 11: Loss=0.4548, LR=0.000250\n",
      "Epoch 12: Loss=0.4606, LR=0.000250\n",
      "Epoch 13: Loss=0.4598, LR=0.000250\n",
      "Epoch 14: Loss=0.4667, LR=0.000250\n",
      "Epoch 15: Loss=0.4641, LR=0.000125\n",
      "Epoch 16: Loss=0.4561, LR=0.000125\n",
      "Epoch 17: Loss=0.4582, LR=0.000125\n",
      "Epoch 18: Loss=0.4627, LR=0.000125\n",
      "Epoch 19: Loss=0.4582, LR=0.000125\n",
      "Epoch 20: Loss=0.4612, LR=0.000063\n",
      "\n",
      "Feature Importance for Model 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 76.96it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance for Model 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 91.75it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "最终验证集类别分布 - 负类: 10007, 正类: 11329\n",
      "\n",
      "Final Ensemble Performance:\n",
      "AUC: 0.8926\n",
      "Accuracy: 0.8112\n",
      "Precision: 0.8479\n",
      "Recall: 0.7853\n",
      "F1: 0.8154\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, roc_auc_score,\n",
    "                             roc_curve)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import (DataLoader, TensorDataset,\n",
    "                              WeightedRandomSampler)\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import Compose\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 固定随机种子\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# --------------------------\n",
    "# 时间序列增强模块\n",
    "# --------------------------\n",
    "class TemporalAugmentation:\n",
    "    \"\"\"时间序列数据增强\"\"\"\n",
    "    def __init__(self, sigma=0.1, p=0.5):\n",
    "        self.sigma = sigma  # 噪声强度\n",
    "        self.p = p  # 应用概率\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if np.random.rand() < self.p:\n",
    "            noise = torch.randn_like(x) * self.sigma\n",
    "            return x + noise\n",
    "        return x\n",
    "\n",
    "# --------------------------\n",
    "# 残差块模块（改进版）\n",
    "# --------------------------\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"带通道注意力机制的残差块\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        # 通道注意力机制\n",
    "        self.ca = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Conv1d(out_channels, out_channels // 8, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(out_channels // 8, out_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, 1,\n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.downsample(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # 通道注意力\n",
    "        ca_weight = self.ca(out)\n",
    "        out = out * ca_weight\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# --------------------------\n",
    "# 改进的CNN模型\n",
    "# --------------------------\n",
    "class DynamicCNN(nn.Module):\n",
    "    \"\"\"带数据增强和时间感知的CNN\"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        # 数据增强层\n",
    "        self.augment = Compose([TemporalAugmentation(sigma=0.05, p=0.3)])\n",
    "\n",
    "        # 特征预处理\n",
    "        self.preprocess = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        # 残差卷积模块\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 3, padding=1),\n",
    "            ResidualBlock(16, 16),\n",
    "            nn.MaxPool1d(2),\n",
    "            ResidualBlock(16, 32),\n",
    "            nn.AdaptiveAvgPool1d(8)\n",
    "        )\n",
    "\n",
    "        # 动态计算全连接输入维度\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.randn(2, input_dim)\n",
    "            dummy = self.preprocess(dummy).unsqueeze(1)\n",
    "            dummy = self.conv_layers(dummy)\n",
    "            self.fc_input = dummy.view(dummy.size(0), -1).shape[1]\n",
    "\n",
    "        # 分类器\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.fc_input, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, augment=True):\n",
    "        if self.training and augment:\n",
    "            x = self.augment(x)\n",
    "        x = self.preprocess(x).unsqueeze(1)\n",
    "        features = self.conv_layers(x).view(x.size(0), -1)\n",
    "        return self.classifier(features).squeeze(1)\n",
    "\n",
    "# --------------------------\n",
    "# 注意力融合模块\n",
    "# --------------------------\n",
    "class AttentionFusion(nn.Module):\n",
    "    \"\"\"基于注意力的模型融合\"\"\"\n",
    "    def __init__(self, modelA, modelB):\n",
    "        super().__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(2, 8),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(8, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        with torch.no_grad():\n",
    "            logitA = self.modelA(x1)\n",
    "            logitB = self.modelB(x2)\n",
    "        concat_logits = torch.stack([logitA, logitB], dim=1)\n",
    "        weights = self.attention(concat_logits)\n",
    "        probA = torch.sigmoid(logitA)\n",
    "        probB = torch.sigmoid(logitB)\n",
    "        return (weights[:, 0] * probA) + (weights[:, 1] * probB)\n",
    "\n",
    "# --------------------------\n",
    "# 模型解释模块\n",
    "# --------------------------\n",
    "def feature_importance(model, X, feature_names, n_samples=1000):\n",
    "    model.eval()\n",
    "    baseline = torch.mean(X, dim=0, keepdim=True)\n",
    "    delta_list = []\n",
    "    \n",
    "    # 确保特征数量与特征名称数量一致\n",
    "    if X.shape[1] != len(feature_names):\n",
    "        print(f\"警告：特征数量 ({X.shape[1]}) 与特征名称数量 ({len(feature_names)}) 不匹配\")\n",
    "        print(\"可能原因：数据预处理时某些列未被正确移除或加载\")\n",
    "        return\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(X.shape[1])):\n",
    "            perturbed = X.clone()\n",
    "            perturbed[:, i] = baseline[0, i]\n",
    "            orig_output = torch.sigmoid(model(X))\n",
    "            perturbed_output = torch.sigmoid(model(perturbed))\n",
    "            delta = torch.mean(torch.abs(orig_output - perturbed_output)).item()\n",
    "            delta_list.append(delta)\n",
    "\n",
    "    # 动态确定显示数量\n",
    "    display_num = min(20, len(delta_list))  # 取特征数量和前20中的较小值\n",
    "    indices = np.argsort(delta_list)[::-1][:display_num]  # 只取实际存在的索引\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(range(display_num), [delta_list[i] for i in indices][::-1])\n",
    "    plt.yticks(range(display_num), [feature_names[i] for i in indices][::-1])\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.title(f'Top {display_num} Important Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# 训练评估模块（优化版）\n",
    "# --------------------------\n",
    "def train_and_evaluate(model, train_loader, val_loader, optimizer, criterion,\n",
    "                       scheduler=None, epochs=30, save_path='best_model.pth'):\n",
    "    history = {'train_loss': [], 'val_auc': [], 'val_f1': [],\n",
    "               'val_accuracy': [], 'val_precision': []}\n",
    "    best_auc = 0\n",
    "    early_stop = EarlyStopper(patience=10)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        y_true, y_probs = [], []\n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                X = X.to(device)\n",
    "                outputs = model(X)\n",
    "                y_true.extend(y.cpu().numpy())\n",
    "                y_probs.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "\n",
    "        # 计算指标\n",
    "        auc = roc_auc_score(y_true, y_probs)\n",
    "        preds = np.round(y_probs)\n",
    "        f1 = f1_score(y_true, preds)\n",
    "        accuracy = accuracy_score(y_true, preds)\n",
    "        precision = precision_score(y_true, preds)\n",
    "\n",
    "        history['val_auc'].append(auc)\n",
    "        history['val_f1'].append(f1)\n",
    "        history['val_accuracy'].append(accuracy)\n",
    "        history['val_precision'].append(precision)\n",
    "\n",
    "        # 学习率调度\n",
    "        if scheduler:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(auc)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val AUC: {auc:.4f} | F1: {f1:.4f} | Accuracy: {accuracy:.4f} | Precision: {precision:.4f}\")\n",
    "\n",
    "        # 保存最佳模型\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Saved new best model with AUC: {auc:.4f}\")\n",
    "\n",
    "        if early_stop(auc):\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    return model, history\n",
    "\n",
    "# --------------------------\n",
    "# 主流程\n",
    "# --------------------------\n",
    "def main():\n",
    "    # 加载数据\n",
    "    df1 = pd.read_csv('./data/cleaned_jigan1.csv')\n",
    "    df2 = pd.read_csv('./data/cleaned_labs_first_day1.csv')\n",
    "    target = 'match_flag'\n",
    "\n",
    "    # 数据对齐\n",
    "    common_ids = np.intersect1d(df1['hadm_id'], df2['hadm_id'])  # 假设存在唯一标识列\n",
    "    df1 = df1[df1['hadm_id'].isin(common_ids)].sort_values('hadm_id').reset_index(drop=True)\n",
    "    df2 = df2[df2['hadm_id'].isin(common_ids)].sort_values('hadm_id').reset_index(drop=True)\n",
    "\n",
    "    # 特征工程\n",
    "    feature_names1 = df1.drop(columns=[target, 'hadm_id']).columns.tolist()  # 提取特征名称\n",
    "    feature_names2 = df2.drop(columns=[target, 'hadm_id']).columns.tolist()\n",
    "    X1 = df1.drop(columns=[target, 'hadm_id']).values.astype(np.float32)  # 移除标识列和目标列\n",
    "    X2 = df2.drop(columns=[target, 'hadm_id']).values.astype(np.float32)\n",
    "    y = df1[target].values.astype(np.float32)\n",
    "\n",
    "    # 添加数据完整性检查\n",
    "    print(\"\\n数据完整性验证：\")\n",
    "    print(f\"X1样本数: {len(X1)}, 特征数: {X1.shape[1]}, 特征名称数: {len(feature_names1)}\")\n",
    "    print(f\"X2样本数: {len(X2)}, 特征数: {X2.shape[1]}, 特征名称数: {len(feature_names2)}\")\n",
    "    print(f\"正类比例: {np.mean(y):.2%}\")\n",
    "    assert len(X1) == len(X2) == len(y), \"特征与标签数量不匹配\"\n",
    "    assert X1.shape[1] == len(feature_names1), \"X1 特征数量与特征名称不匹配\"\n",
    "    assert X2.shape[1] == len(feature_names2), \"X2 特征数量与特征名称不匹配\"\n",
    "\n",
    "    # 训练模型1\n",
    "    print(\"\\nTraining Model 1...\")\n",
    "    dataset1 = TensorDataset(torch.FloatTensor(X1), torch.FloatTensor(y))\n",
    "    train_loader1, val_loader1 = create_loaders(dataset1)\n",
    "    model1 = DynamicCNN(X1.shape[1]).to(device)\n",
    "    optimizer1 = optim.Adam(model1.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    criterion1 = nn.BCEWithLogitsLoss(pos_weight=calc_pos_weight(y))\n",
    "    scheduler1 = optim.lr_scheduler.ReduceLROnPlateau(optimizer1, mode='max', factor=0.1, patience=3)\n",
    "    model1, hist1 = train_and_evaluate(model1, train_loader1, val_loader1, optimizer1,\n",
    "                                     criterion1, scheduler=scheduler1, save_path='best_model1.pth')\n",
    "\n",
    "    # 训练模型2\n",
    "    print(\"\\nTraining Model 2...\")\n",
    "    dataset2 = TensorDataset(torch.FloatTensor(X2), torch.FloatTensor(y))\n",
    "    train_loader2, val_loader2 = create_loaders(dataset2)\n",
    "    model2 = DynamicCNN(X2.shape[1]).to(device)\n",
    "    optimizer2 = optim.Adam(model2.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    criterion2 = nn.BCEWithLogitsLoss(pos_weight=calc_pos_weight(y))\n",
    "    scheduler2 = optim.lr_scheduler.ReduceLROnPlateau(optimizer2, mode='max', factor=0.1, patience=3)\n",
    "    model2, hist2 = train_and_evaluate(model2, train_loader2, val_loader2, optimizer2,\n",
    "                                     criterion2, scheduler=scheduler2, save_path='best_model2.pth')\n",
    "\n",
    "    # 加载最佳模型\n",
    "    model1.load_state_dict(torch.load('best_model1.pth'))\n",
    "    model2.load_state_dict(torch.load('best_model2.pth'))\n",
    "\n",
    "    # 训练融合模型\n",
    "    print(\"\\nTraining Fusion Model...\")\n",
    "    fusion_model = AttentionFusion(model1, model2).to(device)\n",
    "    optimizer = optim.Adam(fusion_model.parameters(), lr=0.001)\n",
    "    scheduler_fusion = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    dataset = TensorDataset(torch.FloatTensor(X1), torch.FloatTensor(X2), torch.FloatTensor(y))\n",
    "    train_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    for epoch in range(20):\n",
    "        total_loss = 0\n",
    "        fusion_model.train()\n",
    "        for X1_batch, X2_batch, y_batch in train_loader:\n",
    "            X1_batch, X2_batch = X1_batch.to(device), X2_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            probs = fusion_model(X1_batch, X2_batch)\n",
    "            loss = nn.BCELoss()(probs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler_fusion.step()\n",
    "        print(f\"Epoch {epoch + 1}: Loss={total_loss / len(train_loader):.4f}, LR={optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    # 模型解释与评估\n",
    "    print(\"\\nFeature Importance for Model 1:\")\n",
    "    feature_importance(model1, torch.FloatTensor(X1[:1000]).to(device), feature_names1)\n",
    "    print(\"\\nFeature Importance for Model 2:\")\n",
    "    feature_importance(model2, torch.FloatTensor(X2[:1000]).to(device), feature_names2)\n",
    "    evaluate_ensemble(fusion_model, X1, X2, y)\n",
    "\n",
    "# --------------------------\n",
    "# 辅助函数\n",
    "# --------------------------\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=10, min_delta=0.005):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "\n",
    "    def __call__(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        return False\n",
    "\n",
    "def create_loaders(dataset, val_ratio=0.2):\n",
    "    # 使用分层划分\n",
    "    y = dataset.tensors[1].numpy()\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    train_idx, val_idx = next(skf.split(np.zeros(len(y)), y))\n",
    "    \n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "    \n",
    "    # 类别平衡采样\n",
    "    y_train = y[train_idx]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=calc_sample_weights(y_train),\n",
    "        num_samples=len(train_dataset),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def calc_pos_weight(y):\n",
    "    pos = np.sum(y)\n",
    "    neg = len(y) - pos\n",
    "    return torch.tensor([neg / pos]).to(device) if pos > 0 else torch.tensor([1.0]).to(device)\n",
    "\n",
    "def calc_sample_weights(y):\n",
    "    class_counts = np.bincount(y.astype(int))\n",
    "    class_weights = 1. / class_counts\n",
    "    return torch.tensor([class_weights[int(label)] for label in y])\n",
    "\n",
    "def evaluate_ensemble(model, X1, X2, y):\n",
    "    # 创建数据集时确保顺序一致\n",
    "    dataset = TensorDataset(torch.FloatTensor(X1), torch.FloatTensor(X2), torch.FloatTensor(y))\n",
    "    loader = DataLoader(dataset, batch_size=256, shuffle=False)  # 必须关闭shuffle\n",
    "    \n",
    "    model.eval()\n",
    "    probs, truths = [], []\n",
    "    with torch.no_grad():\n",
    "        for X1_batch, X2_batch, y_batch in loader:\n",
    "            X1_batch, X2_batch = X1_batch.to(device), X2_batch.to(device)\n",
    "            batch_probs = model(X1_batch, X2_batch).cpu().numpy()\n",
    "            probs.extend(batch_probs)\n",
    "            truths.extend(y_batch.cpu().numpy())  # 直接使用loader提供的标签\n",
    "    \n",
    "    # 转换为numpy数组并验证\n",
    "    truths = np.array(truths)\n",
    "    probs = np.array(probs)\n",
    "    print(f\"\\n最终验证集类别分布 - 负类: {np.sum(truths==0)}, 正类: {np.sum(truths==1)}\")\n",
    "    \n",
    "    # 检查类别分布\n",
    "    unique_classes = np.unique(truths)\n",
    "    if len(unique_classes) == 1:\n",
    "        print(\"\\n警告：验证集只包含单一类别，无法计算AUC\")\n",
    "        class_dist = {0: np.sum(truths==0), 1: np.sum(truths==1)}\n",
    "        print(f\"类别分布: {class_dist}\")\n",
    "        return\n",
    "    \n",
    "    # 计算评估指标\n",
    "    preds = np.round(probs)\n",
    "    print(\"\\nFinal Ensemble Performance:\")\n",
    "    try:\n",
    "        auc = roc_auc_score(truths, probs)\n",
    "        print(f\"AUC: {auc:.4f}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"AUC计算失败: {str(e)}\")\n",
    "        auc = 0\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy_score(truths, preds):.4f}\")\n",
    "    print(f\"Precision: {precision_score(truths, preds):.4f}\")\n",
    "    print(f\"Recall: {recall_score(truths, preds):.4f}\")\n",
    "    print(f\"F1: {f1_score(truths, preds):.4f}\")\n",
    "\n",
    "    # 绘制ROC曲线\n",
    "    if auc > 0:\n",
    "        fpr, tpr, _ = roc_curve(truths, probs)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc718c5b-4049-4fd9-90c2-ba752017cac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
